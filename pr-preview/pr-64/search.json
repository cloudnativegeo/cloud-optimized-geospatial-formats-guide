[
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Get Involved",
    "section": "",
    "text": "We encourage contributions to this guide. The guide’s goal is to provide documentation on the best practices for the current state-of-the-art cloud-optimized formats. These formats are evolving, and so will the guide."
  },
  {
    "objectID": "contributing.html#introduction",
    "href": "contributing.html#introduction",
    "title": "Get Involved",
    "section": "",
    "text": "We encourage contributions to this guide. The guide’s goal is to provide documentation on the best practices for the current state-of-the-art cloud-optimized formats. These formats are evolving, and so will the guide."
  },
  {
    "objectID": "contributing.html#pre-requisites",
    "href": "contributing.html#pre-requisites",
    "title": "Get Involved",
    "section": "Pre-requisites",
    "text": "Pre-requisites\nIf you wish to preview the site locally, install quarto. You will also need to be familiar with quarto markdown."
  },
  {
    "objectID": "contributing.html#communication-channels",
    "href": "contributing.html#communication-channels",
    "title": "Get Involved",
    "section": "Communication Channels",
    "text": "Communication Channels\nDiscussions can occur in GitHub Discussions and issues can be raised at GitHub Issues.\n\nGitHub Discussions: Ideal for questions, feature requests, or general conversations about the project. Use this space for collaborative discussions or if you’re unsure where to start.\nGitHub Issues: Use this for reporting bugs, suggesting enhancements, or other tasks that require tracking and possibly code changes."
  },
  {
    "objectID": "contributing.html#core-principles",
    "href": "contributing.html#core-principles",
    "title": "Get Involved",
    "section": "Core Principles",
    "text": "Core Principles\n\nThis guide intends to be opinionated but acknowledges no one-size-fits-all solution.\nThis guide should provide the best information and guidance available but acknowledge that experts develop many existing resources. Those resources should be linked as appropriate."
  },
  {
    "objectID": "contributing.html#additional-criteria",
    "href": "contributing.html#additional-criteria",
    "title": "Get Involved",
    "section": "Additional Criteria",
    "text": "Additional Criteria\n\nAll examples should use open data. If an example uses data from NASA Earthdata, it must include an example of providing credentials (Earthdata registration is available to anyone).\nLanding pages with no code should use quarto markdown (.qmd).\nPages with executable code should be Jupyter Notebooks (.ipynb)."
  },
  {
    "objectID": "contributing.html#code-of-conduct",
    "href": "contributing.html#code-of-conduct",
    "title": "Get Involved",
    "section": "Code of Conduct",
    "text": "Code of Conduct\n\nBe inclusive, respectful, and understanding of others’ backgrounds and contexts.\nLook for and foster diverse perspectives.\nIf you experience any harmful behavior, please get in touch with Aimee or Alex."
  },
  {
    "objectID": "contributing.html#bug-reporting-feature-requests",
    "href": "contributing.html#bug-reporting-feature-requests",
    "title": "Get Involved",
    "section": "Bug Reporting & Feature Requests",
    "text": "Bug Reporting & Feature Requests\nBefore submitting a bug report or a feature request, please start a GitHub Discussion to see if the issue has already been addressed or if it can be resolved through discussion.\n\nGeneral Steps\n\nFork the repository.\nClone your fork locally.\nCreate a new branch for your changes.\nMake your changes and use quarto preview to make sure they look good.\nOpen a pull request.\n\nOnce the pull request is opened, and the GitHub preview.yml workflow runs (“Deploy PR previews”), you should have a preview available for review at https://developmentseed.org/cloud-optimized-geospatial-formats-guide/pr-preview/pr-&lt;YOUR-PR-NUMBER-HERE&gt;. A bot will comment on your PR when the PR preview is ready.\n\n\nSpecific Contributions\n\n1. Adding a New Format\nFollow the steps outlined in the General Steps, then:\n\nCreate a folder with the format’s name and, within that folder, an intro.qmd.\nLink to the intro.qmd page in the index.qmd (the Welcome page) file and _quarto.yml table of contents.\n\n\n\n2. Modify or Add to an Existing Format\nFeel free to modify or add to existing content if you think it could be improved.\n\n\n3. Adding a Cookbook\nCookbooks should address common questions and present solutions for cloud-optimized access and visualization. To create a cookbook, either add a notebook directly to this repository in the cookbooks directory OR use an external link and add it to cookbooks/index.qmd.\n\n\n4. (Optional) Update Slides\nIf you have made substantive changes, consider updating the Overview Slides. These slides are generated using Quarto and Reveal.js so can be updated with markdown syntax.\n\n\n5. Add Yourself to the List of Authors\nAdd yourself to the list of authors on the Welcome page.\n\n\n6. Final Steps Before Merging\nOnce your PR is approved and all checks have passed, a project maintainer will merge your changes into the main repository."
  },
  {
    "objectID": "contributing.html#licensing",
    "href": "contributing.html#licensing",
    "title": "Get Involved",
    "section": "Licensing",
    "text": "Licensing\nThis work is licensed under the Creative Commons Attribution 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by/4.0/. For attribution requirements, please look at the license terms.\nPreferred citation: Barciauskas, A et al. 2023. Cloud Optimized Geospatial Formats Guide. CC-By-4.0."
  },
  {
    "objectID": "contributing.html#contact",
    "href": "contributing.html#contact",
    "title": "Get Involved",
    "section": "Contact",
    "text": "Contact\nFor questions on how to contribute, start a discussion in the GitHub Discussions section."
  },
  {
    "objectID": "contributing.html#thank-you-to-our-supporters",
    "href": "contributing.html#thank-you-to-our-supporters",
    "title": "Get Involved",
    "section": "Thank you to our supporters",
    "text": "Thank you to our supporters\nThis guide has been made possible through the support of:"
  },
  {
    "objectID": "pmtiles/pmtiles-example.html",
    "href": "pmtiles/pmtiles-example.html",
    "title": "PMTiles example",
    "section": "",
    "text": "This notebook will give an overview of how to create and visualize PMTiles archives."
  },
  {
    "objectID": "pmtiles/pmtiles-example.html#environment",
    "href": "pmtiles/pmtiles-example.html#environment",
    "title": "PMTiles example",
    "section": "Environment",
    "text": "Environment\nThe packages needed for this notebook can be installed with conda or mamba. Using the environment.yml from this folder run:\nconda create -f environment.yml \nor\nmamba create -f environment.yml \nAlternatively, you can install pmtiles and mapbox-vector-tile through pip, and tippecanoe through Homebrew (brew install tippecanoe) if on MacOS."
  },
  {
    "objectID": "pmtiles/pmtiles-example.html#creating-pmtiles",
    "href": "pmtiles/pmtiles-example.html#creating-pmtiles",
    "title": "PMTiles example",
    "section": "Creating PMTiles",
    "text": "Creating PMTiles\nFor this example, we’ll use the same file as used in the FlatGeobuf and GeoParquet example notebooks: a 13MB file of US counties.\nWe’ll use Tippecanoe to convert this file into tiles.\nFirst we’ll download the file to our local directory:\n\n!wget https://flatgeobuf.org/test/data/UScounties.fgb\n\n--2023-08-23 15:54:58--  https://flatgeobuf.org/test/data/UScounties.fgb\nResolving flatgeobuf.org (flatgeobuf.org)... 185.199.108.153\nConnecting to flatgeobuf.org (flatgeobuf.org)|185.199.108.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 14100008 (13M) [application/octet-stream]\nSaving to: ‘UScounties.fgb’\n\nUScounties.fgb      100%[===================&gt;]  13.45M  7.94MB/s    in 1.7s    \n\n2023-08-23 15:55:02 (7.94 MB/s) - ‘UScounties.fgb’ saved [14100008/14100008]\n\n\n\nTippecanoe has many options to customize its behavior. Here we’ll use the -zg flag to tell Tippecanoe to deduce appropriate minimum and maximum zoom levels for the dataset. The -o counties.pmtiles flag tells Tippecanoe to save the output with that name.\nTippecanoe also works especially well with FlatGeobuf files. When a FlatGeobuf file is used as input, Tippecanoe will reuse the spatial index stored in the FlatGeobuf file instead of creating its own.\n\n!tippecanoe UScounties.fgb -o counties.pmtiles -zg\n\nFor layer 0, using name \"UScountiesfgb\"\ndetected indexed FlatGeobuf: assigning feature IDs by sequence\n3221 features, 5580299 bytes of geometry, 53296 bytes of string pool\nChoosing a maxzoom of -z1 for features typically 141427 feet (43107 meters) apart, and at least 33249 feet (10135 meters) apart\nChoosing a maxzoom of -z7 for resolution of about 3195 feet (973 meters) within features\n  99.9%  7/36/49   \n  100.0%  7/127/42  \n\n\nNow we have a file named counties.pmtiles with our data:\n\n!ls -lh counties.pmtiles\n\n-rw-r--r--@ 1 kyle  staff   2.8M Aug 25 13:09 counties.pmtiles"
  },
  {
    "objectID": "pmtiles/pmtiles-example.html#visualization",
    "href": "pmtiles/pmtiles-example.html#visualization",
    "title": "PMTiles example",
    "section": "Visualization",
    "text": "Visualization\nThe easiest way to interpret this data is to load it into the PMTiles Viewer. Drag the counties.pmtiles file into that website, and you’ll be able to hover over areas"
  },
  {
    "objectID": "pmtiles/pmtiles-example.html#reading-from-python",
    "href": "pmtiles/pmtiles-example.html#reading-from-python",
    "title": "PMTiles example",
    "section": "Reading from Python",
    "text": "Reading from Python\nIt’s possible to open and read a PMTiles file from python using the pmtiles and mapbox-vector-tile libraries. The pmtiles library is used to open the archive and fetch a specific tile, while mapbox-vector-tile is used to decode the MVT vector tile data contained within that tile.\n\nfrom pmtiles.reader import Reader, MmapSource\n\nOpen the file and create a pmtiles Reader object\n\nfile = open(\"counties.pmtiles\")\nreader = Reader(MmapSource(file))\n\nFetch a specific tile. This tile’s coordinates were found from the PMTiles viewer above, and is located over the east coast.\n\nx, y, z = 37, 48, 7\ntile_data = reader.get(z, x, y)\n\ntile_data is now a bytes object, representing the data contained in the PMTiles archive for that specific XYZ tile.\n\ntype(tile_data)\n\nbytes\n\n\n\nlen(tile_data)\n\n11878\n\n\nIn our case, the PMTiles archive contains MVT data, so we can decode the buffer using mapbox_vector_tile. It’s also possible for the archive to contain raster images (e.g. PNG files), in which case a different decoding process would be necessary.\n\nimport mapbox_vector_tile\nimport gzip\n\nWe’ll decode the tile and print the output from mapbox_vector_tile. MVT data are encoded with “quantization”, meaning reduced precision so the data can be compressed better. So the coordinates printed out have a range of 0-4096, where those are the integer steps within the local coordinate reference system within the tile. Refer to the mapbox_vector_tile docs for how to read to GeoJSON.\n\nmapbox_vector_tile.decode(gzip.decompress(tile_data))\n\n{'UScountiesfgb': {'extent': 4096,\n  'version': 2,\n  'features': [{'geometry': {'type': 'Polygon',\n     'coordinates': [[[289, 4176],\n       [290, 4168],\n       [299, 4151],\n       [198, 4102],\n       [172, 4100],\n       [163, 4096],\n       [128, 4080],\n       [130, 4070],\n       [0, 4009],\n       [-71, 3976],\n       [-80, 3970],\n       [-80, 4176],\n       [289, 4176]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '079',\n     'FIPS': '42079',\n     'STATE': 'PA',\n     'NAME': 'Luzerne',\n     'LSAD': 'County'},\n    'id': 2224,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1272, 4176],\n       [1256, 4168],\n       [1247, 4167],\n       [1235, 4163],\n       [1226, 4152],\n       [1206, 4143],\n       [1204, 4139],\n       [1180, 4123],\n       [1175, 4118],\n       [1174, 4113],\n       [1174, 4106],\n       [1171, 4096],\n       [1168, 4090],\n       [1168, 4084],\n       [1171, 4079],\n       [1174, 4076],\n       [1177, 4075],\n       [1187, 4077],\n       [1190, 4074],\n       [1177, 4056],\n       [1154, 4041],\n       [1143, 4037],\n       [1119, 4035],\n       [1108, 4030],\n       [1106, 4020],\n       [1092, 4014],\n       [1081, 4012],\n       [1048, 3996],\n       [1042, 3980],\n       [1014, 3960],\n       [1027, 3941],\n       [976, 3908],\n       [967, 3890],\n       [952, 3877],\n       [928, 3864],\n       [898, 3857],\n       [868, 3837],\n       [807, 3809],\n       [758, 3800],\n       [753, 3795],\n       [721, 3785],\n       [675, 3778],\n       [663, 3807],\n       [648, 3835],\n       [529, 4041],\n       [620, 4096],\n       [643, 4110],\n       [590, 4176],\n       [1272, 4176]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '089',\n     'FIPS': '42089',\n     'STATE': 'PA',\n     'NAME': 'Monroe',\n     'LSAD': 'County'},\n    'id': 2227,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[590, 4176],\n       [643, 4110],\n       [620, 4096],\n       [529, 4041],\n       [598, 3923],\n       [655, 3822],\n       [675, 3778],\n       [668, 3775],\n       [625, 3767],\n       [609, 3766],\n       [596, 3762],\n       [577, 3763],\n       [562, 3758],\n       [553, 3752],\n       [524, 3748],\n       [498, 3737],\n       [494, 3730],\n       [488, 3726],\n       [478, 3725],\n       [399, 3706],\n       [363, 3696],\n       [354, 3692],\n       [342, 3677],\n       [304, 3661],\n       [299, 3656],\n       [289, 3642],\n       [282, 3641],\n       [281, 3635],\n       [262, 3625],\n       [75, 3781],\n       [0, 3867],\n       [-80, 3958],\n       [-80, 3970],\n       [0, 4009],\n       [130, 4070],\n       [128, 4080],\n       [163, 4096],\n       [172, 4100],\n       [198, 4102],\n       [299, 4151],\n       [290, 4168],\n       [289, 4176],\n       [590, 4176]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '025',\n     'FIPS': '42025',\n     'STATE': 'PA',\n     'NAME': 'Carbon',\n     'LSAD': 'County'},\n    'id': 2217,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1529, 4176],\n       [1594, 4096],\n       [1703, 3965],\n       [1691, 3952],\n       [1687, 3954],\n       [1681, 3943],\n       [1671, 3935],\n       [1671, 3928],\n       [1668, 3923],\n       [1651, 3914],\n       [1647, 3908],\n       [1648, 3894],\n       [1645, 3883],\n       [1646, 3880],\n       [1654, 3874],\n       [1652, 3869],\n       [1643, 3865],\n       [1642, 3855],\n       [1637, 3849],\n       [1627, 3845],\n       [1625, 3843],\n       [1622, 3833],\n       [1627, 3829],\n       [1630, 3821],\n       [1617, 3812],\n       [1611, 3804],\n       [1613, 3799],\n       [1606, 3792],\n       [1606, 3786],\n       [1598, 3780],\n       [1592, 3771],\n       [1589, 3771],\n       [1588, 3765],\n       [1583, 3757],\n       [1576, 3756],\n       [1569, 3752],\n       [1567, 3756],\n       [1562, 3755],\n       [1558, 3742],\n       [1546, 3737],\n       [1539, 3731],\n       [1535, 3733],\n       [1532, 3732],\n       [1517, 3719],\n       [1505, 3712],\n       [1507, 3706],\n       [1506, 3698],\n       [1507, 3695],\n       [1494, 3686],\n       [1489, 3680],\n       [1489, 3677],\n       [1485, 3672],\n       [1473, 3663],\n       [1470, 3658],\n       [1467, 3656],\n       [1465, 3651],\n       [1452, 3636],\n       [1451, 3631],\n       [1443, 3624],\n       [1435, 3610],\n       [1426, 3606],\n       [1424, 3602],\n       [1419, 3597],\n       [1410, 3577],\n       [1396, 3578],\n       [1393, 3569],\n       [1378, 3563],\n       [1361, 3545],\n       [1356, 3544],\n       [1351, 3547],\n       [1345, 3543],\n       [1341, 3547],\n       [1337, 3542],\n       [1333, 3542],\n       [1315, 3526],\n       [1310, 3526],\n       [1308, 3524],\n       [1303, 3517],\n       [1301, 3516],\n       [1295, 3518],\n       [1288, 3512],\n       [1282, 3510],\n       [1278, 3505],\n       [1275, 3499],\n       [1267, 3497],\n       [1264, 3494],\n       [1254, 3488],\n       [1247, 3476],\n       [1236, 3472],\n       [1235, 3468],\n       [1226, 3458],\n       [1211, 3451],\n       [1207, 3447],\n       [1208, 3442],\n       [1205, 3440],\n       [1180, 3431],\n       [1168, 3424],\n       [1153, 3420],\n       [1150, 3416],\n       [1150, 3408],\n       [1147, 3405],\n       [1141, 3407],\n       [1129, 3399],\n       [1130, 3393],\n       [1128, 3387],\n       [1124, 3385],\n       [1120, 3378],\n       [1114, 3375],\n       [1111, 3363],\n       [1104, 3361],\n       [1102, 3355],\n       [1096, 3351],\n       [1088, 3349],\n       [1085, 3370],\n       [1072, 3393],\n       [1071, 3398],\n       [1077, 3402],\n       [1088, 3404],\n       [1091, 3412],\n       [1085, 3444],\n       [1073, 3455],\n       [1073, 3460],\n       [1087, 3484],\n       [1099, 3492],\n       [1107, 3505],\n       [1108, 3511],\n       [1107, 3514],\n       [1102, 3518],\n       [1097, 3519],\n       [1088, 3518],\n       [1079, 3521],\n       [1073, 3529],\n       [1068, 3541],\n       [1082, 3584],\n       [1089, 3592],\n       [1100, 3618],\n       [1095, 3629],\n       [1081, 3645],\n       [1079, 3656],\n       [1086, 3664],\n       [1099, 3671],\n       [1105, 3676],\n       [1107, 3681],\n       [1110, 3697],\n       [1115, 3707],\n       [1118, 3708],\n       [1127, 3708],\n       [1148, 3701],\n       [1170, 3699],\n       [1174, 3703],\n       [1186, 3724],\n       [1195, 3729],\n       [1203, 3730],\n       [1207, 3732],\n       [1219, 3749],\n       [1219, 3764],\n       [1225, 3773],\n       [1234, 3780],\n       [1243, 3797],\n       [1243, 3803],\n       [1241, 3807],\n       [1224, 3825],\n       [1223, 3832],\n       [1226, 3840],\n       [1233, 3844],\n       [1254, 3845],\n       [1262, 3841],\n       [1269, 3841],\n       [1272, 3842],\n       [1288, 3865],\n       [1291, 3876],\n       [1290, 3885],\n       [1287, 3891],\n       [1280, 3899],\n       [1270, 3914],\n       [1256, 3931],\n       [1255, 3956],\n       [1250, 3969],\n       [1226, 3989],\n       [1212, 4012],\n       [1211, 4018],\n       [1203, 4035],\n       [1194, 4044],\n       [1190, 4065],\n       [1191, 4070],\n       [1190, 4074],\n       [1187, 4077],\n       [1177, 4075],\n       [1174, 4076],\n       [1171, 4079],\n       [1168, 4084],\n       [1168, 4090],\n       [1171, 4096],\n       [1174, 4106],\n       [1174, 4113],\n       [1175, 4118],\n       [1180, 4123],\n       [1204, 4139],\n       [1206, 4143],\n       [1226, 4152],\n       [1235, 4163],\n       [1247, 4167],\n       [1256, 4168],\n       [1272, 4176],\n       [1529, 4176]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '041',\n     'FIPS': '34041',\n     'STATE': 'NJ',\n     'NAME': 'Warren',\n     'LSAD': 'County'},\n    'id': 2207,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[2427, 4176],\n        [2425, 4170],\n        [2437, 4158],\n        [2460, 4120],\n        [2494, 4099],\n        [2518, 4096],\n        [2573, 4090],\n        [2573, 4096],\n        [2574, 4104],\n        [2583, 4096],\n        [2616, 4070],\n        [2606, 4022],\n        [2612, 4020],\n        [2619, 4007],\n        [2615, 3999],\n        [2616, 3992],\n        [2619, 3987],\n        [2630, 3985],\n        [2633, 3981],\n        [2628, 3967],\n        [2630, 3956],\n        [2627, 3941],\n        [2634, 3930],\n        [2632, 3915],\n        [2646, 3904],\n        [2654, 3892],\n        [2656, 3885],\n        [2661, 3874],\n        [2665, 3871],\n        [2665, 3860],\n        [2662, 3856],\n        [2659, 3857],\n        [2656, 3864],\n        [2649, 3864],\n        [2647, 3855],\n        [2648, 3849],\n        [2644, 3833],\n        [2641, 3826],\n        [2645, 3808],\n        [2641, 3793],\n        [2638, 3790],\n        [2632, 3788],\n        [2552, 3846],\n        [2534, 3860],\n        [2536, 3865],\n        [2529, 3868],\n        [2527, 3864],\n        [2472, 3904],\n        [2453, 3906],\n        [2451, 3909],\n        [2443, 3911],\n        [2437, 3917],\n        [2433, 3931],\n        [2425, 3938],\n        [2424, 3942],\n        [2427, 3948],\n        [2424, 3953],\n        [2426, 3956],\n        [2426, 3962],\n        [2430, 3957],\n        [2432, 3957],\n        [2433, 3959],\n        [2426, 3972],\n        [2416, 3973],\n        [2416, 3978],\n        [2408, 3975],\n        [2408, 3980],\n        [2405, 3984],\n        [2407, 3986],\n        [2402, 3989],\n        [2402, 3995],\n        [2401, 3997],\n        [2407, 4002],\n        [2411, 4013],\n        [2415, 4025],\n        [2418, 4047],\n        [2414, 4053],\n        [2415, 4069],\n        [2413, 4071],\n        [2412, 4075],\n        [2413, 4081],\n        [2417, 4079],\n        [2418, 4085],\n        [2412, 4090],\n        [2412, 4096],\n        [2407, 4094],\n        [2399, 4096],\n        [2392, 4094],\n        [2389, 4096],\n        [2389, 4103],\n        [2396, 4111],\n        [2391, 4117],\n        [2391, 4125],\n        [2388, 4128],\n        [2388, 4136],\n        [2387, 4140],\n        [2384, 4140],\n        [2382, 4133],\n        [2370, 4132],\n        [2363, 4139],\n        [2344, 4137],\n        [2341, 4140],\n        [2334, 4142],\n        [2334, 4147],\n        [2329, 4148],\n        [2325, 4146],\n        [2324, 4148],\n        [2318, 4144],\n        [2310, 4144],\n        [2310, 4156],\n        [2306, 4160],\n        [2298, 4162],\n        [2293, 4160],\n        [2292, 4157],\n        [2281, 4157],\n        [2274, 4161],\n        [2265, 4162],\n        [2259, 4157],\n        [2255, 4159],\n        [2251, 4165],\n        [2240, 4168],\n        [2235, 4173],\n        [2234, 4176],\n        [2427, 4176]]],\n      [[[2203, 4176],\n        [2202, 4172],\n        [2196, 4170],\n        [2189, 4174],\n        [2190, 4176],\n        [2203, 4176]]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '031',\n     'FIPS': '34031',\n     'STATE': 'NJ',\n     'NAME': 'Passaic',\n     'LSAD': 'County'},\n    'id': 2230,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2981, 4176],\n       [2977, 4145],\n       [2976, 4129],\n       [2960, 4130],\n       [2885, 4176],\n       [2981, 4176]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '087',\n     'FIPS': '36087',\n     'STATE': 'NY',\n     'NAME': 'Rockland',\n     'LSAD': 'County'},\n    'id': 2226,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[3469, 4176],\n        [3460, 4167],\n        [3451, 4156],\n        [3448, 4138],\n        [3428, 4137],\n        [3426, 4155],\n        [3410, 4166],\n        [3398, 4164],\n        [3341, 4139],\n        [3330, 4126],\n        [3321, 4106],\n        [3317, 4111],\n        [3319, 4122],\n        [3318, 4134],\n        [3325, 4157],\n        [3312, 4176],\n        [3469, 4176]]],\n      [[[3519, 4176],\n        [3517, 4172],\n        [3508, 4166],\n        [3505, 4176],\n        [3519, 4176]]]]},\n    'properties': {'STATE_FIPS': '09',\n     'COUNTY_FIP': '001',\n     'FIPS': '09001',\n     'STATE': 'CT',\n     'NAME': 'Fairfield',\n     'LSAD': 'County'},\n    'id': 1713,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[3156, 3920],\n        [3161, 3917],\n        [3162, 3906],\n        [3161, 3904],\n        [3155, 3902],\n        [3149, 3908],\n        [3149, 3912],\n        [3153, 3912],\n        [3153, 3918],\n        [3156, 3920]]],\n      [[[3312, 4176],\n        [3325, 4157],\n        [3318, 4134],\n        [3319, 4122],\n        [3317, 4111],\n        [3321, 4106],\n        [3323, 4096],\n        [3317, 4074],\n        [3314, 4070],\n        [3310, 4072],\n        [3291, 4063],\n        [3283, 4036],\n        [3278, 4029],\n        [3262, 4018],\n        [3227, 4004],\n        [3212, 3990],\n        [3176, 3966],\n        [3140, 3914],\n        [3137, 3905],\n        [3079, 3925],\n        [3078, 3922],\n        [3057, 3931],\n        [3053, 3950],\n        [3048, 3950],\n        [3048, 3952],\n        [3042, 3955],\n        [3036, 3956],\n        [3039, 3961],\n        [3036, 3961],\n        [3033, 3958],\n        [3034, 3955],\n        [3031, 3954],\n        [3026, 3943],\n        [2941, 3976],\n        [2972, 4096],\n        [2981, 4176],\n        [3312, 4176]]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '119',\n     'FIPS': '36119',\n     'STATE': 'NY',\n     'NAME': 'Westchester',\n     'LSAD': 'County'},\n    'id': 2232,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[-80, 3958],\n       [0, 3867],\n       [75, 3781],\n       [219, 3660],\n       [262, 3625],\n       [250, 3617],\n       [232, 3613],\n       [230, 3605],\n       [205, 3590],\n       [189, 3572],\n       [135, 3544],\n       [120, 3544],\n       [67, 3514],\n       [0, 3481],\n       [-80, 3442],\n       [-80, 3958]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '107',\n     'FIPS': '42107',\n     'STATE': 'PA',\n     'NAME': 'Schuylkill',\n     'LSAD': 'County'},\n    'id': 2216,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[-80, 2134],\n        [-80, 2627],\n        [0, 2560],\n        [93, 2480],\n        [69, 2466],\n        [0, 2431],\n        [-8, 2427],\n        [0, 2380],\n        [2, 2369],\n        [2, 2342],\n        [5, 2310],\n        [3, 2293],\n        [0, 2287],\n        [-72, 2157],\n        [-71, 2150],\n        [-77, 2142],\n        [-80, 2134]]],\n      [[[-80, 2117],\n        [-77, 2115],\n        [-74, 2105],\n        [-65, 2097],\n        [-63, 2093],\n        [-64, 2086],\n        [-69, 2090],\n        [-73, 2086],\n        [-79, 2085],\n        [-78, 2081],\n        [-80, 2080],\n        [-80, 2117]]],\n      [[[-80, 1996],\n        [-74, 1988],\n        [-72, 1979],\n        [-77, 1974],\n        [-79, 1970],\n        [-80, 1971],\n        [-80, 1996]]],\n      [[[-80, 2026],\n        [-73, 2020],\n        [-72, 2015],\n        [-76, 2012],\n        [-78, 2006],\n        [-79, 2001],\n        [-77, 2000],\n        [-80, 1996],\n        [-80, 2026]]],\n      [[[-80, 2123], [-78, 2120], [-80, 2117], [-80, 2123]]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '071',\n     'FIPS': '42071',\n     'STATE': 'PA',\n     'NAME': 'Lancaster',\n     'LSAD': 'County'},\n    'id': 2185,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[223, 1051],\n       [235, 1047],\n       [235, 1044],\n       [240, 1045],\n       [249, 1041],\n       [264, 794],\n       [262, 796],\n       [255, 795],\n       [247, 797],\n       [241, 794],\n       [236, 796],\n       [233, 793],\n       [232, 795],\n       [223, 792],\n       [222, 791],\n       [210, 788],\n       [209, 790],\n       [205, 785],\n       [197, 787],\n       [195, 790],\n       [191, 786],\n       [185, 792],\n       [171, 794],\n       [163, 799],\n       [162, 802],\n       [157, 803],\n       [148, 808],\n       [143, 809],\n       [142, 816],\n       [136, 816],\n       [122, 820],\n       [120, 824],\n       [113, 821],\n       [106, 823],\n       [92, 809],\n       [92, 801],\n       [86, 802],\n       [84, 804],\n       [75, 800],\n       [71, 807],\n       [67, 809],\n       [63, 806],\n       [63, 797],\n       [29, 789],\n       [18, 790],\n       [0, 782],\n       [-5, 780],\n       [-10, 781],\n       [-16, 787],\n       [-21, 788],\n       [-27, 784],\n       [-30, 784],\n       [-37, 786],\n       [-43, 793],\n       [-48, 795],\n       [-58, 792],\n       [-70, 794],\n       [-71, 783],\n       [-75, 781],\n       [-80, 780],\n       [-80, 1037],\n       [-75, 1034],\n       [-64, 1021],\n       [-60, 1021],\n       [-56, 1022],\n       [-48, 1033],\n       [-39, 1036],\n       [-21, 1034],\n       [-17, 1032],\n       [-11, 1025],\n       [-5, 1023],\n       [0, 1025],\n       [8, 1030],\n       [14, 1030],\n       [21, 1022],\n       [49, 1017],\n       [63, 1019],\n       [71, 1012],\n       [76, 1010],\n       [81, 1017],\n       [102, 1023],\n       [107, 1021],\n       [111, 1023],\n       [120, 1017],\n       [130, 1024],\n       [134, 1023],\n       [139, 1029],\n       [155, 1035],\n       [166, 1049],\n       [173, 1050],\n       [176, 1047],\n       [186, 1046],\n       [191, 1038],\n       [193, 1037],\n       [198, 1042],\n       [206, 1041],\n       [209, 1046],\n       [213, 1046],\n       [216, 1048],\n       [222, 1046],\n       [223, 1051]]]},\n    'properties': {'STATE_FIPS': '24',\n     'COUNTY_FIP': '029',\n     'FIPS': '24029',\n     'STATE': 'MD',\n     'NAME': 'Kent',\n     'LSAD': 'County'},\n    'id': 2126,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[120, 824],\n       [122, 820],\n       [136, 816],\n       [142, 816],\n       [143, 809],\n       [148, 808],\n       [157, 803],\n       [162, 802],\n       [163, 799],\n       [171, 794],\n       [185, 792],\n       [191, 786],\n       [195, 790],\n       [197, 787],\n       [205, 785],\n       [209, 790],\n       [210, 788],\n       [222, 791],\n       [223, 792],\n       [232, 795],\n       [233, 793],\n       [236, 796],\n       [241, 794],\n       [247, 797],\n       [255, 795],\n       [262, 796],\n       [264, 794],\n       [276, 601],\n       [262, 592],\n       [236, 584],\n       [213, 581],\n       [209, 575],\n       [202, 573],\n       [197, 566],\n       [186, 558],\n       [167, 548],\n       [153, 536],\n       [149, 535],\n       [143, 520],\n       [137, 502],\n       [133, 500],\n       [130, 495],\n       [132, 473],\n       [129, 466],\n       [116, 452],\n       [112, 447],\n       [108, 443],\n       [99, 440],\n       [96, 432],\n       [89, 422],\n       [86, 421],\n       [86, 418],\n       [88, 417],\n       [89, 414],\n       [87, 405],\n       [84, 404],\n       [82, 396],\n       [79, 393],\n       [79, 389],\n       [78, 387],\n       [80, 384],\n       [73, 382],\n       [71, 377],\n       [68, 374],\n       [68, 366],\n       [57, 359],\n       [49, 364],\n       [47, 361],\n       [49, 354],\n       [49, 352],\n       [42, 352],\n       [42, 348],\n       [39, 340],\n       [35, 339],\n       [33, 335],\n       [26, 332],\n       [23, 322],\n       [11, 315],\n       [13, 311],\n       [7, 307],\n       [4, 299],\n       [4, 295],\n       [0, 292],\n       [-5, 289],\n       [-3, 285],\n       [0, 284],\n       [1, 283],\n       [0, 278],\n       [-8, 270],\n       [-1, 257],\n       [-2, 253],\n       [-4, 254],\n       [-7, 250],\n       [-7, 238],\n       [-10, 234],\n       [-20, 231],\n       [-19, 222],\n       [-14, 222],\n       [-14, 220],\n       [-23, 217],\n       [-21, 214],\n       [-17, 213],\n       [-15, 210],\n       [-16, 204],\n       [-17, 202],\n       [-22, 201],\n       [-22, 200],\n       [-18, 190],\n       [-17, 179],\n       [-45, 186],\n       [-50, 186],\n       [-59, 190],\n       [-80, 194],\n       [-80, 780],\n       [-75, 781],\n       [-71, 783],\n       [-70, 794],\n       [-58, 792],\n       [-48, 795],\n       [-43, 793],\n       [-37, 786],\n       [-30, 784],\n       [-27, 784],\n       [-21, 788],\n       [-16, 787],\n       [-10, 781],\n       [-5, 780],\n       [0, 782],\n       [18, 790],\n       [29, 789],\n       [63, 797],\n       [63, 806],\n       [67, 809],\n       [71, 807],\n       [75, 800],\n       [84, 804],\n       [86, 802],\n       [92, 801],\n       [92, 809],\n       [106, 823],\n       [113, 821],\n       [120, 824]]]},\n    'properties': {'STATE_FIPS': '24',\n     'COUNTY_FIP': '035',\n     'FIPS': '24035',\n     'STATE': 'MD',\n     'NAME': \"Queen Anne's\",\n     'LSAD': 'County'},\n    'id': 2137,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[-80, 194],\n       [-59, 190],\n       [-50, 186],\n       [-45, 186],\n       [-17, 179],\n       [-10, 176],\n       [-9, 172],\n       [-16, 172],\n       [-16, 167],\n       [-8, 158],\n       [-9, 156],\n       [-15, 153],\n       [-16, 149],\n       [-11, 145],\n       [-10, 140],\n       [-12, 133],\n       [-16, 130],\n       [-16, 129],\n       [-10, 126],\n       [-4, 117],\n       [-6, 115],\n       [-18, 116],\n       [-20, 115],\n       [-20, 108],\n       [-16, 104],\n       [-3, 110],\n       [0, 107],\n       [0, 104],\n       [-2, 101],\n       [-9, 101],\n       [-10, 98],\n       [-6, 85],\n       [-3, 82],\n       [0, 83],\n       [4, 84],\n       [11, 72],\n       [19, 71],\n       [22, 65],\n       [22, 62],\n       [10, 53],\n       [16, 46],\n       [26, 45],\n       [27, 44],\n       [26, 42],\n       [14, 35],\n       [14, 30],\n       [26, 24],\n       [33, 23],\n       [36, 13],\n       [53, 4],\n       [51, 0],\n       [47, -2],\n       [45, -5],\n       [50, -11],\n       [59, -14],\n       [60, -19],\n       [55, -20],\n       [49, -29],\n       [38, -30],\n       [14, -44],\n       [7, -49],\n       [0, -66],\n       [-15, -80],\n       [-80, -80],\n       [-80, 194]]]},\n    'properties': {'STATE_FIPS': '24',\n     'COUNTY_FIP': '041',\n     'FIPS': '24041',\n     'STATE': 'MD',\n     'NAME': 'Talbot',\n     'LSAD': 'County'},\n    'id': 2156,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[478, 3725],\n       [484, 3712],\n       [485, 3703],\n       [482, 3694],\n       [487, 3684],\n       [486, 3666],\n       [489, 3653],\n       [496, 3641],\n       [502, 3627],\n       [509, 3622],\n       [528, 3625],\n       [533, 3621],\n       [538, 3607],\n       [543, 3602],\n       [552, 3597],\n       [558, 3598],\n       [571, 3604],\n       [576, 3611],\n       [578, 3626],\n       [583, 3630],\n       [593, 3627],\n       [598, 3623],\n       [599, 3618],\n       [600, 3595],\n       [605, 3582],\n       [622, 3548],\n       [633, 3537],\n       [640, 3517],\n       [643, 3515],\n       [653, 3511],\n       [659, 3502],\n       [661, 3494],\n       [661, 3481],\n       [664, 3472],\n       [739, 3508],\n       [739, 3497],\n       [783, 3442],\n       [795, 3430],\n       [801, 3429],\n       [800, 3418],\n       [807, 3411],\n       [806, 3404],\n       [808, 3398],\n       [811, 3398],\n       [813, 3394],\n       [799, 3393],\n       [795, 3359],\n       [777, 3330],\n       [777, 3328],\n       [880, 3245],\n       [769, 3151],\n       [660, 3017],\n       [165, 3428],\n       [67, 3514],\n       [120, 3544],\n       [135, 3544],\n       [189, 3572],\n       [205, 3590],\n       [230, 3605],\n       [232, 3613],\n       [250, 3617],\n       [262, 3625],\n       [281, 3635],\n       [282, 3641],\n       [289, 3642],\n       [299, 3656],\n       [304, 3661],\n       [342, 3677],\n       [354, 3692],\n       [380, 3701],\n       [478, 3725]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '077',\n     'FIPS': '42077',\n     'STATE': 'PA',\n     'NAME': 'Lehigh',\n     'LSAD': 'County'},\n    'id': 2212,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[67, 3514],\n       [165, 3428],\n       [594, 3072],\n       [351, 2680],\n       [283, 2632],\n       [93, 2480],\n       [0, 2560],\n       [-25, 2581],\n       [-80, 2627],\n       [-80, 3442],\n       [0, 3481],\n       [67, 3514]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '011',\n     'FIPS': '42011',\n     'STATE': 'PA',\n     'NAME': 'Berks',\n     'LSAD': 'County'},\n    'id': 2193,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[594, 3072],\n       [660, 3017],\n       [745, 2952],\n       [937, 2799],\n       [1053, 2710],\n       [1176, 2612],\n       [1343, 2482],\n       [1335, 2471],\n       [1280, 2421],\n       [1252, 2383],\n       [1245, 2377],\n       [1239, 2369],\n       [1224, 2351],\n       [1238, 2340],\n       [1228, 2327],\n       [1210, 2313],\n       [1206, 2307],\n       [1108, 2381],\n       [1091, 2358],\n       [1040, 2396],\n       [980, 2322],\n       [987, 2313],\n       [1002, 2299],\n       [1007, 2292],\n       [1018, 2281],\n       [1027, 2273],\n       [1048, 2259],\n       [1056, 2249],\n       [1065, 2242],\n       [1063, 2239],\n       [963, 2176],\n       [952, 2195],\n       [912, 2257],\n       [898, 2250],\n       [846, 2340],\n       [841, 2345],\n       [839, 2344],\n       [831, 2357],\n       [794, 2335],\n       [754, 2404],\n       [728, 2390],\n       [723, 2399],\n       [701, 2386],\n       [700, 2400],\n       [691, 2405],\n       [693, 2416],\n       [690, 2416],\n       [682, 2423],\n       [679, 2432],\n       [682, 2441],\n       [692, 2447],\n       [694, 2452],\n       [693, 2457],\n       [677, 2466],\n       [665, 2461],\n       [648, 2460],\n       [629, 2472],\n       [624, 2479],\n       [621, 2488],\n       [625, 2498],\n       [635, 2512],\n       [636, 2519],\n       [633, 2522],\n       [624, 2524],\n       [620, 2522],\n       [614, 2514],\n       [610, 2502],\n       [607, 2500],\n       [602, 2501],\n       [598, 2504],\n       [597, 2511],\n       [598, 2521],\n       [595, 2538],\n       [591, 2544],\n       [580, 2553],\n       [576, 2558],\n       [566, 2580],\n       [555, 2613],\n       [549, 2619],\n       [544, 2618],\n       [543, 2612],\n       [546, 2604],\n       [546, 2596],\n       [539, 2589],\n       [535, 2589],\n       [530, 2591],\n       [522, 2602],\n       [519, 2612],\n       [510, 2627],\n       [496, 2670],\n       [491, 2673],\n       [487, 2673],\n       [483, 2671],\n       [481, 2669],\n       [481, 2664],\n       [487, 2654],\n       [487, 2652],\n       [483, 2648],\n       [474, 2644],\n       [468, 2648],\n       [463, 2658],\n       [428, 2674],\n       [419, 2680],\n       [411, 2679],\n       [406, 2680],\n       [398, 2686],\n       [388, 2685],\n       [381, 2681],\n       [367, 2670],\n       [360, 2670],\n       [351, 2680],\n       [594, 3072]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '091',\n     'FIPS': '42091',\n     'STATE': 'PA',\n     'NAME': 'Montgomery',\n     'LSAD': 'County'},\n    'id': 2198,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[398, 2686],\n        [406, 2680],\n        [411, 2679],\n        [419, 2680],\n        [428, 2674],\n        [463, 2658],\n        [468, 2648],\n        [474, 2644],\n        [483, 2648],\n        [487, 2652],\n        [487, 2654],\n        [481, 2664],\n        [481, 2669],\n        [483, 2671],\n        [487, 2673],\n        [491, 2673],\n        [496, 2670],\n        [510, 2627],\n        [519, 2612],\n        [521, 2604],\n        [525, 2597],\n        [535, 2589],\n        [539, 2589],\n        [546, 2596],\n        [546, 2604],\n        [543, 2612],\n        [544, 2618],\n        [549, 2619],\n        [555, 2613],\n        [566, 2580],\n        [576, 2558],\n        [580, 2553],\n        [591, 2544],\n        [595, 2538],\n        [598, 2521],\n        [597, 2511],\n        [598, 2504],\n        [602, 2501],\n        [607, 2500],\n        [610, 2502],\n        [614, 2514],\n        [620, 2522],\n        [624, 2524],\n        [633, 2522],\n        [636, 2519],\n        [635, 2512],\n        [625, 2498],\n        [621, 2488],\n        [624, 2479],\n        [629, 2472],\n        [648, 2460],\n        [665, 2461],\n        [677, 2466],\n        [693, 2457],\n        [694, 2452],\n        [692, 2447],\n        [682, 2441],\n        [679, 2432],\n        [682, 2423],\n        [690, 2416],\n        [693, 2416],\n        [691, 2405],\n        [700, 2400],\n        [701, 2386],\n        [723, 2399],\n        [728, 2390],\n        [754, 2404],\n        [794, 2335],\n        [831, 2357],\n        [839, 2344],\n        [761, 2299],\n        [776, 2272],\n        [705, 2207],\n        [720, 2208],\n        [724, 2206],\n        [728, 2208],\n        [727, 2204],\n        [731, 2198],\n        [730, 2191],\n        [602, 2113],\n        [609, 2103],\n        [610, 2095],\n        [601, 2090],\n        [599, 2096],\n        [593, 2093],\n        [594, 2091],\n        [593, 2090],\n        [603, 2073],\n        [600, 2071],\n        [598, 2074],\n        [593, 2072],\n        [585, 2086],\n        [575, 2081],\n        [577, 2077],\n        [573, 2074],\n        [573, 2068],\n        [575, 2064],\n        [564, 2058],\n        [570, 2048],\n        [555, 2040],\n        [552, 2046],\n        [548, 2044],\n        [551, 2035],\n        [530, 2023],\n        [532, 2017],\n        [529, 2015],\n        [534, 2007],\n        [520, 1999],\n        [517, 2002],\n        [510, 2000],\n        [514, 1993],\n        [495, 1981],\n        [501, 1972],\n        [502, 1967],\n        [498, 1966],\n        [496, 1962],\n        [497, 1959],\n        [489, 1947],\n        [490, 1945],\n        [493, 1943],\n        [503, 1939],\n        [503, 1937],\n        [500, 1935],\n        [499, 1925],\n        [495, 1918],\n        [495, 1915],\n        [499, 1911],\n        [466, 1904],\n        [431, 1894],\n        [400, 1880],\n        [366, 1861],\n        [344, 1845],\n        [306, 1810],\n        [281, 1779],\n        [258, 1740],\n        [239, 1693],\n        [217, 1692],\n        [0, 1691],\n        [-80, 1691],\n        [-80, 1971],\n        [-79, 1970],\n        [-77, 1974],\n        [-72, 1979],\n        [-72, 1982],\n        [-74, 1988],\n        [-80, 1996],\n        [-77, 2000],\n        [-79, 2001],\n        [-78, 2006],\n        [-76, 2012],\n        [-72, 2015],\n        [-73, 2020],\n        [-80, 2026],\n        [-80, 2080],\n        [-78, 2081],\n        [-79, 2085],\n        [-73, 2086],\n        [-69, 2090],\n        [-64, 2086],\n        [-63, 2093],\n        [-65, 2097],\n        [-74, 2105],\n        [-77, 2115],\n        [-80, 2117],\n        [-78, 2120],\n        [-80, 2123],\n        [-80, 2134],\n        [-77, 2142],\n        [-71, 2150],\n        [-72, 2157],\n        [0, 2287],\n        [3, 2293],\n        [5, 2310],\n        [2, 2342],\n        [2, 2369],\n        [0, 2380],\n        [-8, 2427],\n        [0, 2431],\n        [69, 2466],\n        [93, 2480],\n        [283, 2632],\n        [351, 2680],\n        [360, 2670],\n        [367, 2670],\n        [381, 2681],\n        [388, 2685],\n        [398, 2686]]],\n      [[[512, 1924],\n        [518, 1918],\n        [521, 1913],\n        [502, 1911],\n        [506, 1921],\n        [512, 1924]]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '029',\n     'FIPS': '42029',\n     'STATE': 'PA',\n     'NAME': 'Chester',\n     'LSAD': 'County'},\n    'id': 2187,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[841, 2345],\n       [846, 2340],\n       [898, 2250],\n       [912, 2257],\n       [952, 2195],\n       [963, 2176],\n       [957, 2172],\n       [959, 2167],\n       [964, 2161],\n       [972, 2160],\n       [979, 2153],\n       [986, 2155],\n       [991, 2151],\n       [995, 2154],\n       [1004, 2151],\n       [1004, 2146],\n       [1000, 2142],\n       [1003, 2138],\n       [1002, 2135],\n       [999, 2128],\n       [1001, 2118],\n       [1006, 2112],\n       [1016, 2109],\n       [1016, 2102],\n       [1020, 2102],\n       [1023, 2101],\n       [1020, 2092],\n       [1013, 2093],\n       [1009, 2087],\n       [1011, 2086],\n       [1011, 2082],\n       [1005, 2071],\n       [1006, 2056],\n       [999, 2049],\n       [1001, 2045],\n       [996, 2040],\n       [999, 2038],\n       [993, 2029],\n       [994, 2027],\n       [990, 2021],\n       [992, 2020],\n       [988, 2015],\n       [984, 2014],\n       [983, 2008],\n       [980, 2007],\n       [983, 2002],\n       [980, 2001],\n       [983, 1996],\n       [980, 1996],\n       [983, 1985],\n       [1004, 1985],\n       [1015, 1977],\n       [1023, 1986],\n       [1045, 1983],\n       [1051, 1984],\n       [1051, 1975],\n       [1058, 1964],\n       [1043, 1956],\n       [1023, 1947],\n       [970, 1934],\n       [938, 1932],\n       [914, 1935],\n       [895, 1934],\n       [884, 1933],\n       [868, 1927],\n       [849, 1916],\n       [797, 1869],\n       [761, 1843],\n       [742, 1857],\n       [705, 1878],\n       [664, 1895],\n       [639, 1903],\n       [610, 1909],\n       [580, 1912],\n       [535, 1914],\n       [521, 1913],\n       [518, 1918],\n       [512, 1924],\n       [508, 1922],\n       [502, 1911],\n       [499, 1911],\n       [495, 1915],\n       [495, 1918],\n       [499, 1925],\n       [500, 1935],\n       [503, 1937],\n       [503, 1939],\n       [493, 1943],\n       [490, 1945],\n       [489, 1947],\n       [497, 1959],\n       [496, 1962],\n       [498, 1966],\n       [502, 1967],\n       [501, 1972],\n       [495, 1981],\n       [514, 1993],\n       [510, 2000],\n       [517, 2002],\n       [520, 1999],\n       [534, 2007],\n       [529, 2015],\n       [532, 2017],\n       [530, 2023],\n       [551, 2035],\n       [548, 2044],\n       [552, 2046],\n       [555, 2040],\n       [570, 2048],\n       [564, 2058],\n       [575, 2064],\n       [573, 2068],\n       [573, 2074],\n       [577, 2077],\n       [575, 2081],\n       [585, 2086],\n       [593, 2072],\n       [598, 2074],\n       [600, 2071],\n       [603, 2073],\n       [593, 2090],\n       [594, 2091],\n       [593, 2093],\n       [599, 2096],\n       [601, 2090],\n       [610, 2095],\n       [609, 2103],\n       [602, 2113],\n       [730, 2191],\n       [731, 2198],\n       [727, 2204],\n       [728, 2208],\n       [724, 2206],\n       [720, 2208],\n       [705, 2207],\n       [776, 2272],\n       [761, 2299],\n       [841, 2345]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '045',\n     'FIPS': '42045',\n     'STATE': 'PA',\n     'NAME': 'Delaware',\n     'LSAD': 'County'},\n    'id': 2186,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1190, 4074],\n       [1191, 4070],\n       [1190, 4065],\n       [1194, 4044],\n       [1203, 4035],\n       [1211, 4018],\n       [1212, 4012],\n       [1226, 3989],\n       [1250, 3969],\n       [1255, 3956],\n       [1256, 3931],\n       [1270, 3914],\n       [1280, 3899],\n       [1287, 3891],\n       [1290, 3885],\n       [1291, 3876],\n       [1288, 3865],\n       [1272, 3842],\n       [1269, 3841],\n       [1262, 3841],\n       [1254, 3845],\n       [1233, 3844],\n       [1226, 3840],\n       [1223, 3832],\n       [1224, 3825],\n       [1241, 3807],\n       [1243, 3803],\n       [1243, 3797],\n       [1234, 3780],\n       [1225, 3773],\n       [1219, 3764],\n       [1219, 3749],\n       [1207, 3732],\n       [1203, 3730],\n       [1195, 3729],\n       [1186, 3724],\n       [1174, 3703],\n       [1170, 3699],\n       [1148, 3701],\n       [1127, 3708],\n       [1118, 3708],\n       [1115, 3707],\n       [1110, 3697],\n       [1107, 3681],\n       [1105, 3676],\n       [1099, 3671],\n       [1086, 3664],\n       [1079, 3656],\n       [1081, 3645],\n       [1095, 3629],\n       [1100, 3618],\n       [1089, 3592],\n       [1082, 3584],\n       [1068, 3541],\n       [1073, 3529],\n       [1079, 3521],\n       [1088, 3518],\n       [1097, 3519],\n       [1102, 3518],\n       [1107, 3514],\n       [1108, 3511],\n       [1107, 3505],\n       [1099, 3492],\n       [1087, 3484],\n       [1073, 3460],\n       [1073, 3455],\n       [1085, 3444],\n       [1091, 3412],\n       [1088, 3404],\n       [1077, 3402],\n       [1071, 3398],\n       [1072, 3393],\n       [1079, 3382],\n       [992, 3332],\n       [977, 3322],\n       [938, 3292],\n       [880, 3244],\n       [777, 3328],\n       [777, 3330],\n       [795, 3359],\n       [799, 3393],\n       [813, 3394],\n       [811, 3398],\n       [808, 3398],\n       [806, 3404],\n       [807, 3411],\n       [800, 3418],\n       [801, 3429],\n       [795, 3430],\n       [783, 3442],\n       [739, 3497],\n       [739, 3508],\n       [664, 3472],\n       [661, 3481],\n       [661, 3494],\n       [659, 3502],\n       [653, 3511],\n       [643, 3515],\n       [640, 3517],\n       [633, 3537],\n       [622, 3548],\n       [605, 3582],\n       [600, 3595],\n       [599, 3618],\n       [598, 3623],\n       [593, 3627],\n       [583, 3630],\n       [578, 3626],\n       [576, 3611],\n       [571, 3604],\n       [558, 3598],\n       [552, 3597],\n       [543, 3602],\n       [538, 3607],\n       [533, 3621],\n       [528, 3625],\n       [509, 3622],\n       [502, 3627],\n       [496, 3641],\n       [489, 3653],\n       [486, 3666],\n       [487, 3684],\n       [482, 3694],\n       [485, 3703],\n       [484, 3712],\n       [478, 3725],\n       [488, 3726],\n       [494, 3730],\n       [498, 3737],\n       [524, 3748],\n       [553, 3752],\n       [562, 3758],\n       [577, 3763],\n       [596, 3762],\n       [609, 3766],\n       [625, 3767],\n       [668, 3775],\n       [675, 3778],\n       [721, 3785],\n       [753, 3795],\n       [758, 3800],\n       [807, 3809],\n       [868, 3837],\n       [898, 3857],\n       [928, 3864],\n       [952, 3877],\n       [967, 3890],\n       [976, 3908],\n       [1027, 3941],\n       [1014, 3960],\n       [1042, 3980],\n       [1048, 3996],\n       [1081, 4012],\n       [1092, 4014],\n       [1106, 4020],\n       [1108, 4030],\n       [1119, 4035],\n       [1143, 4037],\n       [1154, 4041],\n       [1177, 4056],\n       [1190, 4074]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '095',\n     'FIPS': '42095',\n     'STATE': 'PA',\n     'NAME': 'Northampton',\n     'LSAD': 'County'},\n    'id': 2208,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1978, 4176],\n       [1938, 4131],\n       [1910, 4096],\n       [1889, 4068],\n       [1888, 4056],\n       [1897, 4040],\n       [1897, 4029],\n       [1889, 4014],\n       [1873, 4001],\n       [1871, 3998],\n       [1870, 3992],\n       [1872, 3987],\n       [1871, 3984],\n       [1855, 3977],\n       [1846, 3969],\n       [1832, 3960],\n       [1827, 3961],\n       [1820, 3959],\n       [1818, 3952],\n       [1814, 3951],\n       [1808, 3954],\n       [1796, 3946],\n       [1792, 3945],\n       [1786, 3940],\n       [1782, 3942],\n       [1785, 3951],\n       [1783, 3958],\n       [1769, 3970],\n       [1761, 3974],\n       [1756, 3982],\n       [1749, 3979],\n       [1734, 3980],\n       [1727, 3976],\n       [1727, 3972],\n       [1722, 3968],\n       [1715, 3968],\n       [1713, 3965],\n       [1711, 3968],\n       [1708, 3965],\n       [1706, 3966],\n       [1703, 3965],\n       [1594, 4096],\n       [1570, 4125],\n       [1529, 4176],\n       [1978, 4176]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '037',\n     'FIPS': '34037',\n     'STATE': 'NJ',\n     'NAME': 'Sussex',\n     'LSAD': 'County'},\n    'id': 2225,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1526, 3726],\n       [1592, 3670],\n       [1594, 3665],\n       [1617, 3642],\n       [1622, 3639],\n       [1633, 3639],\n       [1638, 3638],\n       [1638, 3636],\n       [1644, 3636],\n       [1659, 3638],\n       [1666, 3634],\n       [1704, 3625],\n       [1725, 3617],\n       [1740, 3607],\n       [1740, 3603],\n       [1755, 3595],\n       [1767, 3595],\n       [1768, 3590],\n       [1773, 3586],\n       [1772, 3582],\n       [1774, 3569],\n       [1777, 3567],\n       [1778, 3565],\n       [1776, 3564],\n       [1779, 3558],\n       [1778, 3555],\n       [1772, 3550],\n       [1771, 3541],\n       [1768, 3533],\n       [1776, 3526],\n       [1775, 3519],\n       [1771, 3515],\n       [1769, 3500],\n       [1764, 3494],\n       [1757, 3491],\n       [1762, 3478],\n       [1769, 3474],\n       [1774, 3465],\n       [1768, 3455],\n       [1767, 3450],\n       [1770, 3446],\n       [1769, 3440],\n       [1762, 3434],\n       [1765, 3426],\n       [1774, 3425],\n       [1778, 3426],\n       [1783, 3424],\n       [1786, 3418],\n       [1786, 3413],\n       [1797, 3406],\n       [1786, 3387],\n       [1783, 3389],\n       [1771, 3366],\n       [1775, 3364],\n       [1766, 3344],\n       [1783, 3335],\n       [1766, 3300],\n       [1758, 3295],\n       [1751, 3286],\n       [1740, 3277],\n       [1693, 3182],\n       [1690, 3180],\n       [1685, 3182],\n       [1678, 3190],\n       [1678, 3193],\n       [1674, 3197],\n       [1660, 3203],\n       [1732, 3028],\n       [1644, 3014],\n       [1654, 2953],\n       [1555, 2940],\n       [1575, 2880],\n       [1464, 2866],\n       [1448, 2871],\n       [1447, 2872],\n       [1444, 2901],\n       [1440, 2915],\n       [1433, 2936],\n       [1416, 2977],\n       [1410, 2982],\n       [1390, 2991],\n       [1381, 2999],\n       [1371, 3002],\n       [1360, 2997],\n       [1340, 2991],\n       [1329, 2989],\n       [1324, 2990],\n       [1312, 2995],\n       [1298, 3009],\n       [1284, 3013],\n       [1280, 3017],\n       [1276, 3026],\n       [1274, 3046],\n       [1267, 3075],\n       [1263, 3088],\n       [1267, 3106],\n       [1267, 3122],\n       [1272, 3129],\n       [1275, 3138],\n       [1275, 3147],\n       [1269, 3194],\n       [1271, 3224],\n       [1269, 3244],\n       [1265, 3254],\n       [1251, 3266],\n       [1219, 3304],\n       [1195, 3314],\n       [1166, 3319],\n       [1159, 3318],\n       [1151, 3314],\n       [1135, 3299],\n       [1128, 3296],\n       [1120, 3296],\n       [1110, 3298],\n       [1099, 3303],\n       [1093, 3307],\n       [1083, 3320],\n       [1081, 3326],\n       [1082, 3331],\n       [1087, 3340],\n       [1088, 3349],\n       [1096, 3351],\n       [1102, 3355],\n       [1104, 3361],\n       [1111, 3363],\n       [1114, 3375],\n       [1120, 3378],\n       [1124, 3385],\n       [1128, 3387],\n       [1130, 3393],\n       [1129, 3399],\n       [1141, 3407],\n       [1147, 3405],\n       [1150, 3408],\n       [1150, 3416],\n       [1153, 3420],\n       [1168, 3424],\n       [1180, 3431],\n       [1205, 3440],\n       [1208, 3442],\n       [1207, 3447],\n       [1211, 3451],\n       [1226, 3458],\n       [1235, 3468],\n       [1236, 3472],\n       [1247, 3476],\n       [1254, 3488],\n       [1264, 3494],\n       [1267, 3497],\n       [1275, 3499],\n       [1278, 3505],\n       [1282, 3510],\n       [1288, 3512],\n       [1295, 3518],\n       [1301, 3516],\n       [1303, 3517],\n       [1308, 3524],\n       [1310, 3526],\n       [1315, 3526],\n       [1333, 3542],\n       [1337, 3542],\n       [1341, 3547],\n       [1345, 3543],\n       [1351, 3547],\n       [1356, 3544],\n       [1361, 3545],\n       [1378, 3563],\n       [1393, 3569],\n       [1396, 3578],\n       [1410, 3577],\n       [1419, 3597],\n       [1424, 3602],\n       [1426, 3606],\n       [1435, 3610],\n       [1443, 3624],\n       [1451, 3631],\n       [1452, 3636],\n       [1465, 3651],\n       [1467, 3656],\n       [1470, 3658],\n       [1473, 3663],\n       [1485, 3672],\n       [1489, 3677],\n       [1489, 3680],\n       [1494, 3686],\n       [1507, 3695],\n       [1506, 3698],\n       [1507, 3706],\n       [1505, 3712],\n       [1517, 3719],\n       [1526, 3726]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '019',\n     'FIPS': '34019',\n     'STATE': 'NJ',\n     'NAME': 'Hunterdon',\n     'LSAD': 'County'},\n    'id': 2209,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2012, 3669],\n       [2018, 3663],\n       [2019, 3655],\n       [2017, 3652],\n       [2023, 3646],\n       [2022, 3622],\n       [2026, 3623],\n       [2028, 3621],\n       [2035, 3622],\n       [2043, 3616],\n       [2046, 3617],\n       [2052, 3611],\n       [2048, 3598],\n       [2048, 3595],\n       [2051, 3594],\n       [2052, 3591],\n       [2058, 3587],\n       [2057, 3581],\n       [2054, 3578],\n       [2056, 3575],\n       [2061, 3574],\n       [2068, 3568],\n       [2069, 3561],\n       [2071, 3561],\n       [2073, 3559],\n       [2073, 3547],\n       [2070, 3544],\n       [2067, 3545],\n       [2066, 3541],\n       [2069, 3539],\n       [2069, 3537],\n       [2062, 3535],\n       [2058, 3537],\n       [2055, 3529],\n       [2053, 3527],\n       [2052, 3521],\n       [2056, 3501],\n       [2051, 3498],\n       [2050, 3495],\n       [2043, 3494],\n       [2044, 3491],\n       [2050, 3490],\n       [2051, 3486],\n       [2056, 3482],\n       [2054, 3479],\n       [2056, 3469],\n       [2059, 3469],\n       [2055, 3465],\n       [2060, 3464],\n       [2061, 3461],\n       [2070, 3462],\n       [2071, 3463],\n       [2075, 3460],\n       [2082, 3466],\n       [2086, 3475],\n       [2085, 3477],\n       [2088, 3480],\n       [2091, 3478],\n       [2095, 3479],\n       [2094, 3483],\n       [2100, 3484],\n       [2102, 3482],\n       [2106, 3484],\n       [2106, 3487],\n       [2112, 3488],\n       [2114, 3485],\n       [2117, 3487],\n       [2116, 3491],\n       [2128, 3493],\n       [2133, 3498],\n       [2137, 3496],\n       [2149, 3503],\n       [2150, 3506],\n       [2164, 3469],\n       [2175, 3475],\n       [2185, 3486],\n       [2196, 3491],\n       [2198, 3487],\n       [2202, 3485],\n       [2208, 3477],\n       [2211, 3478],\n       [2214, 3483],\n       [2220, 3485],\n       [2224, 3491],\n       [2231, 3495],\n       [2234, 3493],\n       [2236, 3487],\n       [2235, 3481],\n       [2235, 3473],\n       [2229, 3462],\n       [2229, 3455],\n       [2226, 3447],\n       [2220, 3446],\n       [2219, 3444],\n       [2217, 3429],\n       [2213, 3418],\n       [2206, 3414],\n       [2205, 3405],\n       [2199, 3397],\n       [2193, 3396],\n       [2184, 3385],\n       [2173, 3383],\n       [2169, 3381],\n       [2164, 3373],\n       [2159, 3373],\n       [2152, 3365],\n       [2143, 3362],\n       [2137, 3362],\n       [2126, 3354],\n       [2118, 3345],\n       [2108, 3340],\n       [2104, 3341],\n       [2097, 3338],\n       [2094, 3340],\n       [2091, 3337],\n       [2091, 3334],\n       [2086, 3339],\n       [2076, 3331],\n       [2070, 3329],\n       [2071, 3326],\n       [2063, 3315],\n       [2059, 3307],\n       [2056, 3305],\n       [2057, 3292],\n       [2054, 3288],\n       [2059, 3286],\n       [2065, 3280],\n       [2068, 3273],\n       [2072, 3255],\n       [2083, 3244],\n       [2100, 3230],\n       [2119, 3197],\n       [2122, 3195],\n       [2141, 3190],\n       [2143, 3178],\n       [2151, 3171],\n       [2153, 3166],\n       [2152, 3156],\n       [2140, 3148],\n       [2125, 3143],\n       [2119, 3139],\n       [2102, 3115],\n       [2082, 3099],\n       [2075, 3091],\n       [2064, 3080],\n       [2055, 3068],\n       [2041, 3056],\n       [2013, 3040],\n       [1971, 3018],\n       [1968, 3014],\n       [1969, 2989],\n       [1966, 2981],\n       [1966, 2971],\n       [1960, 2967],\n       [1955, 2956],\n       [1944, 2945],\n       [1928, 2936],\n       [1919, 2933],\n       [1922, 2940],\n       [1921, 2944],\n       [1915, 2952],\n       [1870, 2965],\n       [1839, 2952],\n       [1791, 2943],\n       [1770, 2935],\n       [1660, 3203],\n       [1674, 3197],\n       [1678, 3193],\n       [1678, 3190],\n       [1685, 3182],\n       [1692, 3180],\n       [1740, 3277],\n       [1751, 3286],\n       [1758, 3295],\n       [1766, 3300],\n       [1783, 3335],\n       [1766, 3344],\n       [1775, 3364],\n       [1771, 3366],\n       [1783, 3389],\n       [1786, 3387],\n       [1797, 3406],\n       [1786, 3413],\n       [1786, 3418],\n       [1783, 3424],\n       [1778, 3426],\n       [1774, 3425],\n       [1765, 3426],\n       [1762, 3434],\n       [1769, 3440],\n       [1770, 3446],\n       [1767, 3450],\n       [1768, 3455],\n       [1774, 3465],\n       [1769, 3474],\n       [1762, 3478],\n       [1757, 3491],\n       [1764, 3494],\n       [1769, 3500],\n       [1771, 3515],\n       [1775, 3519],\n       [1776, 3526],\n       [1768, 3533],\n       [1771, 3541],\n       [1772, 3550],\n       [1778, 3555],\n       [1779, 3558],\n       [1776, 3564],\n       [1778, 3565],\n       [1777, 3567],\n       [1774, 3569],\n       [1772, 3582],\n       [1773, 3586],\n       [1768, 3590],\n       [1767, 3595],\n       [1848, 3621],\n       [2012, 3669]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '035',\n     'FIPS': '34035',\n     'STATE': 'NJ',\n     'NAME': 'Somerset',\n     'LSAD': 'County'},\n    'id': 2211,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1079, 3382],\n       [1085, 3370],\n       [1088, 3347],\n       [1087, 3340],\n       [1082, 3331],\n       [1082, 3324],\n       [1085, 3316],\n       [1099, 3303],\n       [1110, 3298],\n       [1128, 3296],\n       [1135, 3299],\n       [1151, 3314],\n       [1159, 3318],\n       [1166, 3319],\n       [1195, 3314],\n       [1219, 3304],\n       [1251, 3266],\n       [1265, 3254],\n       [1269, 3244],\n       [1271, 3224],\n       [1269, 3194],\n       [1275, 3147],\n       [1275, 3138],\n       [1272, 3129],\n       [1267, 3122],\n       [1267, 3106],\n       [1263, 3088],\n       [1267, 3075],\n       [1274, 3046],\n       [1276, 3026],\n       [1280, 3017],\n       [1284, 3013],\n       [1298, 3009],\n       [1312, 2995],\n       [1324, 2990],\n       [1329, 2989],\n       [1340, 2991],\n       [1360, 2997],\n       [1371, 3002],\n       [1381, 2999],\n       [1390, 2991],\n       [1410, 2982],\n       [1416, 2977],\n       [1433, 2936],\n       [1440, 2915],\n       [1444, 2901],\n       [1447, 2872],\n       [1453, 2864],\n       [1499, 2823],\n       [1506, 2821],\n       [1516, 2820],\n       [1523, 2816],\n       [1539, 2802],\n       [1557, 2782],\n       [1569, 2762],\n       [1595, 2697],\n       [1604, 2688],\n       [1622, 2679],\n       [1628, 2674],\n       [1663, 2656],\n       [1698, 2630],\n       [1714, 2598],\n       [1723, 2572],\n       [1727, 2568],\n       [1738, 2564],\n       [1748, 2558],\n       [1770, 2525],\n       [1771, 2512],\n       [1767, 2499],\n       [1743, 2477],\n       [1735, 2475],\n       [1722, 2476],\n       [1716, 2475],\n       [1701, 2465],\n       [1683, 2449],\n       [1673, 2449],\n       [1656, 2453],\n       [1633, 2462],\n       [1624, 2461],\n       [1619, 2455],\n       [1615, 2448],\n       [1609, 2432],\n       [1605, 2417],\n       [1601, 2411],\n       [1593, 2405],\n       [1577, 2397],\n       [1572, 2388],\n       [1570, 2381],\n       [1564, 2376],\n       [1540, 2369],\n       [1529, 2364],\n       [1498, 2353],\n       [1481, 2355],\n       [1474, 2354],\n       [1446, 2340],\n       [1403, 2312],\n       [1394, 2322],\n       [1389, 2323],\n       [1388, 2329],\n       [1394, 2334],\n       [1394, 2345],\n       [1405, 2356],\n       [1408, 2365],\n       [1420, 2368],\n       [1426, 2380],\n       [1426, 2390],\n       [1429, 2397],\n       [1429, 2402],\n       [1421, 2406],\n       [1422, 2416],\n       [1416, 2425],\n       [1418, 2428],\n       [1419, 2438],\n       [1418, 2443],\n       [1414, 2444],\n       [1409, 2442],\n       [1404, 2448],\n       [1395, 2447],\n       [1390, 2450],\n       [1390, 2454],\n       [1384, 2454],\n       [1379, 2460],\n       [1374, 2460],\n       [1377, 2469],\n       [1375, 2471],\n       [1368, 2463],\n       [1184, 2606],\n       [1065, 2701],\n       [937, 2799],\n       [745, 2952],\n       [660, 3017],\n       [769, 3151],\n       [872, 3239],\n       [880, 3244],\n       [938, 3292],\n       [977, 3322],\n       [992, 3332],\n       [1079, 3382]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '017',\n     'FIPS': '42017',\n     'STATE': 'PA',\n     'NAME': 'Bucks',\n     'LSAD': 'County'},\n    'id': 2197,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1343, 2482],\n       [1368, 2463],\n       [1375, 2471],\n       [1377, 2469],\n       [1374, 2460],\n       [1379, 2460],\n       [1384, 2454],\n       [1390, 2454],\n       [1390, 2450],\n       [1395, 2447],\n       [1404, 2448],\n       [1409, 2442],\n       [1414, 2444],\n       [1418, 2443],\n       [1419, 2438],\n       [1418, 2428],\n       [1416, 2425],\n       [1422, 2416],\n       [1421, 2406],\n       [1429, 2402],\n       [1429, 2397],\n       [1426, 2390],\n       [1426, 2380],\n       [1420, 2368],\n       [1408, 2365],\n       [1405, 2356],\n       [1394, 2345],\n       [1394, 2334],\n       [1388, 2329],\n       [1389, 2323],\n       [1394, 2322],\n       [1403, 2312],\n       [1389, 2301],\n       [1349, 2260],\n       [1308, 2244],\n       [1297, 2236],\n       [1291, 2228],\n       [1279, 2205],\n       [1260, 2183],\n       [1236, 2172],\n       [1208, 2163],\n       [1180, 2146],\n       [1171, 2133],\n       [1168, 2119],\n       [1167, 2094],\n       [1169, 2081],\n       [1179, 2052],\n       [1175, 2030],\n       [1158, 2004],\n       [1154, 2000],\n       [1146, 1997],\n       [1099, 1995],\n       [1090, 1993],\n       [1058, 1964],\n       [1051, 1975],\n       [1051, 1984],\n       [1045, 1983],\n       [1023, 1986],\n       [1015, 1977],\n       [1004, 1985],\n       [983, 1985],\n       [980, 1996],\n       [983, 1996],\n       [980, 2001],\n       [983, 2002],\n       [980, 2007],\n       [983, 2008],\n       [984, 2014],\n       [988, 2015],\n       [992, 2020],\n       [990, 2021],\n       [994, 2027],\n       [993, 2029],\n       [999, 2038],\n       [996, 2040],\n       [1001, 2045],\n       [999, 2049],\n       [1006, 2056],\n       [1005, 2071],\n       [1011, 2082],\n       [1011, 2086],\n       [1009, 2087],\n       [1013, 2093],\n       [1020, 2092],\n       [1023, 2101],\n       [1020, 2102],\n       [1016, 2102],\n       [1016, 2109],\n       [1006, 2112],\n       [1001, 2118],\n       [999, 2128],\n       [1002, 2135],\n       [1003, 2138],\n       [1000, 2142],\n       [1004, 2146],\n       [1004, 2151],\n       [995, 2154],\n       [991, 2151],\n       [986, 2155],\n       [979, 2153],\n       [972, 2160],\n       [964, 2161],\n       [957, 2172],\n       [982, 2187],\n       [993, 2196],\n       [1063, 2239],\n       [1065, 2242],\n       [1056, 2249],\n       [1048, 2259],\n       [1027, 2273],\n       [1018, 2281],\n       [1007, 2292],\n       [1002, 2299],\n       [987, 2313],\n       [980, 2322],\n       [1040, 2396],\n       [1091, 2358],\n       [1108, 2381],\n       [1206, 2307],\n       [1210, 2313],\n       [1228, 2327],\n       [1238, 2340],\n       [1224, 2351],\n       [1239, 2369],\n       [1245, 2377],\n       [1252, 2383],\n       [1280, 2421],\n       [1335, 2471],\n       [1343, 2482]]]},\n    'properties': {'STATE_FIPS': '42',\n     'COUNTY_FIP': '101',\n     'FIPS': '42101',\n     'STATE': 'PA',\n     'NAME': 'Philadelphia',\n     'LSAD': 'County'},\n    'id': 2177,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1732, 3028],\n       [1770, 2935],\n       [1791, 2943],\n       [1839, 2952],\n       [1870, 2965],\n       [1915, 2952],\n       [1921, 2944],\n       [1922, 2940],\n       [1916, 2919],\n       [1912, 2916],\n       [1904, 2878],\n       [1904, 2869],\n       [1914, 2857],\n       [1912, 2847],\n       [1915, 2845],\n       [1915, 2840],\n       [1916, 2838],\n       [1925, 2839],\n       [1936, 2833],\n       [1943, 2832],\n       [1947, 2821],\n       [1953, 2819],\n       [1957, 2820],\n       [1969, 2816],\n       [1972, 2803],\n       [1976, 2799],\n       [1983, 2797],\n       [1991, 2790],\n       [1995, 2791],\n       [1999, 2785],\n       [2007, 2783],\n       [2010, 2776],\n       [2016, 2773],\n       [2021, 2773],\n       [2027, 2775],\n       [2028, 2777],\n       [2032, 2775],\n       [2036, 2769],\n       [2040, 2771],\n       [2045, 2776],\n       [2052, 2780],\n       [2061, 2772],\n       [2061, 2765],\n       [2072, 2766],\n       [2077, 2759],\n       [2086, 2754],\n       [2088, 2754],\n       [2091, 2751],\n       [2095, 2754],\n       [2119, 2741],\n       [2116, 2702],\n       [2112, 2702],\n       [2112, 2700],\n       [2119, 2689],\n       [2121, 2683],\n       [2069, 2652],\n       [2031, 2632],\n       [2025, 2624],\n       [2023, 2615],\n       [2011, 2600],\n       [2002, 2581],\n       [1991, 2573],\n       [1985, 2576],\n       [1968, 2569],\n       [1957, 2562],\n       [1954, 2562],\n       [1952, 2574],\n       [1948, 2575],\n       [1927, 2567],\n       [1966, 2483],\n       [1945, 2480],\n       [1937, 2485],\n       [1938, 2487],\n       [1933, 2485],\n       [1926, 2487],\n       [1924, 2489],\n       [1920, 2487],\n       [1916, 2488],\n       [1914, 2490],\n       [1915, 2495],\n       [1914, 2497],\n       [1913, 2503],\n       [1908, 2504],\n       [1908, 2503],\n       [1904, 2503],\n       [1902, 2506],\n       [1899, 2503],\n       [1897, 2508],\n       [1893, 2509],\n       [1892, 2513],\n       [1887, 2515],\n       [1885, 2513],\n       [1880, 2517],\n       [1878, 2516],\n       [1874, 2521],\n       [1868, 2521],\n       [1867, 2524],\n       [1862, 2528],\n       [1859, 2528],\n       [1857, 2534],\n       [1853, 2533],\n       [1852, 2536],\n       [1849, 2537],\n       [1847, 2537],\n       [1846, 2534],\n       [1845, 2537],\n       [1841, 2538],\n       [1838, 2535],\n       [1835, 2536],\n       [1840, 2543],\n       [1838, 2548],\n       [1840, 2550],\n       [1832, 2550],\n       [1831, 2554],\n       [1824, 2559],\n       [1823, 2553],\n       [1822, 2557],\n       [1816, 2556],\n       [1813, 2561],\n       [1808, 2560],\n       [1810, 2567],\n       [1806, 2567],\n       [1799, 2570],\n       [1796, 2566],\n       [1790, 2566],\n       [1786, 2563],\n       [1788, 2560],\n       [1783, 2554],\n       [1786, 2549],\n       [1790, 2547],\n       [1787, 2539],\n       [1788, 2537],\n       [1796, 2541],\n       [1793, 2527],\n       [1783, 2517],\n       [1782, 2510],\n       [1774, 2501],\n       [1767, 2500],\n       [1771, 2512],\n       [1770, 2525],\n       [1748, 2558],\n       [1738, 2564],\n       [1727, 2568],\n       [1723, 2572],\n       [1714, 2598],\n       [1698, 2630],\n       [1663, 2656],\n       [1628, 2674],\n       [1622, 2679],\n       [1604, 2688],\n       [1595, 2697],\n       [1569, 2762],\n       [1557, 2782],\n       [1539, 2802],\n       [1523, 2816],\n       [1516, 2820],\n       [1506, 2821],\n       [1499, 2823],\n       [1486, 2834],\n       [1453, 2864],\n       [1448, 2871],\n       [1464, 2866],\n       [1575, 2880],\n       [1555, 2940],\n       [1654, 2953],\n       [1644, 3014],\n       [1732, 3028]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '021',\n     'FIPS': '34021',\n     'STATE': 'NJ',\n     'NAME': 'Mercer',\n     'LSAD': 'County'},\n    'id': 2196,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1799, 2570],\n       [1806, 2567],\n       [1810, 2567],\n       [1808, 2560],\n       [1813, 2561],\n       [1816, 2556],\n       [1822, 2557],\n       [1823, 2553],\n       [1824, 2559],\n       [1831, 2554],\n       [1832, 2550],\n       [1840, 2550],\n       [1838, 2548],\n       [1840, 2543],\n       [1835, 2536],\n       [1838, 2535],\n       [1841, 2538],\n       [1845, 2537],\n       [1846, 2534],\n       [1847, 2537],\n       [1849, 2537],\n       [1852, 2536],\n       [1853, 2533],\n       [1857, 2534],\n       [1859, 2528],\n       [1862, 2528],\n       [1867, 2524],\n       [1868, 2521],\n       [1874, 2521],\n       [1878, 2516],\n       [1880, 2517],\n       [1885, 2513],\n       [1887, 2515],\n       [1892, 2513],\n       [1893, 2509],\n       [1897, 2508],\n       [1899, 2503],\n       [1902, 2506],\n       [1904, 2503],\n       [1908, 2503],\n       [1908, 2504],\n       [1913, 2503],\n       [1914, 2497],\n       [1915, 2495],\n       [1914, 2490],\n       [1916, 2488],\n       [1920, 2487],\n       [1924, 2489],\n       [1926, 2487],\n       [1933, 2485],\n       [1938, 2487],\n       [1937, 2485],\n       [1945, 2480],\n       [1966, 2483],\n       [2052, 2289],\n       [2084, 2203],\n       [2167, 1994],\n       [2254, 1789],\n       [2253, 1454],\n       [2250, 1450],\n       [2244, 1432],\n       [2242, 1417],\n       [2238, 1409],\n       [2235, 1408],\n       [2232, 1404],\n       [2226, 1404],\n       [2224, 1406],\n       [2221, 1405],\n       [2216, 1405],\n       [2212, 1402],\n       [2214, 1393],\n       [2219, 1390],\n       [2214, 1380],\n       [2209, 1380],\n       [2201, 1373],\n       [2199, 1373],\n       [2191, 1377],\n       [2187, 1376],\n       [2184, 1374],\n       [2184, 1369],\n       [2190, 1359],\n       [2190, 1353],\n       [2188, 1350],\n       [2182, 1350],\n       [2175, 1357],\n       [2172, 1363],\n       [2176, 1378],\n       [2172, 1383],\n       [2169, 1384],\n       [2164, 1382],\n       [2162, 1378],\n       [2162, 1367],\n       [2158, 1361],\n       [2154, 1362],\n       [2152, 1366],\n       [2150, 1376],\n       [2148, 1379],\n       [2144, 1379],\n       [2139, 1377],\n       [2134, 1371],\n       [2130, 1369],\n       [2126, 1372],\n       [2120, 1382],\n       [2113, 1383],\n       [2108, 1379],\n       [2103, 1379],\n       [2101, 1381],\n       [2099, 1391],\n       [2092, 1395],\n       [2088, 1403],\n       [2080, 1402],\n       [2076, 1404],\n       [2072, 1412],\n       [2067, 1411],\n       [2059, 1403],\n       [2054, 1403],\n       [2051, 1405],\n       [2045, 1411],\n       [2037, 1413],\n       [2034, 1417],\n       [2031, 1425],\n       [2033, 1434],\n       [2022, 1442],\n       [2015, 1457],\n       [2000, 1455],\n       [1992, 1459],\n       [1983, 1458],\n       [1975, 1468],\n       [1969, 1471],\n       [1966, 1481],\n       [1964, 1484],\n       [1954, 1488],\n       [1936, 1502],\n       [1929, 1506],\n       [1926, 1505],\n       [1916, 1512],\n       [1914, 1512],\n       [1911, 1509],\n       [1910, 1503],\n       [1906, 1499],\n       [1902, 1501],\n       [1902, 1507],\n       [1900, 1513],\n       [1896, 1513],\n       [1893, 1505],\n       [1890, 1504],\n       [1889, 1505],\n       [1888, 1510],\n       [1878, 1509],\n       [1878, 1514],\n       [1874, 1515],\n       [1871, 1511],\n       [1868, 1512],\n       [1868, 1518],\n       [1866, 1520],\n       [1861, 1521],\n       [1863, 1530],\n       [1861, 1538],\n       [1865, 1546],\n       [1862, 1550],\n       [1863, 1554],\n       [1863, 1559],\n       [1860, 1560],\n       [1862, 1563],\n       [1861, 1566],\n       [1863, 1569],\n       [1860, 1591],\n       [1854, 1601],\n       [1854, 1606],\n       [1851, 1615],\n       [1846, 1623],\n       [1842, 1625],\n       [1837, 1634],\n       [1718, 1733],\n       [1716, 1731],\n       [1713, 1735],\n       [1706, 1738],\n       [1702, 1745],\n       [1696, 1747],\n       [1693, 1758],\n       [1684, 1761],\n       [1680, 1769],\n       [1681, 1771],\n       [1678, 1775],\n       [1676, 1776],\n       [1669, 1787],\n       [1659, 1794],\n       [1646, 1809],\n       [1632, 1813],\n       [1628, 1816],\n       [1603, 1822],\n       [1591, 1821],\n       [1587, 1819],\n       [1584, 1819],\n       [1579, 1815],\n       [1560, 1811],\n       [1545, 1805],\n       [1526, 1806],\n       [1517, 1810],\n       [1513, 1819],\n       [1506, 1823],\n       [1472, 1980],\n       [1464, 2006],\n       [1451, 2015],\n       [1447, 2016],\n       [1443, 2024],\n       [1439, 2027],\n       [1435, 2032],\n       [1435, 2041],\n       [1430, 2055],\n       [1421, 2065],\n       [1418, 2069],\n       [1402, 2070],\n       [1392, 2080],\n       [1389, 2081],\n       [1387, 2086],\n       [1388, 2089],\n       [1393, 2089],\n       [1393, 2094],\n       [1397, 2095],\n       [1402, 2102],\n       [1400, 2105],\n       [1392, 2106],\n       [1385, 2105],\n       [1381, 2107],\n       [1376, 2106],\n       [1368, 2106],\n       [1364, 2109],\n       [1359, 2108],\n       [1352, 2115],\n       [1345, 2116],\n       [1344, 2118],\n       [1342, 2125],\n       [1346, 2132],\n       [1346, 2137],\n       [1340, 2142],\n       [1340, 2149],\n       [1338, 2150],\n       [1337, 2161],\n       [1342, 2163],\n       [1342, 2167],\n       [1340, 2170],\n       [1343, 2172],\n       [1343, 2175],\n       [1351, 2181],\n       [1345, 2182],\n       [1341, 2189],\n       [1344, 2192],\n       [1340, 2191],\n       [1338, 2199],\n       [1336, 2201],\n       [1335, 2198],\n       [1328, 2202],\n       [1325, 2207],\n       [1324, 2204],\n       [1321, 2204],\n       [1314, 2212],\n       [1305, 2210],\n       [1303, 2207],\n       [1300, 2209],\n       [1296, 2208],\n       [1293, 2203],\n       [1278, 2204],\n       [1291, 2228],\n       [1297, 2236],\n       [1308, 2244],\n       [1349, 2260],\n       [1389, 2301],\n       [1402, 2312],\n       [1446, 2340],\n       [1474, 2354],\n       [1481, 2355],\n       [1498, 2353],\n       [1529, 2364],\n       [1540, 2369],\n       [1564, 2376],\n       [1568, 2379],\n       [1574, 2393],\n       [1577, 2397],\n       [1593, 2405],\n       [1601, 2411],\n       [1605, 2417],\n       [1609, 2432],\n       [1615, 2448],\n       [1619, 2455],\n       [1624, 2461],\n       [1633, 2462],\n       [1656, 2453],\n       [1678, 2448],\n       [1683, 2449],\n       [1701, 2465],\n       [1716, 2475],\n       [1722, 2476],\n       [1735, 2475],\n       [1743, 2477],\n       [1767, 2500],\n       [1774, 2501],\n       [1782, 2510],\n       [1783, 2517],\n       [1793, 2527],\n       [1796, 2541],\n       [1788, 2537],\n       [1787, 2539],\n       [1790, 2547],\n       [1786, 2549],\n       [1783, 2554],\n       [1788, 2560],\n       [1786, 2563],\n       [1790, 2566],\n       [1796, 2566],\n       [1799, 2570]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '005',\n     'FIPS': '34005',\n     'STATE': 'NJ',\n     'NAME': 'Burlington',\n     'LSAD': 'County'},\n    'id': 2178,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[217, 1692],\n       [217, 1571],\n       [219, 1532],\n       [249, 1041],\n       [240, 1045],\n       [235, 1044],\n       [235, 1047],\n       [223, 1051],\n       [222, 1046],\n       [216, 1048],\n       [213, 1046],\n       [209, 1046],\n       [206, 1041],\n       [198, 1042],\n       [193, 1037],\n       [191, 1038],\n       [186, 1046],\n       [176, 1047],\n       [173, 1050],\n       [166, 1049],\n       [155, 1035],\n       [139, 1029],\n       [134, 1023],\n       [130, 1024],\n       [120, 1017],\n       [111, 1023],\n       [107, 1021],\n       [102, 1023],\n       [81, 1017],\n       [76, 1010],\n       [71, 1012],\n       [63, 1019],\n       [49, 1017],\n       [21, 1022],\n       [14, 1030],\n       [8, 1030],\n       [0, 1025],\n       [-5, 1023],\n       [-11, 1025],\n       [-17, 1032],\n       [-21, 1034],\n       [-39, 1036],\n       [-48, 1033],\n       [-56, 1022],\n       [-60, 1021],\n       [-64, 1021],\n       [-75, 1034],\n       [-80, 1037],\n       [-80, 1144],\n       [-66, 1150],\n       [-57, 1168],\n       [-57, 1174],\n       [-76, 1194],\n       [-80, 1194],\n       [-80, 1260],\n       [-71, 1292],\n       [-56, 1329],\n       [-43, 1345],\n       [-43, 1367],\n       [-48, 1381],\n       [-80, 1391],\n       [-80, 1691],\n       [0, 1691],\n       [217, 1692]]]},\n    'properties': {'STATE_FIPS': '24',\n     'COUNTY_FIP': '015',\n     'FIPS': '24015',\n     'STATE': 'MD',\n     'NAME': 'Cecil',\n     'LSAD': 'County'},\n    'id': 2129,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1272, 1811],\n       [1283, 1808],\n       [1285, 1809],\n       [1287, 1804],\n       [1294, 1799],\n       [1292, 1795],\n       [1294, 1786],\n       [1300, 1777],\n       [1303, 1772],\n       [1302, 1767],\n       [1308, 1764],\n       [1313, 1759],\n       [1315, 1754],\n       [1333, 1738],\n       [1334, 1735],\n       [1332, 1727],\n       [1335, 1722],\n       [1334, 1714],\n       [1331, 1708],\n       [1373, 1681],\n       [1374, 1670],\n       [1381, 1667],\n       [1384, 1663],\n       [1397, 1657],\n       [1407, 1655],\n       [1413, 1656],\n       [1417, 1655],\n       [1425, 1656],\n       [1434, 1649],\n       [1447, 1647],\n       [1461, 1637],\n       [1463, 1634],\n       [1466, 1633],\n       [1467, 1629],\n       [1472, 1626],\n       [1472, 1621],\n       [1476, 1618],\n       [1480, 1611],\n       [1484, 1611],\n       [1486, 1600],\n       [1498, 1585],\n       [1496, 1582],\n       [1498, 1574],\n       [1497, 1569],\n       [1499, 1567],\n       [1496, 1561],\n       [1498, 1559],\n       [1501, 1539],\n       [1507, 1522],\n       [1522, 1508],\n       [1521, 1502],\n       [1523, 1495],\n       [1536, 1486],\n       [1537, 1482],\n       [1544, 1477],\n       [1387, 1300],\n       [1075, 1588],\n       [1044, 1578],\n       [1039, 1581],\n       [1026, 1578],\n       [1004, 1584],\n       [1000, 1592],\n       [999, 1606],\n       [996, 1610],\n       [991, 1611],\n       [984, 1616],\n       [972, 1617],\n       [963, 1613],\n       [961, 1615],\n       [948, 1612],\n       [938, 1621],\n       [918, 1631],\n       [914, 1630],\n       [912, 1627],\n       [907, 1629],\n       [909, 1632],\n       [907, 1634],\n       [898, 1634],\n       [895, 1631],\n       [890, 1631],\n       [889, 1639],\n       [891, 1643],\n       [884, 1644],\n       [883, 1648],\n       [878, 1651],\n       [876, 1658],\n       [870, 1660],\n       [868, 1659],\n       [859, 1664],\n       [856, 1671],\n       [840, 1675],\n       [839, 1682],\n       [836, 1681],\n       [831, 1684],\n       [832, 1689],\n       [831, 1692],\n       [828, 1692],\n       [823, 1697],\n       [822, 1696],\n       [817, 1700],\n       [817, 1704],\n       [821, 1717],\n       [816, 1725],\n       [819, 1727],\n       [815, 1727],\n       [817, 1729],\n       [815, 1732],\n       [817, 1735],\n       [812, 1742],\n       [803, 1739],\n       [801, 1742],\n       [802, 1747],\n       [800, 1746],\n       [800, 1749],\n       [796, 1749],\n       [796, 1745],\n       [793, 1747],\n       [794, 1749],\n       [789, 1753],\n       [791, 1756],\n       [794, 1754],\n       [797, 1756],\n       [797, 1759],\n       [794, 1760],\n       [798, 1765],\n       [788, 1767],\n       [787, 1762],\n       [785, 1759],\n       [783, 1762],\n       [784, 1766],\n       [778, 1766],\n       [774, 1771],\n       [776, 1782],\n       [779, 1783],\n       [782, 1779],\n       [785, 1781],\n       [790, 1790],\n       [788, 1791],\n       [785, 1788],\n       [783, 1789],\n       [781, 1794],\n       [782, 1799],\n       [779, 1807],\n       [777, 1807],\n       [775, 1803],\n       [771, 1804],\n       [774, 1810],\n       [772, 1816],\n       [769, 1817],\n       [764, 1812],\n       [757, 1813],\n       [748, 1809],\n       [734, 1808],\n       [723, 1803],\n       [728, 1808],\n       [775, 1833],\n       [761, 1843],\n       [797, 1869],\n       [849, 1916],\n       [868, 1927],\n       [884, 1933],\n       [895, 1934],\n       [914, 1935],\n       [938, 1932],\n       [970, 1934],\n       [1011, 1943],\n       [1043, 1956],\n       [1059, 1965],\n       [1090, 1993],\n       [1099, 1995],\n       [1146, 1997],\n       [1154, 2000],\n       [1161, 2008],\n       [1177, 1998],\n       [1180, 1993],\n       [1173, 1989],\n       [1174, 1987],\n       [1190, 1978],\n       [1184, 1976],\n       [1187, 1971],\n       [1188, 1965],\n       [1192, 1959],\n       [1195, 1960],\n       [1193, 1968],\n       [1201, 1959],\n       [1196, 1959],\n       [1201, 1952],\n       [1208, 1953],\n       [1205, 1956],\n       [1209, 1960],\n       [1211, 1960],\n       [1213, 1957],\n       [1211, 1955],\n       [1213, 1943],\n       [1216, 1942],\n       [1215, 1947],\n       [1228, 1938],\n       [1229, 1931],\n       [1235, 1930],\n       [1238, 1924],\n       [1241, 1924],\n       [1244, 1919],\n       [1239, 1912],\n       [1241, 1910],\n       [1242, 1906],\n       [1245, 1903],\n       [1242, 1898],\n       [1245, 1891],\n       [1241, 1887],\n       [1241, 1884],\n       [1237, 1879],\n       [1240, 1870],\n       [1236, 1868],\n       [1238, 1866],\n       [1242, 1865],\n       [1243, 1861],\n       [1248, 1855],\n       [1247, 1853],\n       [1256, 1849],\n       [1259, 1845],\n       [1255, 1839],\n       [1255, 1836],\n       [1257, 1835],\n       [1259, 1827],\n       [1249, 1820],\n       [1246, 1823],\n       [1241, 1813],\n       [1239, 1801],\n       [1252, 1804],\n       [1257, 1790],\n       [1264, 1795],\n       [1261, 1802],\n       [1269, 1806],\n       [1268, 1807],\n       [1272, 1811]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '015',\n     'FIPS': '34015',\n     'STATE': 'NJ',\n     'NAME': 'Gloucester',\n     'LSAD': 'County'},\n    'id': 2180,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[535, 1914],\n        [580, 1912],\n        [610, 1909],\n        [639, 1903],\n        [691, 1885],\n        [742, 1857],\n        [775, 1833],\n        [728, 1808],\n        [712, 1791],\n        [714, 1789],\n        [707, 1781],\n        [696, 1775],\n        [691, 1766],\n        [691, 1761],\n        [682, 1733],\n        [675, 1718],\n        [670, 1697],\n        [670, 1679],\n        [668, 1677],\n        [659, 1680],\n        [654, 1678],\n        [643, 1653],\n        [627, 1645],\n        [624, 1640],\n        [623, 1624],\n        [594, 1636],\n        [547, 1568],\n        [510, 1558],\n        [472, 1501],\n        [470, 1491],\n        [472, 1486],\n        [471, 1473],\n        [474, 1456],\n        [485, 1442],\n        [509, 1425],\n        [511, 1421],\n        [545, 1390],\n        [542, 1383],\n        [536, 1349],\n        [535, 1324],\n        [549, 1311],\n        [540, 1288],\n        [526, 1290],\n        [509, 1265],\n        [502, 1233],\n        [507, 1198],\n        [520, 1180],\n        [522, 1174],\n        [534, 1164],\n        [533, 1157],\n        [556, 1141],\n        [581, 1115],\n        [585, 1101],\n        [603, 1068],\n        [619, 1019],\n        [614, 1017],\n        [613, 1010],\n        [606, 1006],\n        [603, 1008],\n        [597, 1006],\n        [595, 1002],\n        [597, 998],\n        [595, 996],\n        [591, 998],\n        [587, 996],\n        [587, 992],\n        [585, 991],\n        [580, 993],\n        [579, 997],\n        [577, 998],\n        [573, 992],\n        [570, 991],\n        [567, 992],\n        [567, 995],\n        [565, 997],\n        [562, 997],\n        [558, 993],\n        [559, 989],\n        [562, 989],\n        [563, 981],\n        [558, 981],\n        [554, 988],\n        [549, 980],\n        [550, 977],\n        [553, 976],\n        [552, 969],\n        [555, 967],\n        [555, 962],\n        [551, 958],\n        [543, 956],\n        [537, 950],\n        [535, 945],\n        [537, 940],\n        [528, 921],\n        [519, 916],\n        [514, 912],\n        [510, 914],\n        [510, 916],\n        [504, 917],\n        [500, 911],\n        [496, 914],\n        [489, 911],\n        [486, 916],\n        [482, 911],\n        [474, 912],\n        [471, 911],\n        [468, 914],\n        [463, 914],\n        [458, 911],\n        [454, 903],\n        [451, 904],\n        [445, 898],\n        [430, 897],\n        [430, 894],\n        [422, 888],\n        [417, 880],\n        [403, 880],\n        [396, 878],\n        [391, 879],\n        [383, 878],\n        [375, 881],\n        [368, 890],\n        [324, 894],\n        [258, 889],\n        [219, 1532],\n        [217, 1571],\n        [217, 1692],\n        [239, 1693],\n        [250, 1722],\n        [269, 1760],\n        [293, 1794],\n        [321, 1825],\n        [344, 1845],\n        [366, 1861],\n        [400, 1880],\n        [431, 1894],\n        [466, 1904],\n        [501, 1911],\n        [535, 1914]]],\n      [[[551, 1518],\n        [550, 1507],\n        [554, 1484],\n        [553, 1479],\n        [556, 1472],\n        [547, 1471],\n        [539, 1487],\n        [533, 1506],\n        [534, 1512],\n        [551, 1518]]],\n      [[[521, 1459],\n        [541, 1443],\n        [543, 1430],\n        [526, 1439],\n        [523, 1445],\n        [521, 1459]]]]},\n    'properties': {'STATE_FIPS': '10',\n     'COUNTY_FIP': '003',\n     'FIPS': '10003',\n     'STATE': 'DE',\n     'NAME': 'New Castle',\n     'LSAD': 'County'},\n    'id': 2130,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[276, 601],\n       [314, 0],\n       [314, -1],\n       [319, -80],\n       [-15, -80],\n       [0, -66],\n       [7, -49],\n       [14, -44],\n       [38, -30],\n       [49, -29],\n       [55, -20],\n       [60, -19],\n       [59, -14],\n       [50, -11],\n       [45, -5],\n       [47, -2],\n       [51, 0],\n       [53, 4],\n       [36, 13],\n       [33, 23],\n       [26, 24],\n       [14, 30],\n       [14, 35],\n       [26, 42],\n       [27, 44],\n       [26, 45],\n       [16, 46],\n       [10, 53],\n       [22, 62],\n       [22, 65],\n       [19, 71],\n       [11, 72],\n       [4, 84],\n       [0, 83],\n       [-3, 82],\n       [-6, 85],\n       [-10, 98],\n       [-9, 101],\n       [-2, 101],\n       [0, 104],\n       [0, 107],\n       [-3, 110],\n       [-16, 104],\n       [-20, 108],\n       [-20, 115],\n       [-18, 116],\n       [-6, 115],\n       [-4, 117],\n       [-10, 126],\n       [-16, 129],\n       [-16, 130],\n       [-12, 133],\n       [-10, 140],\n       [-11, 145],\n       [-16, 149],\n       [-15, 153],\n       [-9, 156],\n       [-8, 158],\n       [-16, 167],\n       [-16, 172],\n       [-9, 172],\n       [-10, 176],\n       [-17, 179],\n       [-18, 190],\n       [-22, 200],\n       [-22, 201],\n       [-17, 202],\n       [-16, 204],\n       [-15, 210],\n       [-17, 213],\n       [-21, 214],\n       [-23, 217],\n       [-14, 220],\n       [-14, 222],\n       [-19, 222],\n       [-20, 231],\n       [-10, 234],\n       [-7, 238],\n       [-7, 250],\n       [-4, 254],\n       [-2, 253],\n       [-1, 257],\n       [-8, 270],\n       [0, 278],\n       [1, 283],\n       [0, 284],\n       [-3, 285],\n       [-5, 289],\n       [0, 292],\n       [4, 295],\n       [4, 299],\n       [7, 307],\n       [13, 311],\n       [11, 315],\n       [23, 322],\n       [26, 332],\n       [33, 335],\n       [35, 339],\n       [39, 340],\n       [42, 348],\n       [42, 352],\n       [49, 352],\n       [49, 354],\n       [47, 361],\n       [49, 364],\n       [57, 359],\n       [68, 366],\n       [68, 374],\n       [71, 377],\n       [73, 382],\n       [80, 384],\n       [78, 387],\n       [79, 389],\n       [79, 393],\n       [82, 396],\n       [84, 404],\n       [87, 405],\n       [89, 414],\n       [88, 417],\n       [86, 418],\n       [86, 421],\n       [89, 422],\n       [96, 432],\n       [99, 440],\n       [108, 443],\n       [112, 447],\n       [116, 452],\n       [129, 466],\n       [132, 473],\n       [130, 495],\n       [133, 500],\n       [137, 502],\n       [143, 520],\n       [149, 535],\n       [153, 536],\n       [167, 548],\n       [186, 558],\n       [197, 566],\n       [202, 573],\n       [209, 575],\n       [213, 581],\n       [236, 584],\n       [262, 592],\n       [276, 601]]]},\n    'properties': {'STATE_FIPS': '24',\n     'COUNTY_FIP': '011',\n     'FIPS': '24011',\n     'STATE': 'MD',\n     'NAME': 'Caroline',\n     'LSAD': 'County'},\n    'id': 2136,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[619, 1019],\n       [629, 1007],\n       [646, 998],\n       [649, 993],\n       [646, 983],\n       [651, 976],\n       [682, 953],\n       [695, 949],\n       [726, 921],\n       [729, 913],\n       [731, 889],\n       [742, 867],\n       [771, 829],\n       [778, 810],\n       [774, 789],\n       [774, 752],\n       [787, 738],\n       [793, 716],\n       [790, 685],\n       [783, 682],\n       [771, 660],\n       [767, 625],\n       [781, 498],\n       [780, 457],\n       [789, 443],\n       [788, 441],\n       [800, 428],\n       [812, 424],\n       [862, 379],\n       [869, 369],\n       [902, 310],\n       [907, 296],\n       [912, 271],\n       [910, 240],\n       [911, 231],\n       [908, 233],\n       [909, 239],\n       [904, 244],\n       [900, 245],\n       [897, 245],\n       [893, 238],\n       [887, 237],\n       [884, 239],\n       [881, 240],\n       [877, 233],\n       [872, 231],\n       [865, 234],\n       [867, 241],\n       [864, 248],\n       [863, 248],\n       [855, 234],\n       [852, 234],\n       [841, 253],\n       [832, 246],\n       [829, 253],\n       [830, 256],\n       [823, 260],\n       [817, 258],\n       [810, 260],\n       [808, 249],\n       [799, 247],\n       [796, 251],\n       [793, 250],\n       [792, 244],\n       [785, 238],\n       [781, 233],\n       [785, 221],\n       [783, 218],\n       [779, 215],\n       [783, 211],\n       [786, 213],\n       [781, 200],\n       [784, 195],\n       [783, 193],\n       [780, 192],\n       [778, 187],\n       [781, 180],\n       [779, 178],\n       [776, 177],\n       [775, 181],\n       [770, 182],\n       [770, 176],\n       [759, 179],\n       [757, 171],\n       [753, 174],\n       [751, 171],\n       [741, 169],\n       [732, 165],\n       [724, 169],\n       [716, 169],\n       [695, 162],\n       [688, 166],\n       [670, 156],\n       [659, 152],\n       [654, 143],\n       [655, 131],\n       [651, 125],\n       [645, 122],\n       [642, 113],\n       [640, 111],\n       [635, 109],\n       [632, 110],\n       [625, 105],\n       [607, 62],\n       [584, 51],\n       [585, 47],\n       [580, 39],\n       [577, 38],\n       [573, 39],\n       [566, 35],\n       [557, 24],\n       [313, 14],\n       [258, 889],\n       [324, 894],\n       [368, 890],\n       [375, 881],\n       [383, 878],\n       [391, 879],\n       [396, 878],\n       [403, 880],\n       [417, 880],\n       [422, 888],\n       [430, 894],\n       [430, 897],\n       [445, 898],\n       [451, 904],\n       [454, 903],\n       [458, 911],\n       [463, 914],\n       [468, 914],\n       [471, 911],\n       [474, 912],\n       [482, 911],\n       [486, 916],\n       [489, 911],\n       [496, 914],\n       [500, 911],\n       [504, 917],\n       [510, 916],\n       [510, 914],\n       [514, 912],\n       [519, 916],\n       [528, 921],\n       [537, 940],\n       [535, 945],\n       [537, 950],\n       [543, 956],\n       [551, 958],\n       [555, 962],\n       [555, 967],\n       [552, 969],\n       [553, 976],\n       [550, 977],\n       [549, 980],\n       [554, 988],\n       [558, 981],\n       [563, 981],\n       [562, 989],\n       [559, 989],\n       [558, 993],\n       [562, 997],\n       [565, 997],\n       [567, 995],\n       [567, 992],\n       [570, 991],\n       [573, 992],\n       [577, 998],\n       [579, 997],\n       [580, 993],\n       [585, 991],\n       [587, 992],\n       [587, 996],\n       [591, 998],\n       [595, 996],\n       [597, 998],\n       [595, 1002],\n       [597, 1006],\n       [603, 1008],\n       [606, 1006],\n       [613, 1010],\n       [614, 1017],\n       [619, 1019]]]},\n    'properties': {'STATE_FIPS': '10',\n     'COUNTY_FIP': '001',\n     'FIPS': '10001',\n     'STATE': 'DE',\n     'NAME': 'Kent',\n     'LSAD': 'County'},\n    'id': 2138,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1272, 1811],\n       [1268, 1807],\n       [1269, 1806],\n       [1261, 1802],\n       [1264, 1795],\n       [1257, 1790],\n       [1252, 1804],\n       [1239, 1801],\n       [1241, 1813],\n       [1246, 1823],\n       [1249, 1820],\n       [1259, 1827],\n       [1257, 1835],\n       [1255, 1836],\n       [1255, 1839],\n       [1259, 1845],\n       [1256, 1849],\n       [1247, 1853],\n       [1248, 1855],\n       [1243, 1861],\n       [1242, 1865],\n       [1238, 1866],\n       [1236, 1868],\n       [1240, 1870],\n       [1237, 1879],\n       [1241, 1884],\n       [1241, 1887],\n       [1245, 1891],\n       [1242, 1898],\n       [1245, 1903],\n       [1242, 1906],\n       [1241, 1910],\n       [1239, 1912],\n       [1244, 1919],\n       [1241, 1924],\n       [1238, 1924],\n       [1235, 1930],\n       [1229, 1931],\n       [1228, 1938],\n       [1215, 1947],\n       [1216, 1942],\n       [1213, 1943],\n       [1211, 1955],\n       [1213, 1957],\n       [1211, 1960],\n       [1209, 1960],\n       [1205, 1956],\n       [1208, 1953],\n       [1201, 1952],\n       [1196, 1959],\n       [1201, 1959],\n       [1193, 1968],\n       [1195, 1960],\n       [1192, 1959],\n       [1188, 1965],\n       [1187, 1971],\n       [1184, 1976],\n       [1190, 1978],\n       [1174, 1987],\n       [1173, 1989],\n       [1180, 1993],\n       [1177, 1998],\n       [1161, 2008],\n       [1175, 2030],\n       [1179, 2052],\n       [1169, 2081],\n       [1167, 2094],\n       [1168, 2119],\n       [1171, 2133],\n       [1180, 2146],\n       [1208, 2163],\n       [1236, 2172],\n       [1260, 2183],\n       [1278, 2204],\n       [1293, 2203],\n       [1296, 2208],\n       [1300, 2209],\n       [1303, 2207],\n       [1305, 2210],\n       [1314, 2212],\n       [1321, 2204],\n       [1324, 2204],\n       [1325, 2207],\n       [1328, 2202],\n       [1335, 2198],\n       [1336, 2201],\n       [1338, 2199],\n       [1340, 2191],\n       [1344, 2192],\n       [1341, 2189],\n       [1345, 2182],\n       [1351, 2181],\n       [1343, 2175],\n       [1343, 2172],\n       [1340, 2170],\n       [1342, 2167],\n       [1342, 2163],\n       [1337, 2161],\n       [1338, 2150],\n       [1340, 2149],\n       [1340, 2142],\n       [1346, 2137],\n       [1346, 2132],\n       [1342, 2125],\n       [1344, 2118],\n       [1345, 2116],\n       [1352, 2115],\n       [1359, 2108],\n       [1364, 2109],\n       [1368, 2106],\n       [1376, 2106],\n       [1381, 2107],\n       [1385, 2105],\n       [1392, 2106],\n       [1400, 2105],\n       [1402, 2102],\n       [1397, 2095],\n       [1393, 2094],\n       [1393, 2089],\n       [1388, 2089],\n       [1387, 2086],\n       [1389, 2081],\n       [1392, 2080],\n       [1402, 2070],\n       [1418, 2069],\n       [1421, 2065],\n       [1430, 2055],\n       [1435, 2041],\n       [1435, 2032],\n       [1439, 2027],\n       [1443, 2024],\n       [1447, 2016],\n       [1451, 2015],\n       [1464, 2006],\n       [1472, 1980],\n       [1506, 1823],\n       [1513, 1819],\n       [1517, 1810],\n       [1526, 1806],\n       [1545, 1805],\n       [1560, 1811],\n       [1579, 1815],\n       [1584, 1819],\n       [1587, 1819],\n       [1591, 1821],\n       [1603, 1822],\n       [1628, 1816],\n       [1632, 1813],\n       [1646, 1809],\n       [1659, 1794],\n       [1669, 1787],\n       [1676, 1776],\n       [1678, 1775],\n       [1681, 1771],\n       [1680, 1769],\n       [1684, 1761],\n       [1693, 1758],\n       [1696, 1747],\n       [1702, 1745],\n       [1706, 1738],\n       [1713, 1735],\n       [1716, 1731],\n       [1718, 1733],\n       [1749, 1707],\n       [1544, 1477],\n       [1537, 1482],\n       [1536, 1486],\n       [1523, 1495],\n       [1521, 1502],\n       [1522, 1508],\n       [1507, 1522],\n       [1501, 1539],\n       [1498, 1559],\n       [1496, 1561],\n       [1499, 1567],\n       [1497, 1569],\n       [1498, 1574],\n       [1496, 1582],\n       [1498, 1585],\n       [1486, 1600],\n       [1484, 1611],\n       [1480, 1611],\n       [1476, 1618],\n       [1472, 1621],\n       [1472, 1626],\n       [1467, 1629],\n       [1466, 1633],\n       [1463, 1634],\n       [1461, 1637],\n       [1447, 1647],\n       [1434, 1649],\n       [1425, 1656],\n       [1417, 1655],\n       [1413, 1656],\n       [1407, 1655],\n       [1397, 1657],\n       [1384, 1663],\n       [1381, 1667],\n       [1374, 1670],\n       [1373, 1681],\n       [1331, 1708],\n       [1334, 1714],\n       [1335, 1722],\n       [1332, 1727],\n       [1334, 1735],\n       [1333, 1738],\n       [1315, 1754],\n       [1313, 1759],\n       [1308, 1764],\n       [1302, 1767],\n       [1303, 1772],\n       [1300, 1777],\n       [1294, 1786],\n       [1292, 1795],\n       [1294, 1799],\n       [1287, 1804],\n       [1285, 1809],\n       [1283, 1808],\n       [1272, 1811]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '007',\n     'FIPS': '34007',\n     'STATE': 'NJ',\n     'NAME': 'Camden',\n     'LSAD': 'County'},\n    'id': 2179,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[763, 1054],\n        [751, 1058],\n        [736, 1068],\n        [721, 1088],\n        [688, 1157],\n        [672, 1156],\n        [661, 1161],\n        [629, 1184],\n        [625, 1195],\n        [584, 1198],\n        [575, 1217],\n        [573, 1234],\n        [575, 1266],\n        [596, 1269],\n        [598, 1273],\n        [594, 1275],\n        [593, 1283],\n        [593, 1293],\n        [598, 1323],\n        [598, 1332],\n        [597, 1339],\n        [591, 1342],\n        [588, 1349],\n        [590, 1354],\n        [609, 1377],\n        [616, 1391],\n        [620, 1400],\n        [619, 1420],\n        [615, 1425],\n        [609, 1430],\n        [600, 1431],\n        [583, 1448],\n        [571, 1455],\n        [559, 1465],\n        [553, 1479],\n        [554, 1484],\n        [550, 1507],\n        [551, 1518],\n        [555, 1527],\n        [568, 1538],\n        [576, 1548],\n        [586, 1551],\n        [616, 1591],\n        [620, 1602],\n        [624, 1623],\n        [624, 1640],\n        [627, 1645],\n        [643, 1653],\n        [654, 1678],\n        [659, 1680],\n        [668, 1677],\n        [670, 1679],\n        [670, 1697],\n        [675, 1718],\n        [682, 1733],\n        [691, 1761],\n        [691, 1766],\n        [696, 1775],\n        [707, 1781],\n        [714, 1789],\n        [712, 1791],\n        [723, 1803],\n        [734, 1808],\n        [748, 1809],\n        [757, 1813],\n        [764, 1812],\n        [769, 1817],\n        [772, 1816],\n        [774, 1810],\n        [771, 1804],\n        [775, 1803],\n        [777, 1807],\n        [779, 1807],\n        [782, 1799],\n        [781, 1794],\n        [783, 1789],\n        [785, 1788],\n        [788, 1791],\n        [790, 1790],\n        [785, 1781],\n        [782, 1779],\n        [779, 1783],\n        [776, 1782],\n        [774, 1771],\n        [778, 1766],\n        [784, 1766],\n        [783, 1762],\n        [785, 1759],\n        [787, 1762],\n        [788, 1767],\n        [798, 1765],\n        [794, 1760],\n        [797, 1759],\n        [797, 1756],\n        [794, 1754],\n        [791, 1756],\n        [789, 1753],\n        [794, 1749],\n        [793, 1747],\n        [796, 1745],\n        [796, 1749],\n        [800, 1749],\n        [800, 1746],\n        [802, 1747],\n        [801, 1742],\n        [803, 1739],\n        [812, 1742],\n        [817, 1735],\n        [815, 1732],\n        [817, 1729],\n        [815, 1727],\n        [819, 1727],\n        [816, 1725],\n        [821, 1717],\n        [817, 1704],\n        [817, 1700],\n        [822, 1696],\n        [823, 1697],\n        [828, 1692],\n        [831, 1692],\n        [832, 1689],\n        [831, 1684],\n        [836, 1681],\n        [839, 1682],\n        [840, 1675],\n        [856, 1671],\n        [859, 1664],\n        [868, 1659],\n        [870, 1660],\n        [876, 1658],\n        [878, 1651],\n        [883, 1648],\n        [884, 1644],\n        [891, 1643],\n        [889, 1639],\n        [890, 1631],\n        [895, 1631],\n        [898, 1634],\n        [907, 1634],\n        [909, 1632],\n        [907, 1629],\n        [912, 1627],\n        [914, 1630],\n        [918, 1631],\n        [938, 1621],\n        [948, 1612],\n        [961, 1615],\n        [963, 1613],\n        [972, 1617],\n        [984, 1616],\n        [991, 1611],\n        [996, 1610],\n        [999, 1606],\n        [1000, 1592],\n        [1004, 1584],\n        [1026, 1578],\n        [1039, 1581],\n        [1044, 1578],\n        [1075, 1588],\n        [1275, 1402],\n        [1269, 1387],\n        [1268, 1378],\n        [1264, 1373],\n        [1257, 1357],\n        [1262, 1348],\n        [1260, 1340],\n        [1260, 1334],\n        [1262, 1334],\n        [1258, 1324],\n        [1260, 1318],\n        [1256, 1309],\n        [1256, 1303],\n        [1253, 1299],\n        [1252, 1291],\n        [1253, 1289],\n        [1252, 1283],\n        [1253, 1282],\n        [1249, 1275],\n        [1251, 1267],\n        [1254, 1264],\n        [1257, 1257],\n        [1256, 1251],\n        [1259, 1245],\n        [1257, 1239],\n        [1254, 1237],\n        [1253, 1229],\n        [1251, 1229],\n        [1252, 1227],\n        [1250, 1224],\n        [1251, 1222],\n        [1248, 1219],\n        [1247, 1215],\n        [1249, 1212],\n        [1247, 1211],\n        [1246, 1206],\n        [1248, 1202],\n        [1243, 1192],\n        [1178, 1249],\n        [1016, 1384],\n        [1003, 1367],\n        [902, 1257],\n        [891, 1251],\n        [867, 1255],\n        [855, 1230],\n        [854, 1219],\n        [851, 1216],\n        [845, 1216],\n        [844, 1212],\n        [836, 1205],\n        [836, 1201],\n        [829, 1191],\n        [820, 1188],\n        [813, 1192],\n        [813, 1194],\n        [802, 1193],\n        [783, 1201],\n        [771, 1194],\n        [761, 1182],\n        [762, 1179],\n        [768, 1178],\n        [766, 1169],\n        [769, 1165],\n        [765, 1159],\n        [760, 1160],\n        [759, 1156],\n        [762, 1153],\n        [768, 1157],\n        [769, 1153],\n        [766, 1147],\n        [764, 1147],\n        [760, 1149],\n        [755, 1145],\n        [757, 1140],\n        [762, 1138],\n        [765, 1142],\n        [768, 1141],\n        [768, 1135],\n        [771, 1131],\n        [770, 1129],\n        [766, 1128],\n        [765, 1126],\n        [766, 1122],\n        [761, 1121],\n        [762, 1114],\n        [756, 1113],\n        [755, 1105],\n        [760, 1100],\n        [762, 1093],\n        [764, 1092],\n        [766, 1094],\n        [767, 1100],\n        [775, 1098],\n        [775, 1094],\n        [773, 1091],\n        [767, 1086],\n        [767, 1084],\n        [772, 1080],\n        [772, 1076],\n        [769, 1074],\n        [763, 1074],\n        [758, 1076],\n        [757, 1071],\n        [761, 1066],\n        [758, 1062],\n        [758, 1060],\n        [763, 1054]]],\n      [[[763, 1054],\n        [765, 1055],\n        [767, 1060],\n        [770, 1060],\n        [772, 1050],\n        [763, 1054]]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '033',\n     'FIPS': '34033',\n     'STATE': 'NJ',\n     'NAME': 'Salem',\n     'LSAD': 'County'},\n    'id': 2131,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1275, 1402],\n       [1575, 1130],\n       [1573, 1127],\n       [1574, 1123],\n       [1579, 1112],\n       [1580, 1106],\n       [1577, 1095],\n       [1572, 1086],\n       [1573, 1080],\n       [1572, 1075],\n       [1580, 1055],\n       [1581, 1041],\n       [1579, 1031],\n       [1569, 1012],\n       [1570, 1000],\n       [1564, 981],\n       [1564, 974],\n       [1562, 968],\n       [1563, 948],\n       [1568, 940],\n       [1563, 941],\n       [1557, 929],\n       [1549, 919],\n       [1537, 911],\n       [1515, 773],\n       [1490, 757],\n       [1479, 754],\n       [1476, 743],\n       [1474, 742],\n       [1476, 740],\n       [1474, 739],\n       [1473, 735],\n       [1475, 732],\n       [1474, 730],\n       [1476, 727],\n       [1473, 727],\n       [1473, 724],\n       [1477, 722],\n       [1476, 719],\n       [1479, 717],\n       [1474, 710],\n       [1473, 701],\n       [1475, 698],\n       [1483, 700],\n       [1484, 697],\n       [1478, 691],\n       [1478, 686],\n       [1480, 685],\n       [1481, 687],\n       [1491, 685],\n       [1488, 679],\n       [1490, 673],\n       [1493, 672],\n       [1492, 669],\n       [1493, 667],\n       [1489, 665],\n       [1420, 689],\n       [1400, 693],\n       [1368, 691],\n       [1327, 695],\n       [1323, 697],\n       [1325, 706],\n       [1331, 712],\n       [1331, 716],\n       [1327, 726],\n       [1313, 736],\n       [1305, 737],\n       [1296, 729],\n       [1289, 733],\n       [1274, 733],\n       [1240, 723],\n       [1218, 729],\n       [1209, 729],\n       [1198, 722],\n       [1180, 688],\n       [1166, 669],\n       [1163, 670],\n       [1124, 711],\n       [1125, 739],\n       [1117, 772],\n       [1107, 788],\n       [1099, 795],\n       [1086, 793],\n       [1079, 813],\n       [1066, 825],\n       [1056, 825],\n       [1013, 847],\n       [1010, 853],\n       [1012, 859],\n       [1009, 869],\n       [999, 895],\n       [970, 903],\n       [954, 894],\n       [950, 881],\n       [945, 876],\n       [920, 899],\n       [906, 915],\n       [889, 957],\n       [888, 969],\n       [879, 981],\n       [867, 987],\n       [848, 985],\n       [834, 973],\n       [797, 1005],\n       [791, 1015],\n       [790, 1030],\n       [784, 1045],\n       [772, 1050],\n       [770, 1060],\n       [767, 1060],\n       [765, 1055],\n       [763, 1054],\n       [758, 1060],\n       [758, 1062],\n       [761, 1066],\n       [757, 1071],\n       [757, 1075],\n       [758, 1076],\n       [763, 1074],\n       [769, 1074],\n       [772, 1076],\n       [772, 1080],\n       [767, 1084],\n       [767, 1086],\n       [773, 1091],\n       [775, 1094],\n       [775, 1098],\n       [767, 1100],\n       [766, 1094],\n       [764, 1092],\n       [762, 1093],\n       [760, 1100],\n       [755, 1103],\n       [754, 1109],\n       [756, 1113],\n       [762, 1114],\n       [761, 1121],\n       [766, 1122],\n       [765, 1126],\n       [766, 1128],\n       [770, 1129],\n       [771, 1131],\n       [768, 1135],\n       [768, 1141],\n       [765, 1142],\n       [762, 1138],\n       [757, 1140],\n       [755, 1145],\n       [760, 1149],\n       [764, 1147],\n       [766, 1147],\n       [769, 1153],\n       [768, 1157],\n       [762, 1153],\n       [759, 1156],\n       [760, 1160],\n       [765, 1159],\n       [769, 1165],\n       [766, 1169],\n       [768, 1178],\n       [762, 1179],\n       [761, 1182],\n       [771, 1194],\n       [783, 1201],\n       [802, 1193],\n       [813, 1194],\n       [813, 1192],\n       [820, 1188],\n       [829, 1191],\n       [836, 1201],\n       [836, 1205],\n       [844, 1212],\n       [845, 1216],\n       [851, 1216],\n       [854, 1219],\n       [855, 1230],\n       [867, 1255],\n       [891, 1251],\n       [902, 1257],\n       [1003, 1367],\n       [1016, 1384],\n       [1178, 1249],\n       [1243, 1192],\n       [1248, 1202],\n       [1246, 1206],\n       [1247, 1211],\n       [1249, 1212],\n       [1247, 1215],\n       [1248, 1219],\n       [1251, 1222],\n       [1250, 1224],\n       [1252, 1227],\n       [1251, 1229],\n       [1253, 1229],\n       [1254, 1237],\n       [1257, 1239],\n       [1259, 1245],\n       [1256, 1251],\n       [1257, 1257],\n       [1254, 1264],\n       [1251, 1267],\n       [1249, 1275],\n       [1253, 1282],\n       [1252, 1283],\n       [1253, 1289],\n       [1252, 1291],\n       [1253, 1299],\n       [1256, 1303],\n       [1256, 1309],\n       [1260, 1318],\n       [1258, 1324],\n       [1262, 1334],\n       [1260, 1334],\n       [1260, 1340],\n       [1262, 1348],\n       [1257, 1357],\n       [1264, 1373],\n       [1268, 1378],\n       [1269, 1387],\n       [1275, 1402]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '011',\n     'FIPS': '34011',\n     'STATE': 'NJ',\n     'NAME': 'Cumberland',\n     'LSAD': 'County'},\n    'id': 2133,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1563, 941],\n       [1568, 940],\n       [1568, 932],\n       [1576, 930],\n       [1582, 926],\n       [1602, 924],\n       [1611, 916],\n       [1620, 905],\n       [1627, 909],\n       [1629, 907],\n       [1643, 907],\n       [1646, 904],\n       [1651, 909],\n       [1656, 911],\n       [1659, 908],\n       [1664, 908],\n       [1666, 905],\n       [1671, 909],\n       [1676, 908],\n       [1679, 909],\n       [1689, 902],\n       [1687, 894],\n       [1688, 894],\n       [1696, 897],\n       [1699, 894],\n       [1706, 893],\n       [1709, 889],\n       [1720, 894],\n       [1725, 891],\n       [1726, 886],\n       [1735, 885],\n       [1744, 888],\n       [1748, 893],\n       [1758, 892],\n       [1764, 888],\n       [1773, 893],\n       [1775, 892],\n       [1773, 886],\n       [1778, 881],\n       [1782, 880],\n       [1785, 886],\n       [1788, 886],\n       [1789, 880],\n       [1791, 878],\n       [1794, 884],\n       [1798, 885],\n       [1802, 878],\n       [1805, 875],\n       [1810, 879],\n       [1816, 878],\n       [1820, 883],\n       [1824, 885],\n       [1828, 883],\n       [1831, 884],\n       [1835, 890],\n       [1837, 890],\n       [1840, 887],\n       [1840, 883],\n       [1838, 877],\n       [1840, 875],\n       [1843, 876],\n       [1845, 881],\n       [1845, 889],\n       [1849, 891],\n       [1864, 890],\n       [1862, 879],\n       [1863, 877],\n       [1870, 874],\n       [1875, 875],\n       [1879, 882],\n       [1885, 887],\n       [1889, 888],\n       [1900, 886],\n       [1913, 881],\n       [1918, 882],\n       [1960, 913],\n       [1967, 914],\n       [1994, 894],\n       [2011, 893],\n       [2023, 900],\n       [2031, 899],\n       [2033, 896],\n       [2019, 883],\n       [2016, 871],\n       [2005, 855],\n       [1976, 841],\n       [1951, 818],\n       [1927, 791],\n       [1895, 747],\n       [1880, 730],\n       [1873, 705],\n       [1844, 669],\n       [1781, 557],\n       [1780, 551],\n       [1782, 547],\n       [1796, 534],\n       [1794, 525],\n       [1746, 472],\n       [1688, 375],\n       [1676, 332],\n       [1667, 317],\n       [1645, 306],\n       [1628, 293],\n       [1583, 247],\n       [1563, 220],\n       [1562, 222],\n       [1554, 226],\n       [1537, 223],\n       [1501, 205],\n       [1481, 199],\n       [1462, 198],\n       [1419, 203],\n       [1413, 207],\n       [1406, 220],\n       [1430, 334],\n       [1439, 361],\n       [1455, 398],\n       [1506, 496],\n       [1514, 517],\n       [1522, 544],\n       [1531, 601],\n       [1530, 630],\n       [1503, 660],\n       [1489, 665],\n       [1493, 667],\n       [1492, 669],\n       [1493, 672],\n       [1490, 673],\n       [1488, 679],\n       [1491, 685],\n       [1481, 687],\n       [1480, 685],\n       [1478, 686],\n       [1478, 691],\n       [1484, 697],\n       [1482, 701],\n       [1475, 698],\n       [1473, 701],\n       [1474, 710],\n       [1479, 717],\n       [1476, 719],\n       [1477, 722],\n       [1473, 724],\n       [1473, 727],\n       [1476, 727],\n       [1474, 730],\n       [1475, 732],\n       [1473, 735],\n       [1474, 739],\n       [1476, 740],\n       [1474, 742],\n       [1476, 743],\n       [1479, 754],\n       [1490, 757],\n       [1515, 773],\n       [1537, 911],\n       [1549, 919],\n       [1557, 929],\n       [1563, 941]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '009',\n     'FIPS': '34009',\n     'STATE': 'NJ',\n     'NAME': 'Cape May',\n     'LSAD': 'County'},\n    'id': 2134,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2885, 4176],\n       [2960, 4130],\n       [2976, 4129],\n       [2972, 4096],\n       [2941, 3976],\n       [2925, 3922],\n       [2889, 3842],\n       [2875, 3801],\n       [2844, 3745],\n       [2831, 3752],\n       [2832, 3760],\n       [2803, 3780],\n       [2803, 3784],\n       [2806, 3789],\n       [2802, 3794],\n       [2797, 3795],\n       [2792, 3789],\n       [2792, 3785],\n       [2788, 3785],\n       [2787, 3781],\n       [2785, 3780],\n       [2786, 3778],\n       [2781, 3781],\n       [2780, 3774],\n       [2775, 3774],\n       [2769, 3765],\n       [2742, 3763],\n       [2733, 3760],\n       [2727, 3755],\n       [2722, 3747],\n       [2718, 3744],\n       [2710, 3742],\n       [2708, 3736],\n       [2692, 3711],\n       [2690, 3703],\n       [2693, 3687],\n       [2690, 3677],\n       [2686, 3679],\n       [2683, 3677],\n       [2677, 3687],\n       [2679, 3692],\n       [2675, 3703],\n       [2672, 3702],\n       [2669, 3705],\n       [2662, 3706],\n       [2657, 3703],\n       [2653, 3694],\n       [2650, 3692],\n       [2640, 3696],\n       [2636, 3695],\n       [2633, 3699],\n       [2632, 3707],\n       [2607, 3723],\n       [2619, 3744],\n       [2620, 3749],\n       [2618, 3760],\n       [2623, 3784],\n       [2638, 3790],\n       [2641, 3793],\n       [2643, 3799],\n       [2645, 3808],\n       [2641, 3826],\n       [2644, 3833],\n       [2648, 3849],\n       [2647, 3855],\n       [2649, 3864],\n       [2656, 3864],\n       [2659, 3857],\n       [2661, 3856],\n       [2665, 3860],\n       [2666, 3864],\n       [2665, 3871],\n       [2661, 3874],\n       [2656, 3885],\n       [2654, 3892],\n       [2646, 3904],\n       [2632, 3915],\n       [2634, 3930],\n       [2627, 3941],\n       [2630, 3956],\n       [2628, 3967],\n       [2633, 3981],\n       [2630, 3985],\n       [2619, 3987],\n       [2616, 3992],\n       [2615, 3999],\n       [2619, 4007],\n       [2612, 4020],\n       [2606, 4022],\n       [2616, 4070],\n       [2583, 4096],\n       [2574, 4104],\n       [2573, 4096],\n       [2573, 4090],\n       [2518, 4096],\n       [2494, 4099],\n       [2460, 4120],\n       [2437, 4158],\n       [2425, 4170],\n       [2427, 4176],\n       [2885, 4176]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '003',\n     'FIPS': '34003',\n     'STATE': 'NJ',\n     'NAME': 'Bergen',\n     'LSAD': 'County'},\n    'id': 2229,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2234, 4176],\n       [2235, 4173],\n       [2240, 4168],\n       [2251, 4165],\n       [2255, 4159],\n       [2259, 4157],\n       [2265, 4162],\n       [2274, 4161],\n       [2281, 4157],\n       [2292, 4157],\n       [2293, 4160],\n       [2298, 4162],\n       [2306, 4160],\n       [2310, 4156],\n       [2310, 4144],\n       [2318, 4144],\n       [2324, 4148],\n       [2325, 4146],\n       [2329, 4148],\n       [2334, 4147],\n       [2334, 4142],\n       [2341, 4140],\n       [2344, 4137],\n       [2363, 4139],\n       [2370, 4132],\n       [2382, 4133],\n       [2384, 4140],\n       [2387, 4140],\n       [2388, 4136],\n       [2388, 4128],\n       [2391, 4125],\n       [2391, 4117],\n       [2396, 4111],\n       [2389, 4103],\n       [2389, 4096],\n       [2392, 4094],\n       [2399, 4096],\n       [2407, 4094],\n       [2412, 4096],\n       [2412, 4090],\n       [2418, 4085],\n       [2417, 4079],\n       [2413, 4081],\n       [2412, 4075],\n       [2413, 4071],\n       [2415, 4069],\n       [2414, 4053],\n       [2418, 4047],\n       [2415, 4025],\n       [2407, 4002],\n       [2401, 3997],\n       [2402, 3995],\n       [2402, 3989],\n       [2407, 3986],\n       [2405, 3984],\n       [2408, 3980],\n       [2408, 3975],\n       [2416, 3978],\n       [2416, 3973],\n       [2426, 3972],\n       [2433, 3959],\n       [2432, 3957],\n       [2430, 3957],\n       [2426, 3962],\n       [2426, 3956],\n       [2424, 3953],\n       [2427, 3948],\n       [2424, 3942],\n       [2425, 3938],\n       [2427, 3936],\n       [2413, 3937],\n       [2411, 3934],\n       [2407, 3933],\n       [2408, 3938],\n       [2404, 3940],\n       [2411, 3942],\n       [2411, 3944],\n       [2406, 3945],\n       [2400, 3941],\n       [2397, 3942],\n       [2396, 3944],\n       [2397, 3945],\n       [2396, 3948],\n       [2397, 3953],\n       [2390, 3954],\n       [2380, 3950],\n       [2381, 3956],\n       [2376, 3952],\n       [2370, 3951],\n       [2367, 3952],\n       [2364, 3949],\n       [2358, 3948],\n       [2358, 3957],\n       [2355, 3957],\n       [2353, 3955],\n       [2351, 3956],\n       [2352, 3959],\n       [2347, 3958],\n       [2345, 3956],\n       [2348, 3956],\n       [2348, 3953],\n       [2344, 3953],\n       [2342, 3959],\n       [2340, 3955],\n       [2335, 3952],\n       [2330, 3939],\n       [2335, 3937],\n       [2335, 3935],\n       [2331, 3935],\n       [2328, 3931],\n       [2333, 3929],\n       [2328, 3927],\n       [2327, 3923],\n       [2329, 3918],\n       [2326, 3902],\n       [2330, 3902],\n       [2330, 3900],\n       [2334, 3898],\n       [2330, 3894],\n       [2335, 3891],\n       [2330, 3888],\n       [2332, 3885],\n       [2329, 3884],\n       [2331, 3878],\n       [2337, 3883],\n       [2339, 3878],\n       [2347, 3877],\n       [2353, 3873],\n       [2356, 3876],\n       [2359, 3874],\n       [2358, 3871],\n       [2354, 3869],\n       [2357, 3861],\n       [2349, 3861],\n       [2347, 3858],\n       [2348, 3854],\n       [2346, 3851],\n       [2345, 3847],\n       [2341, 3844],\n       [2343, 3835],\n       [2347, 3834],\n       [2345, 3830],\n       [2342, 3829],\n       [2341, 3816],\n       [2343, 3811],\n       [2334, 3803],\n       [2338, 3792],\n       [2335, 3785],\n       [2327, 3774],\n       [2320, 3776],\n       [2313, 3774],\n       [2311, 3763],\n       [2303, 3757],\n       [2298, 3749],\n       [2291, 3748],\n       [2291, 3742],\n       [2288, 3739],\n       [2287, 3711],\n       [2279, 3701],\n       [2282, 3700],\n       [2284, 3694],\n       [2280, 3687],\n       [2283, 3686],\n       [2282, 3680],\n       [2278, 3678],\n       [2274, 3678],\n       [2272, 3675],\n       [2275, 3674],\n       [2277, 3669],\n       [2287, 3675],\n       [2286, 3669],\n       [2291, 3668],\n       [2295, 3665],\n       [2301, 3665],\n       [2301, 3662],\n       [2298, 3655],\n       [2287, 3652],\n       [2286, 3650],\n       [2291, 3646],\n       [2288, 3642],\n       [2279, 3637],\n       [2282, 3626],\n       [2280, 3622],\n       [2276, 3622],\n       [2272, 3623],\n       [2268, 3621],\n       [2272, 3615],\n       [2262, 3604],\n       [2258, 3607],\n       [2253, 3606],\n       [2253, 3592],\n       [2246, 3590],\n       [2236, 3592],\n       [2228, 3583],\n       [2227, 3577],\n       [2222, 3577],\n       [2217, 3568],\n       [2200, 3560],\n       [2197, 3555],\n       [2194, 3545],\n       [2189, 3545],\n       [2184, 3542],\n       [2181, 3537],\n       [2169, 3529],\n       [2164, 3529],\n       [2162, 3524],\n       [2164, 3518],\n       [2162, 3514],\n       [2163, 3512],\n       [2160, 3507],\n       [2154, 3508],\n       [2150, 3506],\n       [2149, 3503],\n       [2137, 3496],\n       [2133, 3498],\n       [2128, 3493],\n       [2116, 3491],\n       [2117, 3487],\n       [2114, 3485],\n       [2112, 3488],\n       [2106, 3487],\n       [2106, 3484],\n       [2102, 3482],\n       [2100, 3484],\n       [2094, 3483],\n       [2095, 3479],\n       [2091, 3478],\n       [2088, 3480],\n       [2085, 3477],\n       [2086, 3475],\n       [2082, 3466],\n       [2075, 3460],\n       [2071, 3463],\n       [2070, 3462],\n       [2061, 3461],\n       [2060, 3464],\n       [2055, 3465],\n       [2059, 3469],\n       [2056, 3469],\n       [2054, 3479],\n       [2056, 3482],\n       [2051, 3486],\n       [2050, 3490],\n       [2044, 3491],\n       [2043, 3494],\n       [2050, 3495],\n       [2051, 3498],\n       [2056, 3501],\n       [2052, 3521],\n       [2053, 3527],\n       [2055, 3529],\n       [2058, 3537],\n       [2062, 3535],\n       [2069, 3537],\n       [2069, 3539],\n       [2066, 3541],\n       [2067, 3545],\n       [2070, 3544],\n       [2073, 3547],\n       [2073, 3559],\n       [2071, 3561],\n       [2069, 3561],\n       [2068, 3568],\n       [2061, 3574],\n       [2056, 3575],\n       [2054, 3578],\n       [2057, 3581],\n       [2058, 3587],\n       [2052, 3591],\n       [2051, 3594],\n       [2048, 3595],\n       [2048, 3598],\n       [2052, 3611],\n       [2046, 3617],\n       [2043, 3616],\n       [2035, 3622],\n       [2028, 3621],\n       [2026, 3623],\n       [2022, 3622],\n       [2023, 3646],\n       [2017, 3652],\n       [2019, 3655],\n       [2018, 3663],\n       [2012, 3669],\n       [1848, 3621],\n       [1765, 3594],\n       [1755, 3595],\n       [1740, 3603],\n       [1740, 3607],\n       [1725, 3617],\n       [1704, 3625],\n       [1666, 3634],\n       [1659, 3638],\n       [1644, 3636],\n       [1638, 3636],\n       [1638, 3638],\n       [1633, 3639],\n       [1622, 3639],\n       [1617, 3642],\n       [1594, 3665],\n       [1592, 3670],\n       [1526, 3726],\n       [1532, 3732],\n       [1535, 3733],\n       [1539, 3731],\n       [1546, 3737],\n       [1558, 3742],\n       [1562, 3755],\n       [1567, 3756],\n       [1569, 3752],\n       [1576, 3756],\n       [1583, 3757],\n       [1588, 3765],\n       [1589, 3771],\n       [1592, 3771],\n       [1598, 3780],\n       [1606, 3786],\n       [1606, 3792],\n       [1613, 3799],\n       [1611, 3804],\n       [1617, 3812],\n       [1630, 3821],\n       [1627, 3829],\n       [1622, 3833],\n       [1625, 3843],\n       [1627, 3845],\n       [1637, 3849],\n       [1642, 3855],\n       [1643, 3865],\n       [1652, 3869],\n       [1654, 3874],\n       [1646, 3880],\n       [1645, 3883],\n       [1648, 3894],\n       [1647, 3908],\n       [1651, 3914],\n       [1668, 3923],\n       [1671, 3928],\n       [1671, 3935],\n       [1681, 3943],\n       [1687, 3954],\n       [1691, 3952],\n       [1706, 3966],\n       [1708, 3965],\n       [1711, 3968],\n       [1713, 3965],\n       [1715, 3968],\n       [1722, 3968],\n       [1727, 3972],\n       [1727, 3976],\n       [1734, 3980],\n       [1749, 3979],\n       [1756, 3982],\n       [1761, 3974],\n       [1769, 3970],\n       [1783, 3958],\n       [1785, 3951],\n       [1782, 3942],\n       [1786, 3940],\n       [1792, 3945],\n       [1796, 3946],\n       [1808, 3954],\n       [1814, 3951],\n       [1818, 3952],\n       [1820, 3959],\n       [1827, 3961],\n       [1832, 3960],\n       [1846, 3969],\n       [1855, 3977],\n       [1871, 3984],\n       [1872, 3987],\n       [1870, 3992],\n       [1871, 3998],\n       [1873, 4001],\n       [1889, 4014],\n       [1897, 4029],\n       [1897, 4040],\n       [1888, 4056],\n       [1889, 4068],\n       [1910, 4096],\n       [1938, 4131],\n       [1978, 4176],\n       [2190, 4176],\n       [2189, 4174],\n       [2196, 4170],\n       [2202, 4172],\n       [2203, 4176],\n       [2234, 4176]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '027',\n     'FIPS': '34027',\n     'STATE': 'NJ',\n     'NAME': 'Morris',\n     'LSAD': 'County'},\n    'id': 2228,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2352, 3959],\n       [2351, 3956],\n       [2353, 3955],\n       [2355, 3957],\n       [2358, 3957],\n       [2358, 3948],\n       [2364, 3949],\n       [2367, 3952],\n       [2370, 3951],\n       [2376, 3952],\n       [2381, 3956],\n       [2380, 3950],\n       [2390, 3954],\n       [2397, 3953],\n       [2396, 3948],\n       [2397, 3945],\n       [2396, 3944],\n       [2397, 3942],\n       [2400, 3941],\n       [2406, 3945],\n       [2411, 3944],\n       [2411, 3942],\n       [2404, 3940],\n       [2408, 3938],\n       [2407, 3933],\n       [2411, 3934],\n       [2413, 3937],\n       [2427, 3936],\n       [2433, 3931],\n       [2437, 3917],\n       [2443, 3911],\n       [2451, 3909],\n       [2453, 3906],\n       [2472, 3904],\n       [2527, 3864],\n       [2529, 3868],\n       [2536, 3865],\n       [2534, 3860],\n       [2632, 3788],\n       [2623, 3784],\n       [2618, 3760],\n       [2620, 3749],\n       [2619, 3744],\n       [2607, 3723],\n       [2606, 3710],\n       [2596, 3695],\n       [2592, 3684],\n       [2584, 3671],\n       [2580, 3648],\n       [2586, 3626],\n       [2589, 3623],\n       [2596, 3622],\n       [2606, 3623],\n       [2610, 3626],\n       [2614, 3633],\n       [2621, 3637],\n       [2643, 3638],\n       [2650, 3633],\n       [2651, 3629],\n       [2645, 3598],\n       [2647, 3588],\n       [2657, 3563],\n       [2623, 3508],\n       [2620, 3507],\n       [2588, 3532],\n       [2587, 3536],\n       [2585, 3537],\n       [2577, 3538],\n       [2575, 3535],\n       [2528, 3532],\n       [2516, 3540],\n       [2511, 3558],\n       [2498, 3571],\n       [2448, 3583],\n       [2406, 3600],\n       [2398, 3598],\n       [2393, 3595],\n       [2392, 3591],\n       [2386, 3584],\n       [2382, 3583],\n       [2368, 3587],\n       [2361, 3594],\n       [2354, 3594],\n       [2348, 3590],\n       [2323, 3606],\n       [2304, 3624],\n       [2280, 3633],\n       [2279, 3637],\n       [2288, 3642],\n       [2291, 3646],\n       [2286, 3650],\n       [2287, 3652],\n       [2298, 3655],\n       [2301, 3662],\n       [2301, 3665],\n       [2295, 3665],\n       [2291, 3668],\n       [2286, 3669],\n       [2287, 3675],\n       [2277, 3669],\n       [2275, 3674],\n       [2272, 3675],\n       [2274, 3678],\n       [2278, 3678],\n       [2282, 3680],\n       [2283, 3686],\n       [2280, 3687],\n       [2284, 3694],\n       [2282, 3700],\n       [2279, 3701],\n       [2287, 3711],\n       [2288, 3739],\n       [2291, 3742],\n       [2291, 3748],\n       [2298, 3749],\n       [2303, 3757],\n       [2311, 3763],\n       [2313, 3774],\n       [2320, 3776],\n       [2327, 3774],\n       [2335, 3785],\n       [2338, 3792],\n       [2334, 3803],\n       [2343, 3811],\n       [2341, 3816],\n       [2342, 3829],\n       [2345, 3830],\n       [2347, 3834],\n       [2343, 3835],\n       [2341, 3844],\n       [2345, 3847],\n       [2346, 3851],\n       [2348, 3854],\n       [2347, 3858],\n       [2349, 3861],\n       [2357, 3861],\n       [2354, 3869],\n       [2358, 3871],\n       [2359, 3874],\n       [2356, 3876],\n       [2353, 3873],\n       [2347, 3877],\n       [2339, 3878],\n       [2337, 3883],\n       [2331, 3878],\n       [2329, 3884],\n       [2332, 3885],\n       [2330, 3888],\n       [2335, 3891],\n       [2330, 3894],\n       [2334, 3898],\n       [2330, 3900],\n       [2330, 3902],\n       [2326, 3902],\n       [2329, 3918],\n       [2327, 3923],\n       [2328, 3927],\n       [2333, 3929],\n       [2328, 3931],\n       [2331, 3935],\n       [2335, 3935],\n       [2335, 3937],\n       [2330, 3939],\n       [2331, 3942],\n       [2335, 3952],\n       [2340, 3955],\n       [2342, 3959],\n       [2344, 3953],\n       [2348, 3953],\n       [2348, 3956],\n       [2345, 3956],\n       [2347, 3958],\n       [2352, 3959]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '013',\n     'FIPS': '34013',\n     'STATE': 'NJ',\n     'NAME': 'Essex',\n     'LSAD': 'County'},\n    'id': 2206,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2380, 3382],\n       [2380, 3379],\n       [2378, 3378],\n       [2380, 3376],\n       [2377, 3366],\n       [2385, 3361],\n       [2397, 3350],\n       [2443, 3360],\n       [2446, 3370],\n       [2467, 3365],\n       [2478, 3370],\n       [2484, 3363],\n       [2498, 3366],\n       [2504, 3368],\n       [2508, 3373],\n       [2512, 3369],\n       [2513, 3362],\n       [2521, 3355],\n       [2517, 3320],\n       [2509, 3290],\n       [2504, 3283],\n       [2484, 3287],\n       [2460, 3269],\n       [2456, 3255],\n       [2463, 3214],\n       [2431, 3172],\n       [2425, 3151],\n       [2432, 3120],\n       [2440, 3106],\n       [2477, 3093],\n       [2494, 3084],\n       [2494, 3083],\n       [2497, 3080],\n       [2490, 3067],\n       [2483, 3068],\n       [2481, 3065],\n       [2479, 3067],\n       [2461, 3042],\n       [2461, 3006],\n       [2458, 3003],\n       [2460, 2996],\n       [2455, 2990],\n       [2271, 2799],\n       [2248, 2769],\n       [2249, 2752],\n       [2150, 2698],\n       [2146, 2700],\n       [2116, 2702],\n       [2119, 2741],\n       [2095, 2754],\n       [2091, 2751],\n       [2088, 2754],\n       [2086, 2754],\n       [2077, 2759],\n       [2072, 2766],\n       [2061, 2765],\n       [2061, 2772],\n       [2052, 2780],\n       [2045, 2776],\n       [2040, 2771],\n       [2036, 2769],\n       [2032, 2775],\n       [2028, 2777],\n       [2027, 2775],\n       [2021, 2773],\n       [2016, 2773],\n       [2010, 2776],\n       [2007, 2783],\n       [1999, 2785],\n       [1995, 2791],\n       [1991, 2790],\n       [1983, 2797],\n       [1976, 2799],\n       [1972, 2803],\n       [1969, 2816],\n       [1957, 2820],\n       [1953, 2819],\n       [1947, 2821],\n       [1943, 2832],\n       [1936, 2833],\n       [1925, 2839],\n       [1916, 2838],\n       [1915, 2840],\n       [1915, 2845],\n       [1912, 2847],\n       [1914, 2857],\n       [1904, 2869],\n       [1904, 2878],\n       [1912, 2916],\n       [1916, 2919],\n       [1919, 2933],\n       [1928, 2936],\n       [1944, 2945],\n       [1955, 2956],\n       [1960, 2967],\n       [1966, 2971],\n       [1966, 2981],\n       [1969, 2989],\n       [1969, 3016],\n       [1983, 3025],\n       [2013, 3040],\n       [2041, 3056],\n       [2055, 3068],\n       [2064, 3080],\n       [2075, 3091],\n       [2082, 3099],\n       [2102, 3115],\n       [2119, 3139],\n       [2125, 3143],\n       [2140, 3148],\n       [2152, 3156],\n       [2153, 3166],\n       [2151, 3171],\n       [2143, 3178],\n       [2141, 3190],\n       [2122, 3195],\n       [2119, 3197],\n       [2100, 3230],\n       [2083, 3244],\n       [2072, 3255],\n       [2068, 3273],\n       [2065, 3280],\n       [2059, 3286],\n       [2054, 3288],\n       [2057, 3292],\n       [2056, 3305],\n       [2059, 3307],\n       [2063, 3315],\n       [2071, 3326],\n       [2070, 3329],\n       [2076, 3331],\n       [2086, 3339],\n       [2091, 3334],\n       [2091, 3337],\n       [2094, 3340],\n       [2097, 3338],\n       [2104, 3341],\n       [2108, 3340],\n       [2118, 3345],\n       [2126, 3354],\n       [2137, 3362],\n       [2143, 3362],\n       [2147, 3364],\n       [2154, 3355],\n       [2156, 3357],\n       [2203, 3362],\n       [2279, 3370],\n       [2380, 3382]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '023',\n     'FIPS': '34023',\n     'STATE': 'NJ',\n     'NAME': 'Middlesex',\n     'LSAD': 'County'},\n    'id': 2194,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2280, 3633],\n       [2304, 3624],\n       [2323, 3606],\n       [2348, 3590],\n       [2354, 3594],\n       [2361, 3594],\n       [2368, 3587],\n       [2382, 3583],\n       [2386, 3584],\n       [2392, 3591],\n       [2393, 3595],\n       [2398, 3598],\n       [2406, 3600],\n       [2448, 3583],\n       [2498, 3571],\n       [2511, 3558],\n       [2516, 3540],\n       [2528, 3532],\n       [2575, 3535],\n       [2577, 3538],\n       [2585, 3537],\n       [2587, 3536],\n       [2588, 3532],\n       [2620, 3507],\n       [2623, 3508],\n       [2587, 3450],\n       [2558, 3454],\n       [2551, 3454],\n       [2527, 3425],\n       [2521, 3355],\n       [2513, 3362],\n       [2512, 3369],\n       [2508, 3373],\n       [2504, 3368],\n       [2498, 3366],\n       [2484, 3363],\n       [2478, 3370],\n       [2467, 3365],\n       [2446, 3370],\n       [2443, 3360],\n       [2397, 3350],\n       [2385, 3361],\n       [2377, 3366],\n       [2380, 3376],\n       [2378, 3378],\n       [2380, 3379],\n       [2380, 3382],\n       [2279, 3370],\n       [2203, 3362],\n       [2156, 3357],\n       [2154, 3355],\n       [2147, 3364],\n       [2152, 3365],\n       [2159, 3373],\n       [2164, 3373],\n       [2169, 3381],\n       [2173, 3383],\n       [2184, 3385],\n       [2193, 3396],\n       [2199, 3397],\n       [2203, 3402],\n       [2206, 3414],\n       [2213, 3418],\n       [2217, 3429],\n       [2219, 3444],\n       [2220, 3446],\n       [2226, 3447],\n       [2229, 3455],\n       [2229, 3462],\n       [2235, 3473],\n       [2235, 3481],\n       [2236, 3487],\n       [2234, 3493],\n       [2231, 3495],\n       [2224, 3491],\n       [2220, 3485],\n       [2214, 3483],\n       [2211, 3478],\n       [2208, 3477],\n       [2202, 3485],\n       [2198, 3487],\n       [2196, 3491],\n       [2185, 3486],\n       [2175, 3475],\n       [2164, 3469],\n       [2150, 3506],\n       [2154, 3508],\n       [2160, 3507],\n       [2163, 3512],\n       [2162, 3514],\n       [2164, 3518],\n       [2162, 3524],\n       [2164, 3529],\n       [2169, 3529],\n       [2181, 3537],\n       [2184, 3542],\n       [2189, 3545],\n       [2194, 3545],\n       [2197, 3555],\n       [2200, 3560],\n       [2217, 3568],\n       [2222, 3577],\n       [2227, 3577],\n       [2228, 3583],\n       [2236, 3592],\n       [2246, 3590],\n       [2253, 3592],\n       [2253, 3606],\n       [2258, 3607],\n       [2262, 3604],\n       [2272, 3615],\n       [2268, 3621],\n       [2272, 3623],\n       [2276, 3622],\n       [2280, 3622],\n       [2282, 3626],\n       [2280, 3633]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '039',\n     'FIPS': '34039',\n     'STATE': 'NJ',\n     'NAME': 'Union',\n     'LSAD': 'County'},\n    'id': 2204,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[2941, 3976],\n        [3026, 3943],\n        [3031, 3954],\n        [3034, 3955],\n        [3033, 3958],\n        [3036, 3961],\n        [3039, 3961],\n        [3036, 3956],\n        [3042, 3955],\n        [3048, 3952],\n        [3048, 3950],\n        [3053, 3950],\n        [3057, 3931],\n        [3078, 3922],\n        [3079, 3925],\n        [3137, 3905],\n        [3135, 3901],\n        [3134, 3882],\n        [3129, 3862],\n        [3130, 3854],\n        [3135, 3849],\n        [3139, 3841],\n        [3140, 3824],\n        [3136, 3820],\n        [3130, 3830],\n        [3126, 3839],\n        [3128, 3848],\n        [3124, 3857],\n        [3122, 3856],\n        [3117, 3850],\n        [3114, 3842],\n        [3103, 3845],\n        [3094, 3839],\n        [3090, 3817],\n        [3091, 3809],\n        [3096, 3798],\n        [3106, 3785],\n        [3117, 3779],\n        [3133, 3751],\n        [3131, 3749],\n        [3122, 3749],\n        [3097, 3759],\n        [3088, 3760],\n        [3074, 3755],\n        [3038, 3749],\n        [3022, 3744],\n        [3011, 3732],\n        [3010, 3724],\n        [2998, 3722],\n        [2982, 3725],\n        [2981, 3730],\n        [2949, 3742],\n        [2940, 3748],\n        [2935, 3754],\n        [2928, 3754],\n        [2921, 3765],\n        [2920, 3772],\n        [2919, 3818],\n        [2926, 3837],\n        [2938, 3859],\n        [2952, 3877],\n        [2957, 3891],\n        [2957, 3896],\n        [2953, 3901],\n        [2946, 3897],\n        [2945, 3895],\n        [2938, 3897],\n        [2936, 3900],\n        [2919, 3907],\n        [2925, 3922],\n        [2941, 3976]]],\n      [[[3156, 3866],\n        [3162, 3860],\n        [3164, 3854],\n        [3162, 3836],\n        [3157, 3835],\n        [3152, 3842],\n        [3152, 3864],\n        [3156, 3866]]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '005',\n     'FIPS': '36005',\n     'STATE': 'NY',\n     'NAME': 'Bronx',\n     'LSAD': 'County'},\n    'id': 2199,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2797, 3795],\n       [2802, 3794],\n       [2806, 3789],\n       [2803, 3784],\n       [2803, 3780],\n       [2832, 3760],\n       [2831, 3752],\n       [2844, 3745],\n       [2802, 3666],\n       [2786, 3575],\n       [2766, 3578],\n       [2747, 3549],\n       [2722, 3481],\n       [2694, 3468],\n       [2685, 3461],\n       [2613, 3446],\n       [2587, 3450],\n       [2657, 3563],\n       [2647, 3588],\n       [2645, 3598],\n       [2651, 3629],\n       [2650, 3633],\n       [2643, 3638],\n       [2621, 3637],\n       [2614, 3633],\n       [2610, 3626],\n       [2606, 3623],\n       [2596, 3622],\n       [2589, 3623],\n       [2583, 3633],\n       [2580, 3648],\n       [2582, 3665],\n       [2586, 3675],\n       [2592, 3684],\n       [2596, 3695],\n       [2606, 3710],\n       [2607, 3723],\n       [2632, 3707],\n       [2633, 3699],\n       [2636, 3695],\n       [2640, 3696],\n       [2650, 3692],\n       [2653, 3694],\n       [2657, 3703],\n       [2662, 3706],\n       [2669, 3705],\n       [2672, 3702],\n       [2675, 3703],\n       [2679, 3692],\n       [2677, 3687],\n       [2683, 3677],\n       [2686, 3679],\n       [2690, 3677],\n       [2693, 3687],\n       [2690, 3703],\n       [2692, 3711],\n       [2708, 3736],\n       [2710, 3742],\n       [2718, 3744],\n       [2722, 3747],\n       [2727, 3755],\n       [2733, 3760],\n       [2742, 3763],\n       [2769, 3765],\n       [2775, 3774],\n       [2780, 3774],\n       [2781, 3781],\n       [2786, 3778],\n       [2785, 3780],\n       [2787, 3781],\n       [2788, 3785],\n       [2792, 3785],\n       [2792, 3789],\n       [2797, 3795]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '017',\n     'FIPS': '34017',\n     'STATE': 'NJ',\n     'NAME': 'Hudson',\n     'LSAD': 'County'},\n    'id': 2205,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2711, 3458],\n       [2720, 3444],\n       [2723, 3411],\n       [2734, 3388],\n       [2744, 3372],\n       [2735, 3353],\n       [2722, 3335],\n       [2689, 3301],\n       [2659, 3263],\n       [2658, 3265],\n       [2644, 3255],\n       [2622, 3231],\n       [2617, 3238],\n       [2611, 3241],\n       [2605, 3240],\n       [2587, 3225],\n       [2562, 3211],\n       [2556, 3213],\n       [2531, 3196],\n       [2515, 3192],\n       [2502, 3179],\n       [2482, 3176],\n       [2462, 3166],\n       [2457, 3167],\n       [2451, 3178],\n       [2449, 3189],\n       [2454, 3200],\n       [2468, 3214],\n       [2470, 3233],\n       [2461, 3257],\n       [2488, 3279],\n       [2506, 3279],\n       [2515, 3290],\n       [2525, 3345],\n       [2535, 3360],\n       [2537, 3369],\n       [2536, 3396],\n       [2529, 3398],\n       [2528, 3403],\n       [2530, 3426],\n       [2546, 3446],\n       [2559, 3453],\n       [2568, 3452],\n       [2574, 3446],\n       [2599, 3440],\n       [2647, 3446],\n       [2696, 3458],\n       [2711, 3458]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '085',\n     'FIPS': '36085',\n     'STATE': 'NY',\n     'NAME': 'Richmond',\n     'LSAD': 'County'},\n    'id': 2210,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2891, 3633],\n       [2906, 3626],\n       [2913, 3615],\n       [2925, 3611],\n       [2933, 3596],\n       [2934, 3590],\n       [2932, 3587],\n       [2937, 3577],\n       [2936, 3574],\n       [2950, 3564],\n       [2949, 3562],\n       [2952, 3559],\n       [2950, 3557],\n       [2961, 3549],\n       [2959, 3546],\n       [2966, 3541],\n       [2966, 3533],\n       [2972, 3523],\n       [2976, 3529],\n       [2978, 3525],\n       [2982, 3528],\n       [2983, 3527],\n       [3005, 3546],\n       [3013, 3548],\n       [3017, 3522],\n       [3020, 3523],\n       [3025, 3502],\n       [3029, 3503],\n       [3032, 3488],\n       [3028, 3487],\n       [3029, 3480],\n       [3021, 3477],\n       [3031, 3460],\n       [3033, 3447],\n       [3043, 3449],\n       [3064, 3420],\n       [3063, 3379],\n       [3040, 3344],\n       [2998, 3317],\n       [2911, 3300],\n       [2902, 3305],\n       [2894, 3314],\n       [2834, 3308],\n       [2819, 3309],\n       [2804, 3316],\n       [2803, 3323],\n       [2819, 3347],\n       [2817, 3357],\n       [2806, 3367],\n       [2774, 3374],\n       [2764, 3390],\n       [2760, 3413],\n       [2766, 3436],\n       [2775, 3454],\n       [2795, 3478],\n       [2792, 3516],\n       [2788, 3521],\n       [2793, 3518],\n       [2798, 3520],\n       [2799, 3522],\n       [2816, 3536],\n       [2825, 3557],\n       [2831, 3566],\n       [2852, 3568],\n       [2862, 3574],\n       [2866, 3570],\n       [2866, 3575],\n       [2869, 3589],\n       [2878, 3603],\n       [2876, 3630],\n       [2878, 3628],\n       [2889, 3633],\n       [2891, 3633]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '047',\n     'FIPS': '36047',\n     'STATE': 'NY',\n     'NAME': 'Kings',\n     'LSAD': 'County'},\n    'id': 2203,\n    'type': 'Feature'},\n   {'geometry': {'type': 'MultiPolygon',\n     'coordinates': [[[[2919, 3907],\n        [2936, 3900],\n        [2938, 3897],\n        [2945, 3895],\n        [2946, 3897],\n        [2953, 3901],\n        [2957, 3896],\n        [2957, 3891],\n        [2952, 3877],\n        [2938, 3859],\n        [2926, 3837],\n        [2919, 3813],\n        [2921, 3765],\n        [2928, 3754],\n        [2935, 3754],\n        [2940, 3748],\n        [2949, 3742],\n        [2952, 3732],\n        [2945, 3727],\n        [2941, 3721],\n        [2927, 3705],\n        [2921, 3708],\n        [2918, 3706],\n        [2916, 3709],\n        [2915, 3705],\n        [2911, 3701],\n        [2912, 3697],\n        [2916, 3695],\n        [2915, 3693],\n        [2903, 3681],\n        [2887, 3656],\n        [2882, 3645],\n        [2878, 3640],\n        [2876, 3630],\n        [2878, 3603],\n        [2869, 3589],\n        [2866, 3575],\n        [2866, 3570],\n        [2862, 3574],\n        [2852, 3568],\n        [2830, 3565],\n        [2816, 3536],\n        [2799, 3522],\n        [2798, 3520],\n        [2793, 3518],\n        [2787, 3523],\n        [2786, 3532],\n        [2790, 3545],\n        [2795, 3548],\n        [2797, 3561],\n        [2793, 3571],\n        [2786, 3575],\n        [2802, 3666],\n        [2875, 3801],\n        [2889, 3842],\n        [2919, 3907]]],\n      [[[2763, 3558],\n        [2766, 3555],\n        [2757, 3535],\n        [2753, 3539],\n        [2763, 3558]]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '061',\n     'FIPS': '36061',\n     'STATE': 'NY',\n     'NAME': 'New York',\n     'LSAD': 'County'},\n    'id': 2200,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[3088, 3760],\n       [3097, 3759],\n       [3122, 3749],\n       [3131, 3749],\n       [3133, 3751],\n       [3140, 3740],\n       [3148, 3740],\n       [3159, 3751],\n       [3190, 3709],\n       [3190, 3712],\n       [3228, 3682],\n       [3255, 3660],\n       [3257, 3655],\n       [3258, 3633],\n       [3247, 3611],\n       [3228, 3606],\n       [3214, 3600],\n       [3219, 3578],\n       [3222, 3558],\n       [3220, 3551],\n       [3221, 3519],\n       [3217, 3493],\n       [3222, 3468],\n       [3217, 3463],\n       [3199, 3457],\n       [3198, 3446],\n       [3201, 3434],\n       [3197, 3432],\n       [3198, 3437],\n       [3198, 3438],\n       [3194, 3438],\n       [3193, 3431],\n       [3162, 3415],\n       [3163, 3394],\n       [3171, 3387],\n       [3178, 3386],\n       [3178, 3384],\n       [3189, 3389],\n       [3190, 3387],\n       [3192, 3388],\n       [3203, 3370],\n       [3203, 3354],\n       [3204, 3352],\n       [3195, 3352],\n       [3189, 3349],\n       [3179, 3339],\n       [3181, 3347],\n       [3149, 3348],\n       [3103, 3336],\n       [3063, 3322],\n       [2998, 3290],\n       [2908, 3256],\n       [2909, 3278],\n       [2920, 3289],\n       [2915, 3298],\n       [2911, 3300],\n       [2998, 3317],\n       [3040, 3344],\n       [3063, 3379],\n       [3064, 3420],\n       [3043, 3449],\n       [3033, 3447],\n       [3031, 3460],\n       [3021, 3477],\n       [3029, 3480],\n       [3028, 3487],\n       [3032, 3488],\n       [3029, 3503],\n       [3025, 3502],\n       [3020, 3523],\n       [3017, 3522],\n       [3013, 3548],\n       [3005, 3546],\n       [2983, 3527],\n       [2982, 3528],\n       [2978, 3525],\n       [2976, 3529],\n       [2972, 3523],\n       [2966, 3533],\n       [2966, 3541],\n       [2959, 3546],\n       [2961, 3549],\n       [2950, 3557],\n       [2952, 3559],\n       [2949, 3562],\n       [2950, 3564],\n       [2936, 3574],\n       [2937, 3577],\n       [2932, 3587],\n       [2934, 3590],\n       [2933, 3596],\n       [2925, 3611],\n       [2913, 3615],\n       [2906, 3626],\n       [2891, 3633],\n       [2889, 3633],\n       [2878, 3628],\n       [2876, 3630],\n       [2878, 3640],\n       [2882, 3645],\n       [2887, 3656],\n       [2903, 3681],\n       [2915, 3693],\n       [2916, 3695],\n       [2912, 3697],\n       [2911, 3701],\n       [2915, 3705],\n       [2916, 3709],\n       [2918, 3706],\n       [2921, 3708],\n       [2927, 3705],\n       [2941, 3721],\n       [2945, 3727],\n       [2952, 3732],\n       [2949, 3742],\n       [2981, 3730],\n       [2982, 3725],\n       [2998, 3722],\n       [3010, 3724],\n       [3011, 3732],\n       [3022, 3744],\n       [3038, 3749],\n       [3074, 3755],\n       [3088, 3760]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '081',\n     'FIPS': '36081',\n     'STATE': 'NY',\n     'NAME': 'Queens',\n     'LSAD': 'County'},\n    'id': 2202,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2801, 3129],\n       [2811, 3126],\n       [2828, 3114],\n       [2853, 3059],\n       [2855, 2998],\n       [2863, 2928],\n       [2863, 2883],\n       [2855, 2790],\n       [2848, 2752],\n       [2831, 2672],\n       [2778, 2453],\n       [2772, 2416],\n       [2775, 2412],\n       [2765, 2418],\n       [2763, 2417],\n       [2757, 2420],\n       [2749, 2418],\n       [2740, 2412],\n       [2738, 2405],\n       [2733, 2403],\n       [2718, 2389],\n       [2700, 2402],\n       [2684, 2424],\n       [2685, 2431],\n       [2683, 2435],\n       [2685, 2438],\n       [2681, 2448],\n       [2682, 2464],\n       [2680, 2465],\n       [2677, 2463],\n       [2670, 2472],\n       [2671, 2475],\n       [2665, 2480],\n       [2603, 2407],\n       [2597, 2409],\n       [2596, 2413],\n       [2592, 2416],\n       [2591, 2419],\n       [2588, 2423],\n       [2571, 2424],\n       [2561, 2430],\n       [2556, 2429],\n       [2551, 2431],\n       [2546, 2430],\n       [2539, 2433],\n       [2533, 2432],\n       [2525, 2434],\n       [2513, 2429],\n       [2503, 2429],\n       [2495, 2427],\n       [2483, 2429],\n       [2480, 2432],\n       [2473, 2433],\n       [2465, 2445],\n       [2467, 2453],\n       [2469, 2454],\n       [2470, 2466],\n       [2458, 2494],\n       [2453, 2500],\n       [2447, 2503],\n       [2443, 2503],\n       [2445, 2509],\n       [2443, 2518],\n       [2446, 2524],\n       [2442, 2535],\n       [2438, 2540],\n       [2229, 2548],\n       [2138, 2464],\n       [2054, 2391],\n       [2016, 2370],\n       [1927, 2567],\n       [1948, 2575],\n       [1952, 2574],\n       [1954, 2562],\n       [1957, 2562],\n       [1968, 2569],\n       [1985, 2576],\n       [1991, 2573],\n       [2002, 2581],\n       [2011, 2600],\n       [2023, 2615],\n       [2025, 2624],\n       [2031, 2632],\n       [2069, 2652],\n       [2120, 2682],\n       [2119, 2689],\n       [2114, 2695],\n       [2112, 2702],\n       [2146, 2700],\n       [2150, 2698],\n       [2249, 2752],\n       [2248, 2769],\n       [2271, 2799],\n       [2460, 2996],\n       [2458, 3003],\n       [2461, 3006],\n       [2461, 3042],\n       [2479, 3067],\n       [2481, 3065],\n       [2483, 3068],\n       [2490, 3067],\n       [2497, 3080],\n       [2494, 3083],\n       [2494, 3084],\n       [2516, 3073],\n       [2521, 3060],\n       [2521, 3056],\n       [2518, 3054],\n       [2520, 3050],\n       [2527, 3057],\n       [2539, 3061],\n       [2548, 3073],\n       [2567, 3089],\n       [2567, 3076],\n       [2564, 3074],\n       [2566, 3071],\n       [2574, 3079],\n       [2578, 3075],\n       [2580, 3072],\n       [2584, 3075],\n       [2592, 3071],\n       [2599, 3073],\n       [2614, 3079],\n       [2620, 3086],\n       [2624, 3088],\n       [2651, 3070],\n       [2693, 3056],\n       [2711, 3047],\n       [2736, 3026],\n       [2752, 3018],\n       [2812, 3003],\n       [2824, 3003],\n       [2828, 3019],\n       [2834, 3064],\n       [2813, 3106],\n       [2796, 3120],\n       [2796, 3124],\n       [2801, 3129]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '025',\n     'FIPS': '34025',\n     'STATE': 'NJ',\n     'NAME': 'Monmouth',\n     'LSAD': 'County'},\n    'id': 2195,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[2229, 2548],\n       [2438, 2540],\n       [2442, 2535],\n       [2446, 2524],\n       [2443, 2518],\n       [2445, 2509],\n       [2443, 2503],\n       [2447, 2503],\n       [2453, 2500],\n       [2458, 2494],\n       [2470, 2466],\n       [2469, 2454],\n       [2467, 2453],\n       [2465, 2445],\n       [2473, 2433],\n       [2480, 2432],\n       [2483, 2429],\n       [2495, 2427],\n       [2503, 2429],\n       [2513, 2429],\n       [2525, 2434],\n       [2533, 2432],\n       [2539, 2433],\n       [2546, 2430],\n       [2551, 2431],\n       [2556, 2429],\n       [2561, 2430],\n       [2571, 2424],\n       [2588, 2423],\n       [2591, 2419],\n       [2592, 2416],\n       [2596, 2413],\n       [2597, 2409],\n       [2603, 2407],\n       [2665, 2480],\n       [2671, 2475],\n       [2670, 2472],\n       [2677, 2463],\n       [2680, 2465],\n       [2682, 2464],\n       [2681, 2448],\n       [2685, 2438],\n       [2683, 2435],\n       [2685, 2431],\n       [2684, 2424],\n       [2700, 2402],\n       [2718, 2389],\n       [2733, 2403],\n       [2738, 2405],\n       [2740, 2412],\n       [2749, 2418],\n       [2757, 2420],\n       [2763, 2417],\n       [2765, 2418],\n       [2776, 2411],\n       [2773, 2409],\n       [2764, 2374],\n       [2728, 2180],\n       [2709, 2050],\n       [2689, 1840],\n       [2680, 1779],\n       [2681, 1770],\n       [2678, 1763],\n       [2656, 1727],\n       [2615, 1630],\n       [2544, 1509],\n       [2471, 1376],\n       [2459, 1363],\n       [2418, 1299],\n       [2396, 1277],\n       [2381, 1273],\n       [2378, 1286],\n       [2369, 1285],\n       [2367, 1272],\n       [2353, 1282],\n       [2346, 1284],\n       [2330, 1285],\n       [2306, 1283],\n       [2296, 1276],\n       [2267, 1270],\n       [2234, 1349],\n       [2224, 1363],\n       [2216, 1366],\n       [2215, 1368],\n       [2216, 1378],\n       [2214, 1380],\n       [2219, 1390],\n       [2214, 1393],\n       [2212, 1402],\n       [2216, 1405],\n       [2221, 1405],\n       [2224, 1406],\n       [2226, 1404],\n       [2232, 1404],\n       [2235, 1408],\n       [2238, 1409],\n       [2242, 1417],\n       [2244, 1432],\n       [2250, 1450],\n       [2253, 1454],\n       [2254, 1789],\n       [2167, 1994],\n       [2084, 2203],\n       [2052, 2289],\n       [2016, 2370],\n       [2054, 2391],\n       [2138, 2464],\n       [2229, 2548]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '029',\n     'FIPS': '34029',\n     'STATE': 'NJ',\n     'NAME': 'Ocean',\n     'LSAD': 'County'},\n    'id': 2176,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[3554, 3986],\n       [3563, 3979],\n       [3567, 3971],\n       [3568, 3972],\n       [3574, 3953],\n       [3579, 3944],\n       [3583, 3941],\n       [3585, 3898],\n       [3597, 3881],\n       [3604, 3879],\n       [3602, 3864],\n       [3612, 3843],\n       [3615, 3828],\n       [3661, 3502],\n       [3660, 3492],\n       [3660, 3476],\n       [3661, 3473],\n       [3658, 3473],\n       [3661, 3384],\n       [3622, 3372],\n       [3572, 3360],\n       [3440, 3315],\n       [3442, 3337],\n       [3428, 3340],\n       [3388, 3342],\n       [3336, 3332],\n       [3179, 3335],\n       [3179, 3339],\n       [3189, 3349],\n       [3195, 3352],\n       [3204, 3352],\n       [3203, 3354],\n       [3203, 3370],\n       [3192, 3388],\n       [3190, 3387],\n       [3189, 3389],\n       [3178, 3384],\n       [3178, 3386],\n       [3171, 3387],\n       [3163, 3394],\n       [3162, 3415],\n       [3193, 3431],\n       [3194, 3438],\n       [3198, 3438],\n       [3198, 3437],\n       [3197, 3432],\n       [3201, 3434],\n       [3198, 3446],\n       [3199, 3457],\n       [3217, 3463],\n       [3222, 3468],\n       [3217, 3493],\n       [3221, 3519],\n       [3220, 3551],\n       [3222, 3558],\n       [3219, 3578],\n       [3214, 3600],\n       [3228, 3606],\n       [3247, 3611],\n       [3258, 3633],\n       [3256, 3658],\n       [3190, 3712],\n       [3190, 3709],\n       [3159, 3751],\n       [3180, 3790],\n       [3179, 3801],\n       [3217, 3851],\n       [3220, 3859],\n       [3214, 3875],\n       [3216, 3877],\n       [3239, 3884],\n       [3294, 3859],\n       [3323, 3872],\n       [3325, 3900],\n       [3344, 3928],\n       [3355, 3938],\n       [3365, 3941],\n       [3379, 3938],\n       [3402, 3947],\n       [3411, 3956],\n       [3448, 3972],\n       [3454, 3972],\n       [3480, 3959],\n       [3522, 3970],\n       [3528, 3967],\n       [3550, 3977],\n       [3554, 3986]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '059',\n     'FIPS': '36059',\n     'STATE': 'NY',\n     'NAME': 'Nassau',\n     'LSAD': 'County'},\n    'id': 2201,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[1749, 1707],\n       [1837, 1634],\n       [1842, 1625],\n       [1846, 1623],\n       [1851, 1615],\n       [1854, 1606],\n       [1854, 1601],\n       [1860, 1591],\n       [1863, 1569],\n       [1861, 1566],\n       [1862, 1563],\n       [1860, 1560],\n       [1863, 1559],\n       [1863, 1554],\n       [1862, 1550],\n       [1865, 1546],\n       [1861, 1538],\n       [1863, 1530],\n       [1861, 1521],\n       [1866, 1520],\n       [1868, 1518],\n       [1868, 1512],\n       [1871, 1511],\n       [1874, 1515],\n       [1878, 1514],\n       [1878, 1509],\n       [1888, 1510],\n       [1889, 1505],\n       [1890, 1504],\n       [1893, 1505],\n       [1896, 1513],\n       [1900, 1513],\n       [1902, 1507],\n       [1902, 1501],\n       [1906, 1499],\n       [1910, 1503],\n       [1911, 1509],\n       [1914, 1512],\n       [1916, 1512],\n       [1926, 1505],\n       [1929, 1506],\n       [1936, 1502],\n       [1954, 1488],\n       [1964, 1484],\n       [1966, 1481],\n       [1969, 1471],\n       [1975, 1468],\n       [1983, 1458],\n       [1992, 1459],\n       [2000, 1455],\n       [2015, 1457],\n       [2022, 1442],\n       [2033, 1434],\n       [2031, 1425],\n       [2034, 1417],\n       [2037, 1413],\n       [2045, 1411],\n       [2051, 1405],\n       [2054, 1403],\n       [2059, 1403],\n       [2067, 1411],\n       [2072, 1412],\n       [2076, 1404],\n       [2080, 1402],\n       [2088, 1403],\n       [2092, 1395],\n       [2099, 1391],\n       [2101, 1381],\n       [2103, 1379],\n       [2108, 1379],\n       [2113, 1383],\n       [2120, 1382],\n       [2126, 1372],\n       [2130, 1369],\n       [2134, 1371],\n       [2139, 1377],\n       [2144, 1379],\n       [2148, 1379],\n       [2150, 1376],\n       [2152, 1366],\n       [2154, 1362],\n       [2158, 1361],\n       [2162, 1367],\n       [2162, 1378],\n       [2164, 1382],\n       [2169, 1384],\n       [2172, 1383],\n       [2176, 1378],\n       [2172, 1363],\n       [2178, 1354],\n       [2182, 1350],\n       [2185, 1349],\n       [2190, 1353],\n       [2190, 1359],\n       [2184, 1369],\n       [2184, 1374],\n       [2187, 1376],\n       [2191, 1377],\n       [2199, 1373],\n       [2201, 1373],\n       [2209, 1380],\n       [2214, 1380],\n       [2216, 1378],\n       [2215, 1368],\n       [2216, 1366],\n       [2224, 1363],\n       [2234, 1349],\n       [2267, 1270],\n       [2296, 1276],\n       [2306, 1283],\n       [2330, 1285],\n       [2346, 1284],\n       [2353, 1282],\n       [2367, 1272],\n       [2365, 1261],\n       [2373, 1242],\n       [2378, 1240],\n       [2382, 1233],\n       [2378, 1218],\n       [2334, 1144],\n       [2287, 1088],\n       [2229, 1041],\n       [2227, 1018],\n       [2221, 1010],\n       [2152, 980],\n       [2062, 921],\n       [2033, 896],\n       [2029, 900],\n       [2023, 900],\n       [2011, 893],\n       [1994, 894],\n       [1967, 914],\n       [1960, 913],\n       [1918, 882],\n       [1913, 881],\n       [1900, 886],\n       [1889, 888],\n       [1885, 887],\n       [1879, 882],\n       [1875, 875],\n       [1870, 874],\n       [1863, 877],\n       [1862, 879],\n       [1864, 890],\n       [1849, 891],\n       [1845, 889],\n       [1845, 881],\n       [1843, 876],\n       [1840, 875],\n       [1838, 877],\n       [1840, 883],\n       [1840, 887],\n       [1837, 890],\n       [1835, 890],\n       [1831, 884],\n       [1828, 883],\n       [1824, 885],\n       [1820, 883],\n       [1816, 878],\n       [1810, 879],\n       [1805, 875],\n       [1802, 878],\n       [1798, 885],\n       [1794, 884],\n       [1791, 878],\n       [1789, 880],\n       [1788, 886],\n       [1785, 886],\n       [1782, 880],\n       [1778, 881],\n       [1773, 886],\n       [1775, 892],\n       [1773, 893],\n       [1764, 888],\n       [1758, 892],\n       [1748, 893],\n       [1744, 888],\n       [1735, 885],\n       [1726, 886],\n       [1725, 891],\n       [1720, 894],\n       [1709, 889],\n       [1706, 893],\n       [1699, 894],\n       [1696, 897],\n       [1688, 894],\n       [1687, 894],\n       [1689, 902],\n       [1679, 909],\n       [1676, 908],\n       [1671, 909],\n       [1666, 905],\n       [1664, 908],\n       [1659, 908],\n       [1656, 911],\n       [1651, 909],\n       [1646, 904],\n       [1643, 907],\n       [1629, 907],\n       [1627, 909],\n       [1620, 905],\n       [1611, 916],\n       [1602, 924],\n       [1582, 926],\n       [1576, 930],\n       [1568, 932],\n       [1568, 940],\n       [1563, 948],\n       [1562, 968],\n       [1564, 974],\n       [1564, 981],\n       [1570, 1000],\n       [1569, 1012],\n       [1579, 1031],\n       [1581, 1041],\n       [1580, 1055],\n       [1572, 1075],\n       [1573, 1080],\n       [1572, 1086],\n       [1577, 1095],\n       [1580, 1106],\n       [1579, 1112],\n       [1574, 1123],\n       [1573, 1127],\n       [1575, 1130],\n       [1387, 1300],\n       [1749, 1707]]]},\n    'properties': {'STATE_FIPS': '34',\n     'COUNTY_FIP': '001',\n     'FIPS': '34001',\n     'STATE': 'NJ',\n     'NAME': 'Atlantic',\n     'LSAD': 'County'},\n    'id': 2132,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[812, 261],\n       [817, 258],\n       [823, 260],\n       [830, 256],\n       [829, 253],\n       [832, 246],\n       [841, 253],\n       [852, 234],\n       [855, 234],\n       [863, 248],\n       [865, 247],\n       [867, 241],\n       [865, 234],\n       [872, 231],\n       [877, 233],\n       [881, 240],\n       [884, 239],\n       [887, 237],\n       [893, 238],\n       [897, 245],\n       [904, 244],\n       [909, 239],\n       [908, 233],\n       [925, 218],\n       [911, 191],\n       [922, 169],\n       [982, 102],\n       [1027, 41],\n       [1067, 0],\n       [1088, -29],\n       [1134, -61],\n       [1170, -75],\n       [1200, -74],\n       [1224, -63],\n       [1229, -53],\n       [1224, -36],\n       [1229, -35],\n       [1235, -47],\n       [1242, -80],\n       [319, -80],\n       [314, 0],\n       [313, 14],\n       [557, 24],\n       [566, 35],\n       [573, 39],\n       [577, 38],\n       [580, 39],\n       [585, 47],\n       [584, 51],\n       [607, 62],\n       [625, 105],\n       [632, 110],\n       [635, 109],\n       [640, 111],\n       [642, 113],\n       [645, 122],\n       [651, 125],\n       [655, 131],\n       [654, 143],\n       [659, 152],\n       [670, 156],\n       [688, 166],\n       [695, 162],\n       [716, 169],\n       [724, 169],\n       [732, 165],\n       [741, 169],\n       [751, 171],\n       [753, 174],\n       [757, 171],\n       [759, 179],\n       [770, 176],\n       [770, 182],\n       [775, 181],\n       [776, 177],\n       [779, 178],\n       [781, 180],\n       [778, 187],\n       [780, 192],\n       [783, 193],\n       [784, 195],\n       [781, 200],\n       [786, 213],\n       [783, 211],\n       [779, 215],\n       [783, 218],\n       [785, 221],\n       [781, 233],\n       [785, 238],\n       [792, 244],\n       [793, 250],\n       [796, 251],\n       [799, 247],\n       [808, 249],\n       [810, 260],\n       [812, 261]]]},\n    'properties': {'STATE_FIPS': '10',\n     'COUNTY_FIP': '005',\n     'FIPS': '10005',\n     'STATE': 'DE',\n     'NAME': 'Sussex',\n     'LSAD': 'County'},\n    'id': 2175,\n    'type': 'Feature'},\n   {'geometry': {'type': 'Polygon',\n     'coordinates': [[[4106, 4092],\n       [4117, 4081],\n       [4159, 4083],\n       [4176, 4076],\n       [4176, 3486],\n       [4096, 3462],\n       [3974, 3424],\n       [3896, 3406],\n       [3832, 3405],\n       [3827, 3408],\n       [3813, 3434],\n       [3766, 3424],\n       [3707, 3399],\n       [3661, 3384],\n       [3658, 3473],\n       [3661, 3473],\n       [3660, 3476],\n       [3660, 3492],\n       [3661, 3502],\n       [3615, 3828],\n       [3612, 3843],\n       [3602, 3864],\n       [3604, 3879],\n       [3597, 3881],\n       [3585, 3898],\n       [3583, 3941],\n       [3579, 3944],\n       [3574, 3953],\n       [3568, 3972],\n       [3567, 3971],\n       [3563, 3979],\n       [3554, 3986],\n       [3562, 4023],\n       [3571, 4031],\n       [3581, 4023],\n       [3603, 4015],\n       [3642, 4009],\n       [3652, 3999],\n       [3654, 3983],\n       [3687, 3981],\n       [3691, 3990],\n       [3690, 4023],\n       [3694, 4046],\n       [3696, 4048],\n       [3706, 4049],\n       [3733, 4014],\n       [3745, 4003],\n       [3764, 3993],\n       [3775, 3991],\n       [3777, 3995],\n       [3795, 3999],\n       [3848, 3989],\n       [3944, 3952],\n       [4061, 3998],\n       [4065, 4010],\n       [4067, 4050],\n       [4053, 4061],\n       [4046, 4074],\n       [4078, 4071],\n       [4096, 4085],\n       [4106, 4092]]]},\n    'properties': {'STATE_FIPS': '36',\n     'COUNTY_FIP': '103',\n     'FIPS': '36103',\n     'STATE': 'NY',\n     'NAME': 'Suffolk',\n     'LSAD': 'County'},\n    'id': 2231,\n    'type': 'Feature'}],\n  'type': 'FeatureCollection'}}"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Cloud-Optimized Geospatial Formats Overview",
    "section": "",
    "text": "These slides were generated with https://quarto.org/docs/presentations/revealjs. Source: https://github.com/cloudnativegeo/cloud-optimized-geospatial-formats-guide."
  },
  {
    "objectID": "overview.html#what-does-cloud-optimized-mean-1",
    "href": "overview.html#what-does-cloud-optimized-mean-1",
    "title": "Cloud-Optimized Geospatial Formats Overview",
    "section": "What Does Cloud-Optimized Mean?",
    "text": "What Does Cloud-Optimized Mean?\n\nFile metadata in one read\nWhen accessing data over the internet, such as when data is in cloud storage, latency is high when compared with local storage so it is preferable to fetch lots of data in fewer reads.\nAn easy win is metadata in one read, which can be used to read a cloud-native dataset.\nA cloud-native dataset is one with small addressable chunks via files, internal tiles, or both."
  },
  {
    "objectID": "overview.html#what-does-cloud-optimized-mean-2",
    "href": "overview.html#what-does-cloud-optimized-mean-2",
    "title": "Cloud-Optimized Geospatial Formats Overview",
    "section": "What Does Cloud-Optimized Mean?",
    "text": "What Does Cloud-Optimized Mean?\n\n\n\nAccessible over HTTP using range requests.\nThis makes it compatible with object storage (a file storage alternative to local disk) and thus accessible via HTTP, from many compute instances.\nSupports lazy access and intelligent subsetting.\nIntegrates with high-level analysis libraries and distributed frameworks.\n\n\n\n\n\n\n\nimage credit: Ryan Abernathey"
  },
  {
    "objectID": "overview.html#what-are-cogs-1",
    "href": "overview.html#what-are-cogs-1",
    "title": "Cloud-Optimized Geospatial Formats Overview",
    "section": "What are COGs?",
    "text": "What are COGs?\n\n\n\nCOGs have internal file directories (IFDs) which are used to tell clients where to find different overview levels and data within the file.\nClients can use this metadata to read only the data they need to visualize or calculate.\nThis internal organization is friendly for consumption by clients issuing HTTP GET range request (“bytes: start_offset-end_offset” HTTP header)\n\n\n\n\n\n\n\nimage source: https://medium.com/devseed/cog-talk-part-1-whats-new-941facbcd3d1"
  },
  {
    "objectID": "overview.html#zarr-specs-in-development",
    "href": "overview.html#zarr-specs-in-development",
    "title": "Cloud-Optimized Geospatial Formats Overview",
    "section": "Zarr Specs in Development",
    "text": "Zarr Specs in Development\n\nV2 and older specs exist, however,\nA cross-organization working group has just formed to establish a GeoZarr standards working group, organized by Brianna Pagán (NASA) and includes representatives from many other orgs in the industry.\nThe GeoZarr spec defines conventions for how geospatial data should be organized in a Zarr store. The spec details how the Zarr DataArray and DataSet metadata, and subsequent organization of data, must be in order to be conformant as GeoZarr archive.\nThere is a proposal for Zarr v3 which will address challenges in language support, and storage organization to address the issues of high-latency reads and volume of reads for the many objects stored.\nThere is recent work on a parquet alternative to JSON for indexing."
  },
  {
    "objectID": "overview.html#copc-cloud-optimized-point-clouds",
    "href": "overview.html#copc-cloud-optimized-point-clouds",
    "title": "Cloud-Optimized Geospatial Formats Overview",
    "section": "COPC (Cloud-Optimized Point Clouds)",
    "text": "COPC (Cloud-Optimized Point Clouds)\n\n\n\nimage source: https://copc.io/\n\nPoint clouds are a set of data points in space, such as gathered from LiDAR measurements.\nCOPC is a valid LAZ file.\nSimilar to COGs but for point clouds: COPC is just one file, but data is reorganized into a clustered octree instead of regularly gridded overviews.\n2 key features:\n\nSupport for partial decompression via storage of data in a series of chunks\nVariable-length records (VLRs) can store application-specific metadata of any kind. VLRs describe the octree structure.\n\nLimitation: Not all attribute types are compatible."
  },
  {
    "objectID": "overview.html#not-quite",
    "href": "overview.html#not-quite",
    "title": "Cloud-Optimized Geospatial Formats Overview",
    "section": "Not Quite",
    "text": "Not Quite\n\nThese formats and their tooling are in active development\nSome formats were not mentioned, such as EPT, geopkg, tiledb, Cloud-Optimized HDF5. This presentation was scoped to those known best by the authors.\nThis site will continue to be updated with new content."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-examples.html",
    "href": "cloud-optimized-geotiffs/cogs-examples.html",
    "title": "Examples of Working with COGs",
    "section": "",
    "text": "The packages needed for this notebook can be installed with conda or mamba. Using the environment.yml from this folder run:\nconda create -f environment.yml\nor\nmamba create -f environment.yml\nThis notebook has been tested to work with the listed Conda environment."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-examples.html#environment",
    "href": "cloud-optimized-geotiffs/cogs-examples.html#environment",
    "title": "Examples of Working with COGs",
    "section": "",
    "text": "The packages needed for this notebook can be installed with conda or mamba. Using the environment.yml from this folder run:\nconda create -f environment.yml\nor\nmamba create -f environment.yml\nThis notebook has been tested to work with the listed Conda environment."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-examples.html#setup",
    "href": "cloud-optimized-geotiffs/cogs-examples.html#setup",
    "title": "Examples of Working with COGs",
    "section": "Setup",
    "text": "Setup\nFor demonstrating some COG concepts, we will download a regular GeoTIFF, create a Cloud-Optimized GeoTIFF and explore how they are different.\nFirst we use the earthaccess library to setup credentials to fetch data from NASA’s EarthData catalog.\n\nimport earthaccess\nimport rasterio\nfrom rasterio.plot import show\nfrom rio_cogeo import cog_validate, cog_info\n\n/Users/kyle/local/micromamba/envs/coguide-cog/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\n\nearthaccess.login()\n\nEARTHDATA_USERNAME and EARTHDATA_PASSWORD are not set in the current environment, try setting them or use a different strategy (netrc, interactive)\nYou're now authenticated with NASA Earthdata Login\nUsing token with expiration date: 10/24/2023\nUsing .netrc file for EDL\n\n\n&lt;earthaccess.auth.Auth at 0x10427d390&gt;"
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-examples.html#download-a-geotiff-from-earthdata",
    "href": "cloud-optimized-geotiffs/cogs-examples.html#download-a-geotiff-from-earthdata",
    "title": "Examples of Working with COGs",
    "section": "Download a GeoTIFF from EarthData",
    "text": "Download a GeoTIFF from EarthData\nNote: The whole point of is that we don’t download data. So in future examples, we will demonstrate how to access just subsets of data using COG and compare that with a GeoTIFF.\n\n# Download data\nshort_name = 'VCF5KYR'\nversion = '001'\n\nveg_item_results = earthaccess.search_data(\n    short_name=short_name,\n    version=version,\n    count=1\n)\n\nGranules found: 33\n\n\n\ntest_data_dir = \"./test_data\"\nveg_files = earthaccess.download(veg_item_results, test_data_dir)\nveg_gtiff_filename = f\"{test_data_dir}/{veg_files[0]}\"\n\n Getting 1 granules, approx download size: 0.07 GB\nFile VCF5KYR_1982001_001_2018224204211.tif already downloaded\n\n\nQUEUEING TASKS | : 100%|██████████| 1/1 [00:00&lt;00:00, 900.84it/s]\nPROCESSING TASKS | : 100%|██████████| 1/1 [00:00&lt;00:00, 15887.52it/s]\nCOLLECTING RESULTS | : 100%|██████████| 1/1 [00:00&lt;00:00, 29330.80it/s]\n\n\n\nTo learn more about the example data see the Vegetation Continuous Fields (VCF) information page."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-examples.html#is-it-a-valid-cog",
    "href": "cloud-optimized-geotiffs/cogs-examples.html#is-it-a-valid-cog",
    "title": "Examples of Working with COGs",
    "section": "Is it a valid COG?",
    "text": "Is it a valid COG?\nWe can use rio_cogeo.cog_validate to check. It returns is_valid, errors and warnings.\n\ncog_validate(veg_gtiff_filename)\n\nThe following warnings were found:\n- The file is greater than 512xH or 512xW, it is recommended to include internal overviews\n\nThe following errors were found:\n- The file is greater than 512xH or 512xW, but is not tiled\n\n\n(False,\n ['The file is greater than 512xH or 512xW, but is not tiled'],\n ['The file is greater than 512xH or 512xW, it is recommended to include internal overviews'])\n\n\nReturn values:\n\nis_valid is False: this is not a valid COG.\nerrors are 'The file is greater than 512xH or 512xW, but is not tiled'. To be a valid COG, the file should be tiled since it has a height and width both greater than 512.\nwarnings are 'The file is greater than 512xH or 512xW, it is recommended to include internal overviews'. It is recommended to provide overviews."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-examples.html#converting-a-geotiff-to-cog",
    "href": "cloud-optimized-geotiffs/cogs-examples.html#converting-a-geotiff-to-cog",
    "title": "Examples of Working with COGs",
    "section": "Converting a GeoTIFF to COG",
    "text": "Converting a GeoTIFF to COG\nWe can use rio_cogeo.cog_create to convert a GeoTIFF into a Cloud Optimized GeoTIFF\n\nveg_cog_filename = veg_gtiff_filename.replace(\".tif\", \"_cog.tif\")\n\n!rio cogeo create {veg_gtiff_filename} {veg_cog_filename}\n\nReading input: /Users/kyle/ds/cloud-optimized-geospatial-formats-guide/cloud-optimized-geotiffs/test_data/VCF5KYR_1982001_001_2018224204211.tif\n  [####################################]  100%\nAdding overviews...\nUpdating dataset tags...\nWriting output to: /Users/kyle/ds/cloud-optimized-geospatial-formats-guide/cloud-optimized-geotiffs/test_data/VCF5KYR_1982001_001_2018224204211_cog.tif\n\n\n\ncog_validate(veg_cog_filename)\n\n(True, [], [])\n\n\nThis is a valid COG, so we will use it to compare with our GeoTIFF."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-examples.html#data-structure",
    "href": "cloud-optimized-geotiffs/cogs-examples.html#data-structure",
    "title": "Examples of Working with COGs",
    "section": "Data Structure",
    "text": "Data Structure\nDimensions Dimensions are the number of bands, rows and columns stored in a GeoTIFF. More Info\nInternal Blocks (aka chunks or internal tiles) Internal blocks are required if the dimensions of data are over 512x512. More Info\nLet’s check out the dimensions and blocks of our GeoTIFF and Cloud-Optimized GeoTIFF.\n\nveg_gtiff_rio = rasterio.open(veg_gtiff_filename)\nveg_cog_rio = rasterio.open(veg_cog_filename)\n\n\nprint(veg_gtiff_rio.shape)\nveg_cog_rio.shape\n\n(3600, 7200)\n\n\n(3600, 7200)\n\n\nThey have the same dimensions which is what we expect, so that is good!\nWe can also print information about the GeoTIFF’s IFD (Internal File Directory). Only one item is returned because the GeoTIFF doesn’t have overviews. When we print the IFD info for the COG, which has overviews, we see more items returned.\n\ncog_info(veg_gtiff_filename).IFD\n\n[IFD(Level=0, Width=7200, Height=3600, Blocksize=(1, 7200), Decimation=0)]\n\n\n\ncog_info(veg_cog_filename).IFD\n\n[IFD(Level=0, Width=7200, Height=3600, Blocksize=(512, 512), Decimation=0),\n IFD(Level=1, Width=3600, Height=1800, Blocksize=(128, 128), Decimation=2),\n IFD(Level=2, Width=1800, Height=900, Blocksize=(128, 128), Decimation=4),\n IFD(Level=3, Width=900, Height=450, Blocksize=(128, 128), Decimation=8)]\n\n\nNote for IFD Level 0, the regular GeoTIFF has a blocksize of (1, 7200) which implies each row of data is a separate block. So whenever reading in data, even if only a few columns are required, the full row must be read."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-examples.html#overviews",
    "href": "cloud-optimized-geotiffs/cogs-examples.html#overviews",
    "title": "Examples of Working with COGs",
    "section": "Overviews",
    "text": "Overviews\nOverviews are downsampled (aggregated) data intended for visualization.\nThe smallest size overview should match the tiling components’ fetch size, typically 256x256. Due to aspect ratio variation just aim to have at least one dimension at or slightly less than 256. &gt; The COG driver in GDAL, or rio cogeo tools should do this.\nThere are many resampling algorithms for generating overviews. The best resampling algorithm depends on the range, type, and distribution of the data. When creating overviews several options should be compared before deciding which resampling method to apply.\nGDAL &gt;= 3.2 allows for the overview resampling method to be set directly.\n\n\nveg_gtiff_rio.overviews(1)\n\n[]\n\n\n\nveg_cog_rio.overviews(1)\n\n[2, 4, 8]\n\n\nBy displaying each overview, we can see how the dimensions get coarser for each overview level.\n\ndef show_overviews(geotiff):  \n    for overview in geotiff.overviews(1):\n        out_height = int(geotiff.height // overview)\n        out_width = int(geotiff.width // overview)\n        print(f\"out height: {out_height}\")\n        print(f\"out width: {out_width}\")    \n        # read first band of file and set shape of new output array\n        window_size_height = round(out_height/8)\n        window_size_width = round(out_width/8)\n        image = veg_cog_rio.read(1, out_shape=(1, out_height, out_width))[\n            window_size_height:(window_size_height*2),\n            window_size_width:(window_size_width*2),\n        ]\n        show(image)\n        \nshow_overviews(veg_cog_rio)\n\nout height: 1800\nout width: 3600\nout height: 900\nout width: 1800\nout height: 450\nout width: 900\n\n\n\n\n\n\n\n\n\n\n\nWe can generate more and different overviews, through different tilesizes and resampling.\n\nimport gen_overviews\n\n\ntmp_dst = gen_overviews.create_overviews_from_gtiff(veg_gtiff_rio)\ntmp_cog = rasterio.open(tmp_dst)\ncog_info(tmp_dst).IFD\n\n\n\n\n[IFD(Level=0, Width=7200, Height=3600, Blocksize=(1, 7200), Decimation=0),\n IFD(Level=1, Width=3600, Height=1800, Blocksize=(128, 128), Decimation=2),\n IFD(Level=2, Width=1800, Height=900, Blocksize=(128, 128), Decimation=4),\n IFD(Level=3, Width=900, Height=450, Blocksize=(128, 128), Decimation=8),\n IFD(Level=4, Width=450, Height=225, Blocksize=(128, 128), Decimation=16)]\n\n\nNote: Now we have overviews but there are still no tiles on the Level 0 IFD.\n\noverviews = tmp_cog.overviews(1)\noverviews\n\n[2, 4, 8, 16]\n\n\n\nshow_overviews(tmp_cog)\n\nout height: 1800\nout width: 3600\nout height: 900\nout width: 1800\nout height: 450\nout width: 900\nout height: 225\nout width: 450"
  },
  {
    "objectID": "geoparquet/geoparquet-example.html",
    "href": "geoparquet/geoparquet-example.html",
    "title": "GeoParquet Example",
    "section": "",
    "text": "This notebook will give an overview of how to read and write GeoParquet files with GeoPandas, putting an emphasis on cloud-native operations where possible.\nThe easiest way to read and write GeoParquet files is to use GeoPandas’ read_parquet and to_parquet functions."
  },
  {
    "objectID": "geoparquet/geoparquet-example.html#environment",
    "href": "geoparquet/geoparquet-example.html#environment",
    "title": "GeoParquet Example",
    "section": "Environment",
    "text": "Environment\nThe packages needed for this notebook can be installed with conda or mamba. Using the environment.yml from this folder run:\nconda create -f environment.yml\nor\nmamba create -f environment.yml\nThis notebook has been tested to work with the listed Conda environment. If you don’t want to use Conda or Mamba, install the latest versions of geopandas, fsspec, and pyarrow with pip. Note that you’ll also need the GDAL CLI with Parquet driver. If you’re on MacOS, you can install that via brew install gdal."
  },
  {
    "objectID": "geoparquet/geoparquet-example.html#imports",
    "href": "geoparquet/geoparquet-example.html#imports",
    "title": "GeoParquet Example",
    "section": "Imports",
    "text": "Imports\n\nfrom urllib.request import urlretrieve\n\nimport fsspec\nimport geopandas as gpd\nfrom fsspec.implementations.http import HTTPFileSystem"
  },
  {
    "objectID": "geoparquet/geoparquet-example.html#comparison-with-flatgeobuf",
    "href": "geoparquet/geoparquet-example.html#comparison-with-flatgeobuf",
    "title": "GeoParquet Example",
    "section": "Comparison with FlatGeobuf",
    "text": "Comparison with FlatGeobuf\nIn order to compare reading GeoParquet with FlatGeobuf, we’ll cover reading and writing GeoParquet files on local disk storage. To be consistent with the FlatGeobuf example, we’ll fetch the same US counties FlatGeobuf file (13 MB) and convert it to GeoParquet using ogr2ogr.\n\n# URL to download\nurl = \"https://flatgeobuf.org/test/data/UScounties.fgb\"\n\n# Download, saving to the current directory\nlocal_fgb_path, _ = urlretrieve(url, \"countries.fgb\")\n\n\n!ogr2ogr countries.parquet countries.fgb\n\nLoading this GeoParquet file is really fast! 13% faster than loading the same data via FlatGeobuf (shown in the FlatGeobuf example notebook).\n\n%time gdf = gpd.read_parquet(\"countries.parquet\")\n\nCPU times: user 23.8 ms, sys: 11.8 ms, total: 35.6 ms\nWall time: 34.1 ms\n\n\n\ngdf\n\n\n\n\n\n\n\n\nSTATE_FIPS\nCOUNTY_FIP\nFIPS\nSTATE\nNAME\nLSAD\ngeometry\n\n\n\n\n0\n23\n009\n23009\nME\nHancock\nCounty\nMULTIPOLYGON (((-68.53108 44.33278, -68.53348 ...\n\n\n1\n33\n007\n33007\nNH\nCoos\nCounty\nMULTIPOLYGON (((-71.05975 45.01485, -71.06939 ...\n\n\n2\n50\n009\n50009\nVT\nEssex\nCounty\nMULTIPOLYGON (((-71.49463 44.90874, -71.49392 ...\n\n\n3\n50\n019\n50019\nVT\nOrleans\nCounty\nMULTIPOLYGON (((-72.14193 45.00600, -72.16051 ...\n\n\n4\n23\n007\n23007\nME\nFranklin\nCounty\nMULTIPOLYGON (((-70.83471 45.27514, -70.77984 ...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n3216\n15\n003\n15003\nHI\nHonolulu\nCounty\nMULTIPOLYGON (((-171.73761 25.79210, -171.7513...\n\n\n3217\n15\n007\n15007\nHI\nKauai\nCounty\nMULTIPOLYGON (((-160.55535 21.66345, -160.5541...\n\n\n3218\n15\n009\n15009\nHI\nMaui\nCounty\nMULTIPOLYGON (((-157.06121 20.89150, -157.0611...\n\n\n3219\n15\n001\n15001\nHI\nHawaii\nCounty\nMULTIPOLYGON (((-155.08767 19.72887, -155.0909...\n\n\n3220\n15\n005\n15005\nHI\nKalawao\nCounty\nMULTIPOLYGON (((-157.01455 21.18550, -157.0145...\n\n\n\n\n3221 rows × 7 columns"
  },
  {
    "objectID": "geoparquet/geoparquet-example.html#writing-to-local-disk",
    "href": "geoparquet/geoparquet-example.html#writing-to-local-disk",
    "title": "GeoParquet Example",
    "section": "Writing to local disk",
    "text": "Writing to local disk\nWe can use GeoDataFrame.to_parquet to write out this data to GeoParquet files locally. This is about 3x faster than writing the same dataset to FlatGeobuf, but note that FlatGeobuf’s writing is also calculating a spatial index.\n\n%time gdf.to_parquet(\"countries_written.parquet\")\n\nCPU times: user 42.3 ms, sys: 12.6 ms, total: 55 ms\nWall time: 53.9 ms"
  },
  {
    "objectID": "geoparquet/geoparquet-example.html#reading-from-the-cloud",
    "href": "geoparquet/geoparquet-example.html#reading-from-the-cloud",
    "title": "GeoParquet Example",
    "section": "Reading from the cloud",
    "text": "Reading from the cloud\nAs of GeoParquet version 1.0.0-rc.1, spatial indexing has not yet been implemented. Therefore, there is not yet an API in GeoPandas to read data given a specific bounding box.\nWhat is already efficient in GeoParquet is reading only specified columns from a dataset.\n\nurl = \"https://data.source.coop/cholmes/eurocrops/unprojected/geoparquet/FR_2018_EC21.parquet\"\n\nNote that since we’re fetching this data directly from the cloud, we need to pass in an fsspec filesystem object. Otherwise GeoPandas will attempt to load a local file.\n\nfilesystem = HTTPFileSystem()\n\nBy default, calling read_parquet will fetch the entire file and parse it all into a single GeoDataFrame. Since this is a 3GB file, downloading the file takes a long time:\n\n# This cell will take a few minutes to run, because it downloads the entire file\n# %time gdf = gpd.read_parquet(url, filesystem=filesystem)\n\nWe can make this faster by only fetching specific columns. Because GeoParquet stores data in a columnar fashion, when selecting only specific columns we can download a lot less data.\n\n# This cell will take a few minutes to run, because it downloads the entire file for these columns\n# %time gdf = gpd.read_parquet(url, columns=[\"ID_PARCEL\", \"geometry\"], filesystem=filesystem)"
  },
  {
    "objectID": "geoparquet/geoparquet-example.html#working-with-geoparquet-row-groups-advanced",
    "href": "geoparquet/geoparquet-example.html#working-with-geoparquet-row-groups-advanced",
    "title": "GeoParquet Example",
    "section": "Working with GeoParquet row groups (Advanced)",
    "text": "Working with GeoParquet row groups (Advanced)\nAs described in the intro document, GeoParquet is a chunked format, which allows you to access one of the chunks of rows very efficiently. This can allow you to stream a dataset — loading and operating on one chunk at a time — if the dataset is larger than your memory.\nGeoPandas does not yet have built-in support for working with row groups, so this section will use the underlying pyarrow library directly.\n\nimport pyarrow.parquet as pq\nfrom geopandas.io.arrow import _arrow_to_geopandas\n\nFirst, we’ll create a ParquetFile object from the remote URL. All this does is load the metadata from the file, allowing you to inspect the schema and number of columns, rows, and row groups. Because this doesn’t load any actual data, it’s nearly instant to complete.\n\nparquet_file = pq.ParquetFile(url, filesystem=filesystem)\n\nWe can access the column names in the dataset:\n\nparquet_file.schema_arrow.names\n\n['ID_PARCEL',\n 'SURF_PARC',\n 'CODE_CULTU',\n 'CODE_GROUP',\n 'CULTURE_D1',\n 'CULTURE_D2',\n 'EC_org_n',\n 'EC_trans_n',\n 'EC_hcat_n',\n 'EC_hcat_c',\n 'geometry']\n\n\nThis Parquet file includes 9.5 million rows:\n\nparquet_file.metadata.num_rows\n\n9517874\n\n\nAnd 146 row groups. Given that each row group is about the same number of rows, each one contains around 65,000 rows.\n\nparquet_file.num_row_groups\n\n146\n\n\nThen to load one of the row groups by numeric index, we can call ParquetFile.read_row_group.\n\npyarrow_table = parquet_file.read_row_group(0)\n\nNote that this returns a pyarrow.Table, not a geopandas.GeoDataFrame. To convert between the two, we can use _arrow_to_geopandas. This conversion is very fast.\n\ngeopandas_gdf = _arrow_to_geopandas(pyarrow_table, parquet_file.metadata.metadata)\n\nAs expected, this row group contains right around 65,000 rows\n\ngeopandas_gdf.shape\n\n(65536, 11)\n\n\n\ngeopandas_gdf.head()\n\n\n\n\n\n\n\n\nID_PARCEL\nSURF_PARC\nCODE_CULTU\nCODE_GROUP\nCULTURE_D1\nCULTURE_D2\nEC_org_n\nEC_trans_n\nEC_hcat_n\nEC_hcat_c\ngeometry\n\n\n\n\n0\n123563\n6.38\nCZH\n5\nNone\nNone\nColza d’hiver\nWinter rapeseed\nwinter_rapeseed_rape\n3301060401\nMULTIPOLYGON (((3.33896 49.84122, 3.33948 49.8...\n\n\n1\n5527076\n2.30\nPPH\n18\nNone\nNone\nPrairie permanente - herbe prédominante (resso...\nPermanent pasture - predominantly grass (woody...\npasture_meadow_grassland_grass\n3302000000\nMULTIPOLYGON (((-1.44483 49.61280, -1.44467 49...\n\n\n2\n11479241\n6.33\nPPH\n18\nNone\nNone\nPrairie permanente - herbe prédominante (resso...\nPermanent pasture - predominantly grass (woody...\npasture_meadow_grassland_grass\n3302000000\nMULTIPOLYGON (((2.87821 46.53674, 2.87820 46.5...\n\n\n3\n12928442\n5.10\nPPH\n18\nNone\nNone\nPrairie permanente - herbe prédominante (resso...\nPermanent pasture - predominantly grass (woody...\npasture_meadow_grassland_grass\n3302000000\nMULTIPOLYGON (((-0.19026 48.28723, -0.19025 48...\n\n\n4\n318389\n0.92\nPPH\n18\nNone\nNone\nPrairie permanente - herbe prédominante (resso...\nPermanent pasture - predominantly grass (woody...\npasture_meadow_grassland_grass\n3302000000\nMULTIPOLYGON (((5.72084 44.03576, 5.72081 44.0...\n\n\n\n\n\n\n\nAs before, we can speed up the data fetching by requesting only specific columns in the read_row_group call.:\n\npyarrow_table = parquet_file.read_row_group(0, columns=[\"ID_PARCEL\", \"geometry\"])\n\nThen the resulting GeoDataFrame will only have those two columns:\n\n_arrow_to_geopandas(pyarrow_table, parquet_file.metadata.metadata).head()\n\n\n\n\n\n\n\n\nID_PARCEL\ngeometry\n\n\n\n\n0\n123563\nMULTIPOLYGON (((3.33896 49.84122, 3.33948 49.8...\n\n\n1\n5527076\nMULTIPOLYGON (((-1.44483 49.61280, -1.44467 49...\n\n\n2\n11479241\nMULTIPOLYGON (((2.87821 46.53674, 2.87820 46.5...\n\n\n3\n12928442\nMULTIPOLYGON (((-0.19026 48.28723, -0.19025 48...\n\n\n4\n318389\nMULTIPOLYGON (((5.72084 44.03576, 5.72081 44.0..."
  },
  {
    "objectID": "cookbooks/index.html",
    "href": "cookbooks/index.html",
    "title": "Cloud-Optimized Cookbooks",
    "section": "",
    "text": "Cookbooks should address common questions and present solutions for cloud-optimized access and visualization.\nCookbooks:\n\nZarr Visualization Cookbook (in development)"
  },
  {
    "objectID": "flatgeobuf/intro.html",
    "href": "flatgeobuf/intro.html",
    "title": "FlatGeobuf",
    "section": "",
    "text": "FlatGeobuf\nFlatGeobuf is a binary file format for geographic vector data, such as points, lines, and polygons.\nUnlike some formats like Cloud-Optimized GeoTIFF, which builds on the previous success of TIFF and GeoTIFF, FlatGeobuf is a new format, designed from the ground up to be faster for geospatial data.\nFlatGeobuf is widely supported — via its GDAL implementation — in many programming languages as well as applications like QGIS.\nFlatGeobuf supports any vector geometry type defined in the OGC Simple Features specification. This includes the standard building blocks of Point, LineString, Polygon, MultiPoint, MultiLineString, MultiPolygon, and GeometryCollection, but also includes more obscure types such as CircularString, Surface, and TIN (Triangulated irregular network). A best practice is to store only geometries with the same type, as that allows readers to know which geometry type is stored without scanning the entire file.\nAn optional row-based spatial index optimizes for remote reading.\n\nFile layout\nThe internal layout of the file has four sections: magic bytes (aka signature), header, index, and data (aka features).\n\n\nImage source: Horace Williams, Kicking the Tires: Flatgeobuf\n\n\nThe file signature is 8 “magic bytes” indicating the file type and specification version, which allows readers to know a file is FlatGeobuf, even if it’s missing a file extension.\nNext comes the header, which stores the bounding box of the dataset, the geometry type of the features (if known and unique), the attribute schema, the number of features, and coordinate reference system information.\nAfter the file header is an optional spatial index. If included, this lets a reader skip reading features that are not within a provided spatial query.\nLast come the individual features. The rest of the file is a sequence of feature records, placed end to end in a row-wise fashion.\n\n\n\nRow based\nInternally, features are laid out in a row-oriented fashion rather than a column-oriented fasion. This means that it’s relatively cheap to select specific records from the file, but relatively expensive to select a specific column. This is ideal for a small spatial query (assuming an index exists in the file) but to load all geometries requires loading all attribute information as well.\n\n\nNo internal compression\nFlatGeobuf does not support compression while maintaining the ability to seek within the file. In particular, FlatGeobuf’s spatial index describes the byte ranges in the uncompressed file. Those byte ranges will be incorrect if the file is compressed.\nA compression like gzip can be applied to the FlatGeobuf file in full, but keep in mind that storing the compressed file will eliminate random access support.\n\n\nNo append support\nFlatGeobuf is a write-only format, and doesn’t support appending, as that would invalidate the spatial index in the file.\n\n\nRandom access supported via spatial index\nFlatGeobuf optionally supports a spatial index at the beginning of the file, which can speed up reading portions of a file based on a spatial query. For more information on how this spatial index works, refer to the Hilbert R Tree page.\n\n\n\n\n\n\nNote\n\n\n\nNote that because FlatGeobuf has no internal chunking, the spatial index references every single object in the file. This means that for datasets with many small geometries, like points, the spatial index will be very large as a proportion of the file size.\n\n\n\n\n\nStreaming features is supported\nFlatGeobuf supports streaming, meaning that you can use part of the file before the entire file has finished downloading. This is different than random access, because you have no ability to skip around in the file.\nStreaming can be valuable because it makes an application seem more responsive; you can have something happen without having to wait for the full download to complete. A good example of this is this example by FlatGeobuf’s author Björn Harrtell. As the file is downloaded to the browser, portions of the file get rendered progressively in parts.\nThis works even with full-file compression like gzip or deflate because those compression algorithms support streaming decompression.\n\n\nBroad type system\nFlatGeobuf supports attributes with a range of types:\n\nByte: Signed 8-bit integer\nUByte: Unsigned 8-bit integer\nBool: Boolean\nShort: Signed 16-bit integer\nUShort: Unsigned 16-bit integer\nInt: Signed 32-bit integer\nUInt: Unsigned 32-bit integer\nLong: Signed 64-bit integer\nULong: Unsigned 64-bit integer\nFloat: Single precision floating point number\nDouble: Double precision floating point number\nString: UTF8 string\nJson: General JSON type intended to be application specific\nDateTime: ISO 8601 date time\nBinary: General binary type intended to be application specific\n\n\n\n\n\n\n\nNote\n\n\n\nNote that FlatGeobuf is unable to store nested types without overhead. It doesn’t support a “list” or “dict” type apart from JSON, which has a parsing overhead.\nIn some situations, having strong nested type support can be useful. For example STAC stored as GeoParquet has columns that are nested, such as the assets column that needs to store a dictionary-like mapping from asset names to their information. FlatGeobuf is able to store such data by serializing it to JSON, but it’s not possible to see the nested schema before parsing the full dataset.\n\n\n\n\nKnown table schema\nFlatGeobuf declares the schema of properties at the beginning of the file. This makes it much easier to read the file — compared to a fully schemaless format like GeoJSON — because the reader knows what data type each attribute has in advance.\n\n\nReferences\n\nflatgeobuf.org: Official project website.\nFlatgeobuf: Implementer’s Guide"
  },
  {
    "objectID": "flatgeobuf/flatgeobuf.html",
    "href": "flatgeobuf/flatgeobuf.html",
    "title": "FlatGeobuf example",
    "section": "",
    "text": "This notebook will give an overview of how to read and write FlatGeobuf files with GeoPandas, putting an emphasis on cloud-native operations where possible.\nThe primary way to interact with FlatGeobuf in Python is via bindings to GDAL, as there is no pure-Python implementation of FlatGeobuf.\nThere are two different Python libraries for interacting between Python and GDAL’s vector support: fiona and pyogrio. Both of these are integrated into geopandas.read_file via the engine keyword, but pyogrio is much faster. Set engine=\"pyogrio\" when using read_file or GeoDataFrame.to_file to speed up reading and writing significantly. We also suggest passing use_arrow=True when reading for a slight extra speedup (this is not supported when writing)."
  },
  {
    "objectID": "flatgeobuf/flatgeobuf.html#local-vs-remote-reading",
    "href": "flatgeobuf/flatgeobuf.html#local-vs-remote-reading",
    "title": "FlatGeobuf example",
    "section": "Local vs Remote reading",
    "text": "Local vs Remote reading\nThe cloud-native vector ecosystem is young and doesn’t work as seamlessly as the COG and Zarr for subsetted access. We download data here to demonstrate important concepts but look to update these methods once better datasets and tools are available for working with FlatGeobuf without downloading entire files.\nAt the end of the notebook we have an example with reading via a spatial filter. Keep in mind that using a large spatial filter will cause the read to take a long time."
  },
  {
    "objectID": "flatgeobuf/flatgeobuf.html#environment",
    "href": "flatgeobuf/flatgeobuf.html#environment",
    "title": "FlatGeobuf example",
    "section": "Environment",
    "text": "Environment\nThe packages needed for this notebook can be installed with conda or mamba. Using the environment.yml from this folder run:\nconda create -f environment.yml\nor\nmamba create -f environment.yml\nAlternatively, you can install the versions of pyogrio and geopandas used in this notebook with pip:\npip install pyogrio==0.6.0 geopandas==0.13.2"
  },
  {
    "objectID": "flatgeobuf/flatgeobuf.html#imports",
    "href": "flatgeobuf/flatgeobuf.html#imports",
    "title": "FlatGeobuf example",
    "section": "Imports",
    "text": "Imports\n\nfrom tempfile import TemporaryDirectory\nfrom urllib.request import urlretrieve\n\nimport geopandas as gpd\nimport pyogrio"
  },
  {
    "objectID": "flatgeobuf/flatgeobuf.html#reading-from-local-disk",
    "href": "flatgeobuf/flatgeobuf.html#reading-from-local-disk",
    "title": "FlatGeobuf example",
    "section": "Reading from local disk",
    "text": "Reading from local disk\nFirst we’ll cover reading FlatGeobuf from local disk storage. As a first example, we’ll use the US counties FlatGeobuf data from this example. This file is only 13 MB in size, which we’ll download to cover simple loading from disk.\n\n# Create a temporary directory in which to save the file\ntmpdir = TemporaryDirectory()\n\n# URL to download\nurl = \"https://flatgeobuf.org/test/data/UScounties.fgb\"\n\n# Download, saving the output path\nlocal_fgb_path, _ = urlretrieve(url, f\"{tmpdir.name}/countries.fgb\")\n\nIn each of the cases below, we use geopandas.read_file to read the file into a GeoDataFrame.\nFirst we’ll show that reading this file with engine=\"fiona\" (the default) is slower. Taking an extra 500 milliseconds might not seem like a lot, but this file contains only 3,000 rows, so this difference gets magnified with larger files.\n\n%time gdf = gpd.read_file(local_fgb_path, engine=\"fiona\")\n\nCPU times: user 565 ms, sys: 16.9 ms, total: 582 ms\nWall time: 685 ms\n\n\nPassing engine=\"pyogrio\" speeds up loading by 18x here!\n\n%time gdf = gpd.read_file(local_fgb_path, engine=\"pyogrio\")\n\nCPU times: user 25.3 ms, sys: 6.84 ms, total: 32.1 ms\nWall time: 31.3 ms\n\n\nUsing use_arrow=True often makes loading slightly faster again! We’re now 21x faster than using fiona.\n\n%time gdf = gpd.read_file(local_fgb_path, engine=\"pyogrio\", use_arrow=True)\n\nCPU times: user 19.7 ms, sys: 10.1 ms, total: 29.7 ms\nWall time: 29.1 ms"
  },
  {
    "objectID": "flatgeobuf/flatgeobuf.html#writing-to-local-disk",
    "href": "flatgeobuf/flatgeobuf.html#writing-to-local-disk",
    "title": "FlatGeobuf example",
    "section": "Writing to local disk",
    "text": "Writing to local disk\nSimilarly, we can use GeoDataFrame.to_file to write to a local FlatGeobuf file. As expected, writing can be much faster if you pass engine=\"pyogrio\".\nBy default, this writes a spatial index to the created FlatGeobuf file.\n\n%time gdf.to_file(f\"{tmpdir.name}/out_fiona.fgb\")\n\nCPU times: user 362 ms, sys: 44.4 ms, total: 407 ms\nWall time: 418 ms\n\n\n\n%time gdf.to_file(f\"{tmpdir.name}/out_pyogrio.fgb\", engine=\"pyogrio\")\n\nCPU times: user 60.8 ms, sys: 23.4 ms, total: 84.2 ms\nWall time: 83.5 ms"
  },
  {
    "objectID": "flatgeobuf/flatgeobuf.html#reading-from-the-cloud",
    "href": "flatgeobuf/flatgeobuf.html#reading-from-the-cloud",
    "title": "FlatGeobuf example",
    "section": "Reading from the cloud",
    "text": "Reading from the cloud\nKnowing how to read and write local files is important, but given that FlatGeobuf is a cloud-optimized format, it’s important to be able to read from cloud-hosted files as well.\nFor this example, we’ll use the EuroCrops data hosted on Source Cooperative because it has versions of the same data in both FlatGeobuf and GeoParquet format. Hopefully using the same dataset for both the FlatGeobuf and GeoParquet example notebooks will be helpful.\n\nurl = \"https://data.source.coop/cholmes/eurocrops/unprojected/flatgeobuf/FR_2018_EC21.fgb\"\n\nUsually when reading from the cloud, you want to filter on some spatial extent. Pyogrio offers a read_info function to access many pieces of information about the file:\n\npyogrio.read_info(url)\n\n{'crs': 'EPSG:4326',\n 'encoding': 'UTF-8',\n 'fields': array(['ID_PARCEL', 'SURF_PARC', 'CODE_CULTU', 'CODE_GROUP', 'CULTURE_D1',\n        'CULTURE_D2', 'EC_org_n', 'EC_trans_n', 'EC_hcat_n', 'EC_hcat_c'],\n       dtype=object),\n 'dtypes': array(['object', 'float64', 'object', 'object', 'object', 'object',\n        'object', 'object', 'object', 'object'], dtype=object),\n 'geometry_type': 'MultiPolygon',\n 'features': 9517874,\n 'driver': 'FlatGeobuf',\n 'capabilities': {'random_read': 1,\n  'fast_set_next_by_index': 0,\n  'fast_spatial_filter': 1},\n 'layer_metadata': None,\n 'dataset_metadata': None}\n\n\n\n\n\n\n\n\nNote\n\n\n\nSadly the output of read_info does not yet include the bounding box of the file, even though the FlatGeobuf file contains that information in the header. This may be a reason to consider externalizing metadata using Spatio-Temporal Asset Catalog files (STAC) in the future.\n\n\nFor now we’ll hard-code a region around Valence in the south of France, which we know the be within our dataset.\n\n# The order of bounds is\n# (min longitude, min latitude, max longitude, max latitude)\nbounds = (4.301042, 44.822783, 4.410535, 44.877149)\n\nWe can fetch a dataframe containing only the records in these bounds by passing a bbox argument to read_file. Note that the Coordinate Reference System of this bounding box must match the CRS of the dataset. Here, we know from the output of read_info that the CRS of the dataset is EPSG:4326, so we can pass a longitude-latitude bounding box.\n\n%time crops_gdf = gpd.read_file(url, bbox=bounds)\n\nCPU times: user 144 ms, sys: 21.4 ms, total: 165 ms\nWall time: 6 s\n\n\nPassing engine=\"pyogrio\" is only slightly faster, which may mean that most of the time is taken up in network requests, not in parsing the actual data into Python.\n\n%time crops_gdf = gpd.read_file(url, bbox=bounds, engine=\"pyogrio\")\n\nCPU times: user 26.9 ms, sys: 2.98 ms, total: 29.9 ms\nWall time: 490 ms\n\n\nThis gives us a much smaller dataset of only 400 rows (down from 9.5 million rows in the original dataset).\n\ncrops_gdf.head()\n\n\n\n\n\n\n\n\nID_PARCEL\nSURF_PARC\nCODE_CULTU\nCODE_GROUP\nCULTURE_D1\nCULTURE_D2\nEC_org_n\nEC_trans_n\nEC_hcat_n\nEC_hcat_c\ngeometry\n\n\n\n\n0\n9484573\n11.08\nSPL\n17\nNone\nNone\nSurface pastorale - ressources fourragères lig...\nPastoral area - predominant woody fodder resou...\nother_tree_wood_forest\n3306990000\nMULTIPOLYGON (((4.41142 44.85441, 4.41145 44.8...\n\n\n1\n487218\n2.53\nPPH\n18\nNone\nNone\nPrairie permanente - herbe prédominante (resso...\nPermanent pasture - predominantly grass (woody...\npasture_meadow_grassland_grass\n3302000000\nMULTIPOLYGON (((4.41366 44.85898, 4.41373 44.8...\n\n\n2\n487224\n0.89\nCTG\n22\nNone\nNone\nChâtaigne\nChestnut\nsweet_chestnuts\n3303030500\nMULTIPOLYGON (((4.41159 44.85891, 4.41034 44.8...\n\n\n3\n9484542\n1.31\nCTG\n22\nNone\nNone\nChâtaigne\nChestnut\nsweet_chestnuts\n3303030500\nMULTIPOLYGON (((4.40904 44.85805, 4.41034 44.8...\n\n\n4\n487216\n1.70\nBOP\n17\nNone\nNone\nBois pâturé\nGrazed wood\nother_tree_wood_forest\n3306990000\nMULTIPOLYGON (((4.41135 44.85476, 4.41134 44.8...\n\n\n\n\n\n\n\n\ncrops_gdf.shape\n\n(415, 11)\n\n\nThere are other useful keyword arguments to read_file. Since we’re using the pyogrio engine, we can pass specific column names into read_file, and only those columns will be parsed. In the case of FlatGeobuf, this doesn’t save us much time, because the same amount of data needs to be fetched. (Though if running this cell soon after the previous one, the relevant data will be cached and won’t be downloaded again.)\n\ncolumn_names = [\"ID_PARCEL\", \"SURF_PARC\", \"CODE_CULTU\", \"geometry\"]\n%time crops_gdf = gpd.read_file(url, bbox=bounds, columns=column_names, engine=\"pyogrio\")\n\nCPU times: user 25 ms, sys: 2.47 ms, total: 27.4 ms\nWall time: 706 ms\n\n\n\ncrops_gdf.head()\n\n\n\n\n\n\n\n\nCODE_CULTU\nID_PARCEL\nSURF_PARC\ngeometry\n\n\n\n\n0\nSPL\n9484573\n11.08\nMULTIPOLYGON (((4.41142 44.85441, 4.41145 44.8...\n\n\n1\nPPH\n487218\n2.53\nMULTIPOLYGON (((4.41366 44.85898, 4.41373 44.8...\n\n\n2\nCTG\n487224\n0.89\nMULTIPOLYGON (((4.41159 44.85891, 4.41034 44.8...\n\n\n3\nCTG\n9484542\n1.31\nMULTIPOLYGON (((4.40904 44.85805, 4.41034 44.8...\n\n\n4\nBOP\n487216\n1.70\nMULTIPOLYGON (((4.41135 44.85476, 4.41134 44.8..."
  },
  {
    "objectID": "zarr/zarr-in-practice.html",
    "href": "zarr/zarr-in-practice.html",
    "title": "Zarr in Practice",
    "section": "",
    "text": "This notebook demonstrates how to create, explore and modify a Zarr store.\nThese concepts are explored in more detail in the official Zarr Tutorial.\nIt also shows the use of public Zarr stores for geospatial data."
  },
  {
    "objectID": "zarr/zarr-in-practice.html#how-to-create-a-zarr-store",
    "href": "zarr/zarr-in-practice.html#how-to-create-a-zarr-store",
    "title": "Zarr in Practice",
    "section": "How to create a Zarr store",
    "text": "How to create a Zarr store\n\nimport sys\nimport numpy as np\nimport xarray as xr\nimport zarr\n\n# Here we create a simple Zarr store.\nzstore = zarr.array(np.arange(10))\n\nThis is an in-memory Zarr store. To persist it to disk, we can use .save.\n\nzarr.save(\"test.zarr\", zstore)\n\nWe can open the metadata about this dataset, which gives us some interesting information. The dataset has a shape of 10 chunks of 10, so we know all the data was stored in 1 chunk, and was compressed with the blosc compressor.\n\n!cat test.zarr/.zarray \n\n{\n    \"chunks\": [\n        10\n    ],\n    \"compressor\": {\n        \"blocksize\": 0,\n        \"clevel\": 5,\n        \"cname\": \"lz4\",\n        \"id\": \"blosc\",\n        \"shuffle\": 1\n    },\n    \"dtype\": \"&lt;i8\",\n    \"fill_value\": 0,\n    \"filters\": null,\n    \"order\": \"C\",\n    \"shape\": [\n        10\n    ],\n    \"zarr_format\": 2\n}\n\n\nThis was a pretty basic example. Let’s explore the other things we might want to do when creating Zarr."
  },
  {
    "objectID": "zarr/zarr-in-practice.html#how-to-create-a-group",
    "href": "zarr/zarr-in-practice.html#how-to-create-a-group",
    "title": "Zarr in Practice",
    "section": "How to create a group",
    "text": "How to create a group\n\nroot = zarr.group()\ngroup1 = root.create_group('group1')\ngroup2 = root.create_group('group2')\nz1 = group1.create_dataset('ds_in_group', shape=(100,100), chunks=(10,10), dtype='i4')\nz2 = group2.create_dataset('ds_in_group', shape=(1000,1000), chunks=(10,10), dtype='i4')\nroot.tree(expand=True)"
  },
  {
    "objectID": "zarr/zarr-in-practice.html#how-to-examine-and-modify-the-chunk-shape",
    "href": "zarr/zarr-in-practice.html#how-to-examine-and-modify-the-chunk-shape",
    "title": "Zarr in Practice",
    "section": "How to Examine and Modify the Chunk Shape",
    "text": "How to Examine and Modify the Chunk Shape\nIf your data is sufficiently large, Zarr will chose a chunksize for you.\n\nzarr_no_chunks = zarr.array(np.arange(100), chunks=True)\nzarr_no_chunks.chunks, zarr_no_chunks.shape\n\n((100,), (100,))\n\n\n\nzarr_with_chunks = zarr.array(np.arange(10000000), chunks=True)\nzarr_with_chunks.chunks, zarr_with_chunks.shape\n\n((156250,), (10000000,))\n\n\nFor zarr_with_chunks we see the chunks are smaller than the shape, so we know the data has been chunked. Other ways to examine the chunk structure are zarr.info and zarr.cdata_shape.\n\n?zarr_no_chunks.cdata_shape\n\n\nType:        property\nString form: &lt;property object at 0x7efde6ecfb00&gt;\nDocstring:  \nA tuple of integers describing the number of chunks along each\ndimension of the array.\n\n\n\n\nzarr_no_chunks.cdata_shape, zarr_with_chunks.cdata_shape\n\n((1,), (64,))\n\n\nThe zarr store with chunks has 64 chunks. The number of chunks multiplied by the chunk size equals the length of the whole array.\n\nzarr_with_chunks.cdata_shape[0] * zarr_with_chunks.chunks[0] == zarr_with_chunks.shape[0]\n\nTrue\n\n\n\nWhat’s the storage size of these chunks?\nThe default chunks are pretty small.\n\nsys.getsizeof(zarr_with_chunks.chunk_store['0']) # this is in bytes\n\n8049\n\n\n\nzarr_with_big_chunks = zarr.array(np.arange(10000000), chunks=(500000))\n\n\nzarr_with_big_chunks.chunks, zarr_with_big_chunks.shape, zarr_with_big_chunks.cdata_shape\n\n((500000,), (10000000,), (20,))\n\n\nThis Zarr store has 10 million values, stored in 20 chunks of 500,000 data values.\n\nsys.getsizeof(zarr_with_big_chunks.chunk_store['0'])\n\n24941\n\n\nThese chunks are still pretty small, but this is just a silly example. In the real world, you will likely want to deal in Zarr chunks of 1MB or greater, especially when dealing with remote storatge options where data is read over a network and the number of requests should be minimized."
  },
  {
    "objectID": "zarr/zarr-in-practice.html#exploring-and-modifying-data-compression",
    "href": "zarr/zarr-in-practice.html#exploring-and-modifying-data-compression",
    "title": "Zarr in Practice",
    "section": "Exploring and Modifying Data Compression",
    "text": "Exploring and Modifying Data Compression\nContinuing with data from the example above, we can tell that Zarr has also compressed the data for us using zarr.info or zarr.compressor.\n\nzarr_with_chunks.compressor\n\nBlosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n\n\nThe Blosc compressor is actually a meta compressor so actually implements multiple different internal compressors. In this case, it has implemented lz4 compression. We can also explore how much space was saved by using this compression method.\n\nzarr_with_chunks.info\n\n\n\n\nType\nzarr.core.Array\n\n\nData type\nint64\n\n\nShape\n(10000000,)\n\n\nChunk shape\n(156250,)\n\n\nOrder\nC\n\n\nRead-only\nFalse\n\n\nCompressor\nBlosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n\n\nStore type\nzarr.storage.KVStore\n\n\nNo. bytes\n80000000 (76.3M)\n\n\nNo. bytes stored\n514193 (502.1K)\n\n\nStorage ratio\n155.6\n\n\nChunks initialized\n64/64\n\n\n\n\n\nWe can see, from the storage ratio above, that compression has made our data 155 times smaller 😱 .\nYou can set compression=None when creating a Zarr array to turn off this behavior, but I’m not sure why you would do that.\nLet’s see what happens when we use a different compression method. We can checkout a full list of numcodecs compressors here: https://numcodecs.readthedocs.io/.\n\nfrom numcodecs import GZip\ncompressor = GZip()\nzstore_gzip_compressed = zarr.array(np.arange(10000000), chunks=True, compressor=compressor)\nzstore_gzip_compressed.info\n\n\n\n\nType\nzarr.core.Array\n\n\nData type\nint64\n\n\nShape\n(10000000,)\n\n\nChunk shape\n(156250,)\n\n\nOrder\nC\n\n\nRead-only\nFalse\n\n\nCompressor\nGZip(level=1)\n\n\nStore type\nzarr.storage.KVStore\n\n\nNo. bytes\n80000000 (76.3M)\n\n\nNo. bytes stored\n15086009 (14.4M)\n\n\nStorage ratio\n5.3\n\n\nChunks initialized\n64/64\n\n\n\n\n\nIn this case, the storage ratio is 5.3 - so not as good! How to chose a compression algorithm is a topic for future investigation."
  },
  {
    "objectID": "zarr/zarr-in-practice.html#consolidating-metadata",
    "href": "zarr/zarr-in-practice.html#consolidating-metadata",
    "title": "Zarr in Practice",
    "section": "Consolidating metadata",
    "text": "Consolidating metadata\nIt’s important to consolidate metadata to minimize requests. Each group and array will have a metadata file, so in order to limit requests to read the whole tree of metadata files, Zarr provides the ability to consolidate metdata into a metadata file at the of the store.\nSo far we have only been dealing in single array Zarr data stores. In this next example, we will create a zarr store with multiple arrays and then consolidate metadata. The speed up with local storage is insignificant, but becomes significant when dealing in remote storage options, which we will see in the following example on accessing cloud storage.\n\nroot = zarr.group()\nzarr_store = 'example.zarr'\n# Let's create many groups and many arrays\nnum_groups, num_arrays_per_group = 100, 100\nfor i in range(num_groups):\n    group = root.create_group(f'group-{i}')\n    for j in range(num_arrays_per_group):\n        group.create_dataset(f'array-{j}', shape=(1000,1000), dtype='i4')\n\nstore = zarr.DirectoryStore(zarr_store)\nzarr.save(store, root)\n\n\n# We don't expect it to exist yet!\n!cat {zarr_store}/.zmetadata\n\ncat: {zarr_store}/.zmetadata: No such file or directory\n\n\n\nzarr.consolidate_metadata(zarr_store)\n\n&lt;zarr.core.Array (100,) &lt;U8&gt;\n\n\n\nzarr.open_consolidated(zarr_store)\n\n&lt;zarr.core.Array (100,) &lt;U8&gt;\n\n\n\n!cat {zarr_store}/.zmetadata\n\n{\n    \"metadata\": {\n        \".zarray\": {\n            \"chunks\": [\n                100\n            ],\n            \"compressor\": {\n                \"blocksize\": 0,\n                \"clevel\": 5,\n                \"cname\": \"lz4\",\n                \"id\": \"blosc\",\n                \"shuffle\": 1\n            },\n            \"dtype\": \"&lt;U8\",\n            \"fill_value\": \"\",\n            \"filters\": null,\n            \"order\": \"C\",\n            \"shape\": [\n                100\n            ],\n            \"zarr_format\": 2\n        }\n    },\n    \"zarr_consolidated_format\": 1\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "",
    "text": "Geospatial data is experiencing exponential growth in both size and complexity. As a result, traditional data access methods, such as file downloads, have become increasingly impractical for achieving scientific objectives. With the limitations of these older methods becoming more apparent, cloud-optimized geospatial formats present a much-needed solution.\nCloud optimization enables efficient, on-the-fly access to geospatial data, offering several advantages:\n\nReduced Latency: Subsets of the raw data can be fetched and processed much faster compared to downloading entire files.\nScalability: Cloud-optimized formats are usually stored on cloud object storage, which is infinitely scalable. Object storage supports many parallel read requests when combined with metadata about where different data bits are stored, making it easier to work with large datasets.\nFlexibility: Cloud-optimized formats allow for high levels of customization, enabling users to tailor data access to their specific needs. Additionally, advanced query capabilities provide the freedom to perform complex operations on the data without downloading and processing entire datasets.\nCost-Effectiveness: Reduced data transfer and storage needs can lower costs. Many of these formats offer compression options, which reduce storage costs.\n\nIf you want to provide optimized access to geospatial data, this guide is designed to help you understand the best practices and tools available for cloud-optimized geospatial formats."
  },
  {
    "objectID": "index.html#why-cloud-optimize",
    "href": "index.html#why-cloud-optimize",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "",
    "text": "Geospatial data is experiencing exponential growth in both size and complexity. As a result, traditional data access methods, such as file downloads, have become increasingly impractical for achieving scientific objectives. With the limitations of these older methods becoming more apparent, cloud-optimized geospatial formats present a much-needed solution.\nCloud optimization enables efficient, on-the-fly access to geospatial data, offering several advantages:\n\nReduced Latency: Subsets of the raw data can be fetched and processed much faster compared to downloading entire files.\nScalability: Cloud-optimized formats are usually stored on cloud object storage, which is infinitely scalable. Object storage supports many parallel read requests when combined with metadata about where different data bits are stored, making it easier to work with large datasets.\nFlexibility: Cloud-optimized formats allow for high levels of customization, enabling users to tailor data access to their specific needs. Additionally, advanced query capabilities provide the freedom to perform complex operations on the data without downloading and processing entire datasets.\nCost-Effectiveness: Reduced data transfer and storage needs can lower costs. Many of these formats offer compression options, which reduce storage costs.\n\nIf you want to provide optimized access to geospatial data, this guide is designed to help you understand the best practices and tools available for cloud-optimized geospatial formats."
  },
  {
    "objectID": "index.html#built-for-the-community-by-the-community.",
    "href": "index.html#built-for-the-community-by-the-community.",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "Built for the Community, by the Community.",
    "text": "Built for the Community, by the Community.\nThere is no one-size-fits-all approach to cloud-optimized data. Still, the community has developed many tools for creating and assessing geospatial formats that should be organized and shared.\nThis guide provides the landscape of cloud-optimized geospatial formats and the best-known answers to common questions."
  },
  {
    "objectID": "index.html#how-to-get-involved",
    "href": "index.html#how-to-get-involved",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "How to Get Involved",
    "text": "How to Get Involved\nIf you want to contribute or modify content, read the Get Involved page.\nIf you have a question or idea for this guide, please start a Github Discussion."
  },
  {
    "objectID": "index.html#the-opportunity",
    "href": "index.html#the-opportunity",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "The Opportunity",
    "text": "The Opportunity\nStoring data in the cloud does not on its own solve geospatial’s data problem. Users cannot reasonably wait to download, store, and work with large files on their machines. Large volumes of data must be available via subsetting methods to access data in memory.\nWhile it is possible to provide subsetting as a service, this requires ongoing maintenance of additional servers and as well as extra network latency when accessing data (data has to go to the server where the subsetting service is running and then to the user). With cloud-optimized formats and the appropriate libraries, subsets of data can be accessed directly from an end user’s machine without introducing an additional server.\nRegardless, users will access data over a network, which must be considered when designing the cloud-optimized format. Traditional geospatial formats are optimized for on-disk access via small internal chunks. A network introduces latency, and the number of requests must be considered.\nAs a community, we have arrived at the following cloud-optimized format pattern:\n\nMetadata includes addresses for data blocks.\nMetadata is stored in a consistent format and location.\nMetadata can be read once.\nMetadata can read the underlying file format, which supports subsetted access via addressable chunks, internal tiling, or both.\n\nThese characteristics allow for parallelized and partial reading."
  },
  {
    "objectID": "index.html#data-type-to-traditional-to-cloud-optimized-geospatial-file-format-table",
    "href": "index.html#data-type-to-traditional-to-cloud-optimized-geospatial-file-format-table",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "Data Type to Traditional to Cloud-Optimized Geospatial File Format Table",
    "text": "Data Type to Traditional to Cloud-Optimized Geospatial File Format Table\nThe diagram below depicts how some of the cloud-optimized formats discussed in this guide are cloud-optimized formats of traditional geospatial file formats.\n\n\n\nCloud-Optimized Geospatial Formats\n\n\nNotes:\n\nSome data formats cover multiple data types, specifically:\n\nGeoJSON can be used for vector and point cloud data.\nHDF5 can be used for point cloud data or data cubes (or both via groups).\nGeoParquet and FlatGeobuf can be used for vector data or point cloud data.\n\nLAS files are intended for 3D points, not 2D points (since COPC files are compressed LAS files, the same goes for COPC files).\nTopoJSON (an extension of GeoJSON that encodes topology) and newline-delimited GeoJSON are types of GeoJSON worth mentioning but have yet to be explicitly represented in the diagram.\nGeoTIFF and GeoParquet are geospatial versions of the non-geospatial file formats TIFF and Parquet, respectively. FlatGeobuf builds upon the non-geospatial flatbuffers serialization library (though flatbuffers is not a standalone file format)"
  },
  {
    "objectID": "index.html#table-of-contents",
    "href": "index.html#table-of-contents",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "Table of Contents",
    "text": "Table of Contents\n\nOverview of Formats (slideshow)\nFormats\n\nCloud-Optimized GeoTIFFs\nZarr\nKerchunk\nCloud-Optimized NetCDF4/HDF5\nGeoParquet\nFlatGeobuf\n\nCookbooks"
  },
  {
    "objectID": "index.html#running-examples",
    "href": "index.html#running-examples",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "Running Examples",
    "text": "Running Examples\nMost of the data formats covered in this guide have a Jupyter Notebook example that covers the basics of reading and writing the given format. At the top of each notebook is a link to an environment.yml file describing what libraries need to be installed to run correctly. You can use Conda or Mamba (a successor to Conda with faster package installs) to install the environment needed to run the notebook."
  },
  {
    "objectID": "index.html#authors",
    "href": "index.html#authors",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "Authors",
    "text": "Authors\n\nAimee Barciauskas\nAlex Mandel\nKyle Barron\nZac Deziel\nOverview Slide credits: Vincent Sarago, Chris Holmes, Patrick Quinn, Matt Hanson, Ryan Abernathey"
  },
  {
    "objectID": "index.html#questions-to-ask-when-generating-cloud-optimized-geospatial-data-in-any-format",
    "href": "index.html#questions-to-ask-when-generating-cloud-optimized-geospatial-data-in-any-format",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "Questions to Ask When Generating Cloud-Optimized Geospatial Data in Any Format",
    "text": "Questions to Ask When Generating Cloud-Optimized Geospatial Data in Any Format\n\nWhat variable(s) should be included in the new data format?\nWill you create copies to optimize for different needs?\nWhat is the intended use case or usage profile? Will this product be used for visualization, analysis, or both?\nWhat is the expected access method?\nHow much of your data is typically rendered or selected at once?"
  },
  {
    "objectID": "index.html#thank-you-to-our-supporters",
    "href": "index.html#thank-you-to-our-supporters",
    "title": "Cloud-Optimized Geospatial Formats Guide",
    "section": "Thank you to our supporters",
    "text": "Thank you to our supporters\nThis guide has been made possible through the support of:"
  },
  {
    "objectID": "cloud-optimized-netcdf4-hdf5/index.html",
    "href": "cloud-optimized-netcdf4-hdf5/index.html",
    "title": "Cloud-Optimized NetCDF4/HDF5",
    "section": "",
    "text": "Cloud-optimized access to NetCDF4/HDF5 files is possible. However, there are no standards for the metadata, chunking and compression for cloud-optimized access for these file types.\n\n\n\n\n\n\nNote\n\n\n\nNote: NetCDF4 are valid HDF5 files, see Reading and Editing NetCDF-4 Files with HDF5.\n\n\nNetCDF4/HDF5 were designed for disk access and thus moving them to the cloud has borne little fruit. Matt Rocklin describes the issue in HDF in the Cloud: Challenges and Solutions for Scientific Data:\n\nThe HDF format is complex and metadata is strewn throughout the file, so that a complex sequence of reads is required to reach a specific chunk of data. The only pragmatic way to read a chunk of data from an HDF file today is to use the existing HDF C library, which expects to receive a C FILE object, pointing to a normal file system (not a cloud object store) (this is not entirely true, as we’ll see below).\nSo organizations like NASA are dumping large amounts of HDF onto Amazon’s S3 that no one can actually read, except by downloading the entire file to their local hard drive, and then pulling out the particular bits that they need with the HDF library. This is inefficient. It misses out on the potential that cloud-hosted public data can offer to our society.\n\nTo provide cloud-optimized access to these files without an intermediate service like Hyrax or the Highly Scalable Data Service (HSDS), it is recommended to determine if the NetCDF4/HDF5 data you wish to provide can be used with kerchunk. Rich Signell provided some insightful examples and instructions on how to create a kerchunk reference file (aka fsspec.ReferenceFileSystem) for NetCDF4/HDF5 and the things to be aware of in Cloud-Performant NetCDF4/HDF5 with Zarr, Fsspec, and Intake. Note, the post is from 2020, so it’s possible details have changed; however, the approach of using kerchunk for NetCDF4/HDF5 is still recommended.\nStay tuned for more information on cloud-optimized NetCDF4/HDF5 in future releases of this guide."
  },
  {
    "objectID": "kerchunk/kerchunk-in-practice.html",
    "href": "kerchunk/kerchunk-in-practice.html",
    "title": "Kerchunk in Practice",
    "section": "",
    "text": "In this notebook, we demonstrate how to create a kerchunk reference file for one and then multiple publicly available NetCDF files and how to open a kerchunk store with xarray.\nGenerally, NetCDF should work with kerchunk. Some nested data structures and data types, such as those that can exist in HDF5, won’t work with kerchunk. A future release of this guide will provide further information and/or resources on limitations of kerchunk."
  },
  {
    "objectID": "kerchunk/kerchunk-in-practice.html#environment",
    "href": "kerchunk/kerchunk-in-practice.html#environment",
    "title": "Kerchunk in Practice",
    "section": "Environment",
    "text": "Environment\nThe packages needed for this notebook can be installed with conda or mamba. Using the environment.yml from this folder run:\nconda create -f environment.yml\nor\nmamba create -f environment.yml\nThis notebook has been tested to work with the listed Conda environment."
  },
  {
    "objectID": "kerchunk/kerchunk-in-practice.html#how-to-create-a-kerchunk-store",
    "href": "kerchunk/kerchunk-in-practice.html#how-to-create-a-kerchunk-store",
    "title": "Kerchunk in Practice",
    "section": "How to create a kerchunk store",
    "text": "How to create a kerchunk store\nWe can use the publicly available NEX GDDP CMIP6 dataset for this example. This dataset is provided by NASA and publicly available on AWS S3. You can browse that data in the nex-gddp-cmip6 file browser.\n\nimport json\nimport os\nfrom tempfile import TemporaryDirectory\n\nimport fsspec\nimport imagecodecs.numcodecs\nimport xarray as xr\nfrom kerchunk.combine import MultiZarrToZarr\nfrom kerchunk.hdf import SingleHdf5ToZarr\n\nimagecodecs.numcodecs.register_codecs() \n\n\n# Set variables\n## Since there are a number of CMIP6 models and variables to chose from, we make the model and variable selections variables.\nmodel = \"ACCESS-CM2\"\n# `tasmax` is daily-maximum near-surface air temperature, see https://pcmdi.llnl.gov/mips/cmip3/variableList.html.\nvariable = \"tasmax\"\n## Note we are only reading historical data here, but model data is available for SSPs (Shared Socio-economic Pathways) as well.\n## SSPs are scenarios are used to model the future, so SSP files predict environment variables into the future.\ns3_path = f\"s3://nex-gddp-cmip6/NEX-GDDP-CMIP6/{model}/historical/r1i1p1*/{variable}/*\"\n\n# Initiate fsspec filesystem for reading.\n## We set anon=True because this specific dataset on AWS does not require users to be logged in to access.\nfs_read = fsspec.filesystem(\"s3\", anon=True)\n\n# Retrieve list of available data.\nfile_paths = fs_read.glob(s3_path)\nprint(f\"{len(file_paths)} discovered from {s3_path}\")\n\n65 discovered from s3://nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1*/tasmax/*\n\n\nTo start, we are just going to create a single reference file for a single NetCDF file.\n\nnetcdf_file = file_paths[0]\nnetcdf_file\n\n'nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1950.nc'\n\n\n\n# Define a function to generate the kerchunk file so we can use it again for other files.\ndef generate_json_reference(input_file, temp_dir: str):\n    \"\"\"\n    Use Kerchunk's `SingleHdf5ToZarr` method to create a `Kerchunk` index from a NetCDF file.\n    \"\"\"\n    with fs_read.open(input_file, **dict(mode=\"rb\")) as infile:\n        print(f\"Running kerchunk generation for {input_file}...\")\n        # Chunks smaller than `inline_threshold` will be stored directly in the reference file as data (as opposed to a URL and byte range).\n        h5chunks = SingleHdf5ToZarr(infile, input_file, inline_threshold=300)\n        fname = input_file.split(\"/\")[-1].strip(\".nc\")\n        outf = os.path.join(temp_dir, f\"{fname}.json\")\n        with open(outf, \"wb\") as f:\n            f.write(json.dumps(h5chunks.translate()).encode())\n        return outf\n\n\n# Create a temporary directory to store the .json reference files.\n# Alternately, you could write these to cloud storage.\ntd = TemporaryDirectory()\ntemp_dir = td.name\nprint(f\"Writing single file references to {temp_dir}\")\n\nWriting single file references to /var/folders/42/5jr6891d4ds4xysz7q0rsghw0000gn/T/tmpn1bas0mo\n\n\n\nsingle_kerchunk_reference = generate_json_reference(netcdf_file, temp_dir)\n\nRunning kerchunk generation for nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1950.nc...\n\n\nWe might also want to inspect what was just created. Below we load just the first few keys and values of the “refs” part of the kerchunk reference file.\n\n# Read and load the JSON file\nwith open(single_kerchunk_reference, 'r') as file:\n    data = json.load(file)\nkeys_to_select = ['.zgroup', 'tasmax/.zarray', 'tasmax/0.0.0']\n\n# Pretty print JSON data\ndata_to_print = {}\nfor key, value in data['refs'].items():\n    if key in keys_to_select:\n        if isinstance(value, str):\n            data_to_print[key] = json.loads(value)\n        else:\n            data_to_print[key] = value\nprint(json.dumps(data_to_print, indent=4))\n\n{\n    \".zgroup\": {\n        \"zarr_format\": 2\n    },\n    \"tasmax/.zarray\": {\n        \"chunks\": [\n            1,\n            600,\n            1440\n        ],\n        \"compressor\": {\n            \"id\": \"zlib\",\n            \"level\": 5\n        },\n        \"dtype\": \"&lt;f4\",\n        \"fill_value\": 1.0000000200408773e+20,\n        \"filters\": [\n            {\n                \"elementsize\": 4,\n                \"id\": \"shuffle\"\n            }\n        ],\n        \"order\": \"C\",\n        \"shape\": [\n            365,\n            600,\n            1440\n        ],\n        \"zarr_format\": 2\n    },\n    \"tasmax/0.0.0\": [\n        \"nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1950.nc\",\n        18097,\n        674483\n    ]\n}\n\n\nWe can also check that our reference file works with xarray.\n\n# Open dataset as zarr object using fsspec reference file system and Xarray\nfs_single = fsspec.filesystem(\n    \"reference\", fo=single_kerchunk_reference, remote_protocol=\"https\"\n)\nsingle_map = fs_single.get_mapper(\"\")\n\n\nds_single = xr.open_dataset(single_map, engine=\"zarr\", backend_kwargs=dict(consolidated=False))\nds_single\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (lat: 600, lon: 1440, time: 365)\nCoordinates:\n  * lat      (lat) float64 0.0 1.23e-321 0.0 ... -3.218e+163 -3.218e+163\n  * lon      (lon) float64 0.0 2.164e-314 0.0 ... -2.022e-53 -1.699e+282\n  * time     (time) datetime64[ns] 1950-01-01T12:00:00 ... 1950-12-31T12:00:00\nData variables:\n    tasmax   (time, lat, lon) float32 ...\nAttributes: (12/22)\n    Conventions:           CF-1.7\n    activity:              NEX-GDDP-CMIP6\n    cmip6_institution_id:  CSIRO-ARCCSS\n    cmip6_license:         CC-BY-SA 4.0\n    cmip6_source_id:       ACCESS-CM2\n    contact:               Dr. Rama Nemani: rama.nemani@nasa.gov, Dr. Bridget...\n    ...                    ...\n    scenario:              historical\n    source:                BCSD\n    title:                 ACCESS-CM2, r1i1p1f1, historical, global downscale...\n    tracking_id:           f85d4c2e-48e4-484f-aad4-6a3f30a04326\n    variant_label:         r1i1p1f1\n    version:               1.0xarray.DatasetDimensions:lat: 600lon: 1440time: 365Coordinates: (3)lat(lat)float640.0 1.23e-321 ... -3.218e+163axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([ 0.000000e+000,  1.230223e-321,  0.000000e+000, ..., -3.218047e+163,\n       -3.218047e+163, -3.218047e+163])lon(lon)float640.0 2.164e-314 ... -1.699e+282axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([ 0.000000e+000,  2.163912e-314,  0.000000e+000, ...,  1.902013e-242,\n       -2.022208e-053, -1.698612e+282])time(time)datetime64[ns]1950-01-01T12:00:00 ... 1950-12-...axis :Tlong_name :timestandard_name :timearray(['1950-01-01T12:00:00.000000000', '1950-01-02T12:00:00.000000000',\n       '1950-01-03T12:00:00.000000000', ..., '1950-12-29T12:00:00.000000000',\n       '1950-12-30T12:00:00.000000000', '1950-12-31T12:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (1)tasmax(time, lat, lon)float32...cell_measures :area: areacellacell_methods :area: mean time: maximumcomment :maximum near-surface (usually, 2 meter) air temperature (add cell_method attribute 'time: max')long_name :Daily Maximum Near-Surface Air Temperaturestandard_name :air_temperatureunits :K[315360000 values with dtype=float32]Indexes: (3)latPandasIndexPandasIndex(Index([                     0.0,                1.23e-321,\n                            0.0,                1.23e-321,\n       -3.2180465730379564e+163, -3.2180465730379564e+163,\n       -3.2180465730379564e+163, -3.2180465730379564e+163,\n       -3.2180465730379564e+163, -3.2180465730379564e+163,\n       ...\n       -3.2180465730379564e+163, -3.2180465730379564e+163,\n       -3.2180465730379564e+163, -3.2180465730379564e+163,\n       -3.2180465730379564e+163, -3.2180465730379564e+163,\n       -3.2180465730379564e+163, -3.2180465730379564e+163,\n       -3.2180465730379564e+163, -3.2180465730379564e+163],\n      dtype='float64', name='lat', length=600))lonPandasIndexPandasIndex(Index([                    0.0,        2.163911906e-314,\n                           0.0,                     nan,\n                           0.0,                     0.0,\n                           0.0,                     0.0,\n                           0.0,                     0.0,\n       ...\n                           0.0,                     0.0,\n        1.5390572997222847e+73,  1.0494093556865241e-86,\n        7.328222560480262e-213,  3.493934932025909e-195,\n        7.981962361089973e-296,   1.90201295465319e-242,\n        -2.022208454662242e-53, -1.698612219286841e+282],\n      dtype='float64', name='lon', length=1440))timePandasIndexPandasIndex(DatetimeIndex(['1950-01-01 12:00:00', '1950-01-02 12:00:00',\n               '1950-01-03 12:00:00', '1950-01-04 12:00:00',\n               '1950-01-05 12:00:00', '1950-01-06 12:00:00',\n               '1950-01-07 12:00:00', '1950-01-08 12:00:00',\n               '1950-01-09 12:00:00', '1950-01-10 12:00:00',\n               ...\n               '1950-12-22 12:00:00', '1950-12-23 12:00:00',\n               '1950-12-24 12:00:00', '1950-12-25 12:00:00',\n               '1950-12-26 12:00:00', '1950-12-27 12:00:00',\n               '1950-12-28 12:00:00', '1950-12-29 12:00:00',\n               '1950-12-30 12:00:00', '1950-12-31 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=365, freq=None))Attributes: (22)Conventions :CF-1.7activity :NEX-GDDP-CMIP6cmip6_institution_id :CSIRO-ARCCSScmip6_license :CC-BY-SA 4.0cmip6_source_id :ACCESS-CM2contact :Dr. Rama Nemani: rama.nemani@nasa.gov, Dr. Bridget Thrasher: bridget@climateanalyticsgroup.orgcreation_date :2021-10-04T14:00:55.510838+00:00disclaimer :This data is considered provisional and subject to change. This data is provided as is without any warranty of any kind, either express or implied, arising by law or otherwise, including but not limited to warranties of completeness, non-infringement, accuracy, merchantability, or fitness for a particular purpose. The user assumes all risk associated with the use of, or inability to use, this data.external_variables :areacellafrequency :dayhistory :2021-10-04T14:00:55.510838+00:00: install global attributesinstitution :NASA Earth Exchange, NASA Ames Research Center, Moffett Field, CA 94035product :outputrealm :atmosreferences :BCSD method: Thrasher et al., 2012, Hydrol. Earth Syst. Sci.,16, 3309-3314. Ref period obs: latest version of the Princeton Global Meteorological Forcings (http://hydrology.princeton.edu/data.php), based on Sheffield et al., 2006, J. Climate, 19 (13), 3088-3111.resolution_id :0.25 degreescenario :historicalsource :BCSDtitle :ACCESS-CM2, r1i1p1f1, historical, global downscaled CMIP6 climate projection datatracking_id :f85d4c2e-48e4-484f-aad4-6a3f30a04326variant_label :r1i1p1f1version :1.0\n\n\nIt worked! But we can do even better. What if you want to open multiple NetCDF files with xarray? Let’s create kerchunk references for 3 files and then combine them.\n\nsubset_files = file_paths[0:3]\nsubset_files\n\n['nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1950.nc',\n 'nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1951.nc',\n 'nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1952.nc']\n\n\n\n# Iterate through filelist to generate Kerchunked files. Good use for `dask.bag`, see: https://docs.dask.org/en/stable/bag.html.\noutput_files = []\nfor single_file in subset_files:\n    out_file = generate_json_reference(single_file, temp_dir)\n    output_files.append(out_file)\n\nRunning kerchunk generation for nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1950.nc...\nRunning kerchunk generation for nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1951.nc...\nRunning kerchunk generation for nex-gddp-cmip6/NEX-GDDP-CMIP6/ACCESS-CM2/historical/r1i1p1f1/tasmax/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1952.nc...\n\n\n\noutput_files\n\n['/var/folders/42/5jr6891d4ds4xysz7q0rsghw0000gn/T/tmpn1bas0mo/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1950.json',\n '/var/folders/42/5jr6891d4ds4xysz7q0rsghw0000gn/T/tmpn1bas0mo/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1951.json',\n '/var/folders/42/5jr6891d4ds4xysz7q0rsghw0000gn/T/tmpn1bas0mo/tasmax_day_ACCESS-CM2_historical_r1i1p1f1_gn_1952.json']\n\n\n\n# combine individual references into single consolidated reference\nmzz = MultiZarrToZarr(\n    output_files,\n    remote_protocol='s3',\n    remote_options={'anon': True},\n    concat_dims=['time'],\n    coo_map={'time': 'cf:time'},\n    # inline_threshold=0 means don't story any raw data in the kerchunk reference file.\n    inline_threshold=0\n)\nmulti_kerchunk = mzz.translate()\n\n\n# Write kerchunk .json record\noutput_fname = os.path.join(temp_dir, f\"combined_CMIP6_daily_{model}_{variable}_kerchunk.json\")\nwith open(f\"{output_fname}\", \"wb\") as f:\n    print(f\"Writing combined kerchunk reference file {output_fname}\")\n    f.write(json.dumps(multi_kerchunk).encode())\n\nWriting combined kerchunk reference file /var/folders/42/5jr6891d4ds4xysz7q0rsghw0000gn/T/tmpn1bas0mo/combined_CMIP6_daily_ACCESS-CM2_tasmax_kerchunk.json\n\n\n\n# open dataset as zarr object using fsspec reference file system and Xarray\nfs_multi = fsspec.filesystem(\n    \"reference\",\n    fo=multi_kerchunk,\n    remote_protocol=\"s3\"\n)\nmulti_map = fs_multi.get_mapper(\"\")\n\n\nds_multi = xr.open_dataset(multi_map, engine=\"zarr\", backend_kwargs=dict(consolidated=False))\nds_multi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (lat: 600, lon: 1440, time: 1096)\nCoordinates:\n  * lat      (lat) float64 0.0 2.164e-314 0.0 ... 2.961e-314 2.961e-314\n  * lon      (lon) float64 0.0 2.164e-314 0.0 ... -6.915e+193 -4.603e+95\n  * time     (time) datetime64[ns] 1950-01-01T12:00:00 ... 1952-12-31T12:00:00\nData variables:\n    tasmax   (time, lat, lon) float32 ...\nAttributes: (12/22)\n    Conventions:           CF-1.7\n    activity:              NEX-GDDP-CMIP6\n    cmip6_institution_id:  CSIRO-ARCCSS\n    cmip6_license:         CC-BY-SA 4.0\n    cmip6_source_id:       ACCESS-CM2\n    contact:               Dr. Rama Nemani: rama.nemani@nasa.gov, Dr. Bridget...\n    ...                    ...\n    scenario:              historical\n    source:                BCSD\n    title:                 ACCESS-CM2, r1i1p1f1, historical, global downscale...\n    tracking_id:           f85d4c2e-48e4-484f-aad4-6a3f30a04326\n    variant_label:         r1i1p1f1\n    version:               1.0xarray.DatasetDimensions:lat: 600lon: 1440time: 1096Coordinates: (3)lat(lat)float640.0 2.164e-314 ... 2.961e-314axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([0.000000e+000, 2.163912e-314, 0.000000e+000, ..., 2.961067e-314,\n       2.960919e-314, 2.961067e-314])lon(lon)float640.0 2.164e-314 ... -4.603e+95axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([ 0.000000e+000,  2.163912e-314,  0.000000e+000, ...,  2.334981e+006,\n       -6.914611e+193, -4.603478e+095])time(time)datetime64[ns]1950-01-01T12:00:00 ... 1952-12-...axis :Tlong_name :timestandard_name :timearray(['1950-01-01T12:00:00.000000000', '1950-01-02T12:00:00.000000000',\n       '1950-01-03T12:00:00.000000000', ..., '1952-12-29T12:00:00.000000000',\n       '1952-12-30T12:00:00.000000000', '1952-12-31T12:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (1)tasmax(time, lat, lon)float32...cell_measures :area: areacellacell_methods :area: mean time: maximumcomment :maximum near-surface (usually, 2 meter) air temperature (add cell_method attribute 'time: max')long_name :Daily Maximum Near-Surface Air Temperaturestandard_name :air_temperatureunits :K[946944000 values with dtype=float32]Indexes: (3)latPandasIndexPandasIndex(Index([              0.0,  2.163911906e-314,               0.0,\n                     nan,               0.0,  2.847840319e-314,\n        2.847840477e-314,            5e-324, 2.8478403307e-314,\n       2.8478403347e-314,\n       ...\n        2.960919408e-314, 2.9610663864e-314,  2.960919313e-314,\n       2.9610664496e-314, 2.9609193446e-314,  2.961066513e-314,\n       2.9609192497e-314,  2.961066576e-314, 2.9609192813e-314,\n       2.9610666394e-314],\n      dtype='float64', name='lat', length=600))lonPandasIndexPandasIndex(Index([                     0.0,         2.163911906e-314,\n                            0.0,                      nan,\n        1.8178640317427325e+185,  1.0640025030406259e+248,\n          6.01334685394558e-154,   9.363931581572749e+252,\n        1.2064976717019484e+285,   2.582765705848744e-144,\n       ...\n         2.7454590140292026e+40,  -3.255930979178767e-308,\n        1.5281971544072024e-111,   -7.088607689435405e+42,\n         1.1472324330854862e+22,  3.6014577529949115e+106,\n          9.851096278175061e+67,       2334981.4421286285,\n       -6.9146108782833415e+193,   -4.603477998061419e+95],\n      dtype='float64', name='lon', length=1440))timePandasIndexPandasIndex(DatetimeIndex(['1950-01-01 12:00:00', '1950-01-02 12:00:00',\n               '1950-01-03 12:00:00', '1950-01-04 12:00:00',\n               '1950-01-05 12:00:00', '1950-01-06 12:00:00',\n               '1950-01-07 12:00:00', '1950-01-08 12:00:00',\n               '1950-01-09 12:00:00', '1950-01-10 12:00:00',\n               ...\n               '1952-12-22 12:00:00', '1952-12-23 12:00:00',\n               '1952-12-24 12:00:00', '1952-12-25 12:00:00',\n               '1952-12-26 12:00:00', '1952-12-27 12:00:00',\n               '1952-12-28 12:00:00', '1952-12-29 12:00:00',\n               '1952-12-30 12:00:00', '1952-12-31 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=1096, freq=None))Attributes: (22)Conventions :CF-1.7activity :NEX-GDDP-CMIP6cmip6_institution_id :CSIRO-ARCCSScmip6_license :CC-BY-SA 4.0cmip6_source_id :ACCESS-CM2contact :Dr. Rama Nemani: rama.nemani@nasa.gov, Dr. Bridget Thrasher: bridget@climateanalyticsgroup.orgcreation_date :2021-10-04T14:00:55.510838+00:00disclaimer :This data is considered provisional and subject to change. This data is provided as is without any warranty of any kind, either express or implied, arising by law or otherwise, including but not limited to warranties of completeness, non-infringement, accuracy, merchantability, or fitness for a particular purpose. The user assumes all risk associated with the use of, or inability to use, this data.external_variables :areacellafrequency :dayhistory :2021-10-04T14:00:55.510838+00:00: install global attributesinstitution :NASA Earth Exchange, NASA Ames Research Center, Moffett Field, CA 94035product :outputrealm :atmosreferences :BCSD method: Thrasher et al., 2012, Hydrol. Earth Syst. Sci.,16, 3309-3314. Ref period obs: latest version of the Princeton Global Meteorological Forcings (http://hydrology.princeton.edu/data.php), based on Sheffield et al., 2006, J. Climate, 19 (13), 3088-3111.resolution_id :0.25 degreescenario :historicalsource :BCSDtitle :ACCESS-CM2, r1i1p1f1, historical, global downscaled CMIP6 climate projection datatracking_id :f85d4c2e-48e4-484f-aad4-6a3f30a04326variant_label :r1i1p1f1version :1.0\n\n\nCool! Now we have 1096 days (3 years) of data."
  },
  {
    "objectID": "kerchunk/kerchunk-in-practice.html#how-to-read-a-kerchunk-store",
    "href": "kerchunk/kerchunk-in-practice.html#how-to-read-a-kerchunk-store",
    "title": "Kerchunk in Practice",
    "section": "How to read a Kerchunk Store",
    "text": "How to read a Kerchunk Store\nWe’ve already demonstrated how to open the datasets with Xarray:\nfs_multi = fsspec.filesystem(\n    \"reference\",\n    fo=multi_kerchunk,\n    remote_protocol=\"s3\"\n)\nLet’s take it line by line to understand what’s happening.\n\nfsspec.filesystem is used to open the kerchunk reference. It is not necessary to have kerchunk installed to read data.\nThe first argument to fsspec.filesystem is the protocol. In the case of a kerchunk reference the protocol is the string \"reference\".\nThe fo argument is the set of reference files used to create a ReferenceFileSystem instance.\nThe remote_protocol argument is the protocol of the filesystem on which the references will be evaluated (unless fs is provided). If not given, will be derived from the first URL that has a protocol in the templates or in the references.\n\nNotice how the fs_multi object we’ve created is a fsspec.implementations.reference.ReferenceFileSystem.\n\ntype(fs_multi)\n\nfsspec.implementations.reference.ReferenceFileSystem\n\n\nRead about all the options for a fsspec.ReferenceFileSystem in the fsspec docs.\nOne other common situation is to load data over HTTP (as opposed to a local filesystem or via the S3 protocol). Here’s an example from the kerchunk case studies that loads a reference file and data files over HTTP:\n\nzarr_all_url='https://sentinel-1-global-coherence-earthbigdata.s3.us-west-2.amazonaws.com/data/wrappers/zarr-all.json'\n\nmapper = fsspec.get_mapper(\n    'reference://',\n    fo=zarr_all_url,\n    target_protocol='http',\n    remote_protocol='http'\n)\ndataset = xr.open_dataset(\n    mapper, engine='zarr', backend_kwargs={'consolidated': False}\n)\ndataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:          (season: 4, polarization: 4, latitude: 193200,\n                      longitude: 432000, coherence: 6, flightdirection: 2,\n                      orbit: 175)\nCoordinates:\n  * coherence        (coherence) float32 6.0 12.0 18.0 24.0 36.0 48.0\n  * flightdirection  (flightdirection) object 'A' 'D'\n  * latitude         (latitude) float32 82.0 82.0 82.0 ... -79.0 -79.0 -79.0\n  * longitude        (longitude) float32 -180.0 -180.0 -180.0 ... 180.0 180.0\n  * orbit            (orbit) float64 1.0 2.0 3.0 4.0 ... 172.0 173.0 174.0 175.0\n  * polarization     (polarization) object 'vv' 'vh' 'hv' 'hh'\n  * season           (season) object 'winter' 'spring' 'summer' 'fall'\nData variables:\n    AMP              (season, polarization, latitude, longitude) float32 ...\n    COH              (season, polarization, coherence, latitude, longitude) float32 ...\n    inc              (orbit, flightdirection, latitude, longitude) float32 ...\n    lsmap            (orbit, flightdirection, latitude, longitude) float32 ...\n    rho              (season, polarization, latitude, longitude) float32 ...\n    rmse             (season, polarization, latitude, longitude) float32 ...\n    tau              (season, polarization, latitude, longitude) float32 ...xarray.DatasetDimensions:season: 4polarization: 4latitude: 193200longitude: 432000coherence: 6flightdirection: 2orbit: 175Coordinates: (7)coherence(coherence)float326.0 12.0 18.0 24.0 36.0 48.0array([ 6., 12., 18., 24., 36., 48.], dtype=float32)flightdirection(flightdirection)object'A' 'D'array(['A', 'D'], dtype=object)latitude(latitude)float3282.0 82.0 82.0 ... -79.0 -79.0array([ 81.99958,  81.99875,  81.99792, ..., -78.99792, -78.99875, -78.99958],\n      dtype=float32)longitude(longitude)float32-180.0 -180.0 ... 180.0 180.0array([-179.99959, -179.99875, -179.99791, ...,  179.99791,  179.99875,\n        179.99959], dtype=float32)orbit(orbit)float641.0 2.0 3.0 ... 173.0 174.0 175.0array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,  12.,\n        13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,\n        25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,  36.,\n        37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,  48.,\n        49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,  60.,\n        61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,  72.,\n        73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,\n        85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,\n        97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107., 108.,\n       109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119., 120.,\n       121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131., 132.,\n       133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143., 144.,\n       145., 146., 147., 148., 149., 150., 151., 152., 153., 154., 155., 156.,\n       157., 158., 159., 160., 161., 162., 163., 164., 165., 166., 167., 168.,\n       169., 170., 171., 172., 173., 174., 175.])polarization(polarization)object'vv' 'vh' 'hv' 'hh'array(['vv', 'vh', 'hv', 'hh'], dtype=object)season(season)object'winter' 'spring' 'summer' 'fall'array(['winter', 'spring', 'summer', 'fall'], dtype=object)Data variables: (7)AMP(season, polarization, latitude, longitude)float32...[1335398400000 values with dtype=float32]COH(season, polarization, coherence, latitude, longitude)float32...[8012390400000 values with dtype=float32]inc(orbit, flightdirection, latitude, longitude)float32...[29211840000000 values with dtype=float32]lsmap(orbit, flightdirection, latitude, longitude)float32...[29211840000000 values with dtype=float32]rho(season, polarization, latitude, longitude)float32...[1335398400000 values with dtype=float32]rmse(season, polarization, latitude, longitude)float32...[1335398400000 values with dtype=float32]tau(season, polarization, latitude, longitude)float32...[1335398400000 values with dtype=float32]Indexes: (7)coherencePandasIndexPandasIndex(Index([6.0, 12.0, 18.0, 24.0, 36.0, 48.0], dtype='float32', name='coherence'))flightdirectionPandasIndexPandasIndex(Index(['A', 'D'], dtype='object', name='flightdirection'))latitudePandasIndexPandasIndex(Index([ 81.99958038330078,  81.99874877929688,  81.99791717529297,\n        81.99708557128906,  81.99624633789062,  81.99541473388672,\n        81.99458312988281,   81.9937515258789,    81.992919921875,\n        81.99208068847656,\n       ...\n       -78.99208068847656,   -78.992919921875,  -78.9937515258789,\n       -78.99458312988281, -78.99541473388672, -78.99624633789062,\n       -78.99708557128906, -78.99791717529297, -78.99874877929688,\n       -78.99958038330078],\n      dtype='float32', name='latitude', length=193200))longitudePandasIndexPandasIndex(Index([ -179.9995880126953, -179.99874877929688, -179.99790954589844,\n       -179.99708557128906, -179.99624633789062, -179.99542236328125,\n        -179.9945831298828, -179.99374389648438,   -179.992919921875,\n       -179.99208068847656,\n       ...\n        179.99208068847656,    179.992919921875,  179.99374389648438,\n         179.9945831298828,  179.99542236328125,  179.99624633789062,\n        179.99708557128906,  179.99790954589844,  179.99874877929688,\n         179.9995880126953],\n      dtype='float32', name='longitude', length=432000))orbitPandasIndexPandasIndex(Index([  1.0,   2.0,   3.0,   4.0,   5.0,   6.0,   7.0,   8.0,   9.0,  10.0,\n       ...\n       166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0],\n      dtype='float64', name='orbit', length=175))polarizationPandasIndexPandasIndex(Index(['vv', 'vh', 'hv', 'hh'], dtype='object', name='polarization'))seasonPandasIndexPandasIndex(Index(['winter', 'spring', 'summer', 'fall'], dtype='object', name='season'))Attributes: (0)\n\n\nBecause xarray uses fsspec to read data, you can also bypass creating a fsspec object explicitly. Here’s an example using of opening a kerchunk reference generated with pangeo-forge for the NOAA 1/4° daily Optimum Interpolation Sea Surface Temperature (or daily OISST) Climate Data Record (CDR).\n\nurl = \"https://ncsa.osn.xsede.org/Pangeo/pangeo-forge/pangeo-forge/aws-noaa-oisst-feedstock/aws-noaa-oisst-avhrr-only.zarr/reference.json\"\nds = xr.open_dataset(\n    \"reference://\",\n    engine='zarr',\n    backend_kwargs={\n        'consolidated': False,\n        'storage_options': {\n            'fo': url,\n            'remote_options': {'anon': True},\n            'remote_protocol': 's3'}},\n    chunks={})\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:  (time: 15044, zlev: 1, lat: 720, lon: 1440)\nCoordinates:\n  * lat      (lat) float32 -89.88 -89.62 -89.38 -89.12 ... 89.38 89.62 89.88\n  * lon      (lon) float32 0.125 0.375 0.625 0.875 ... 359.1 359.4 359.6 359.9\n  * time     (time) datetime64[ns] 1981-09-01T12:00:00 ... 2022-11-08T12:00:00\n  * zlev     (zlev) float32 0.0\nData variables:\n    anom     (time, zlev, lat, lon) float32 dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n    err      (time, zlev, lat, lon) float32 dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n    ice      (time, zlev, lat, lon) float32 dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n    sst      (time, zlev, lat, lon) float32 dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\nAttributes: (12/37)\n    Conventions:                CF-1.6, ACDD-1.3\n    cdm_data_type:              Grid\n    comment:                    Data was converted from NetCDF-3 to NetCDF-4 ...\n    creator_email:              oisst-help@noaa.gov\n    creator_url:                https://www.ncei.noaa.gov/\n    date_created:               2020-05-08T19:05:13Z\n    ...                         ...\n    source:                     ICOADS, NCEP_GTS, GSFC_ICE, NCEP_ICE, Pathfin...\n    standard_name_vocabulary:   CF Standard Name Table (v40, 25 January 2017)\n    summary:                    NOAAs 1/4-degree Daily Optimum Interpolation ...\n    time_coverage_end:          1981-09-01T23:59:59Z\n    time_coverage_start:        1981-09-01T00:00:00Z\n    title:                      NOAA/NCEI 1/4 Degree Daily Optimum Interpolat...xarray.DatasetDimensions:time: 15044zlev: 1lat: 720lon: 1440Coordinates: (4)lat(lat)float32-89.88 -89.62 ... 89.62 89.88grids :Uniform grid from -89.875 to 89.875 by 0.25long_name :Latitudeunits :degrees_northarray([-89.875, -89.625, -89.375, ...,  89.375,  89.625,  89.875],\n      dtype=float32)lon(lon)float320.125 0.375 0.625 ... 359.6 359.9grids :Uniform grid from 0.125 to 359.875 by 0.25long_name :Longitudeunits :degrees_eastarray([1.25000e-01, 3.75000e-01, 6.25000e-01, ..., 3.59375e+02, 3.59625e+02,\n       3.59875e+02], dtype=float32)time(time)datetime64[ns]1981-09-01T12:00:00 ... 2022-11-...long_name :Center time of the dayarray(['1981-09-01T12:00:00.000000000', '1981-09-02T12:00:00.000000000',\n       '1981-09-03T12:00:00.000000000', ..., '2022-11-06T12:00:00.000000000',\n       '2022-11-07T12:00:00.000000000', '2022-11-08T12:00:00.000000000'],\n      dtype='datetime64[ns]')zlev(zlev)float320.0actual_range :0, 0long_name :Sea surface heightpositive :downunits :metersarray([0.], dtype=float32)Data variables: (4)anom(time, zlev, lat, lon)float32dask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;long_name :Daily sea surface temperature anomaliesunits :Celsiusvalid_max :1200valid_min :-1200\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n58.11 GiB\n3.96 MiB\n\n\nShape\n(15044, 1, 720, 1440)\n(1, 1, 720, 1440)\n\n\nDask graph\n15044 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nerr\n\n\n(time, zlev, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nEstimated error standard deviation of analysed_sst\n\nunits :\n\nCelsius\n\nvalid_max :\n\n1000\n\nvalid_min :\n\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n58.11 GiB\n3.96 MiB\n\n\nShape\n(15044, 1, 720, 1440)\n(1, 1, 720, 1440)\n\n\nDask graph\n15044 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nice\n\n\n(time, zlev, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nSea ice concentration\n\nunits :\n\n%\n\nvalid_max :\n\n100\n\nvalid_min :\n\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n58.11 GiB\n3.96 MiB\n\n\nShape\n(15044, 1, 720, 1440)\n(1, 1, 720, 1440)\n\n\nDask graph\n15044 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nsst\n\n\n(time, zlev, lat, lon)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 1, 720, 1440), meta=np.ndarray&gt;\n\n\n\n\nlong_name :\n\nDaily sea surface temperature\n\nunits :\n\nCelsius\n\nvalid_max :\n\n4500\n\nvalid_min :\n\n-300\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n58.11 GiB\n3.96 MiB\n\n\nShape\n(15044, 1, 720, 1440)\n(1, 1, 720, 1440)\n\n\nDask graph\n15044 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nIndexes: (4)latPandasIndexPandasIndex(Index([-89.875, -89.625, -89.375, -89.125, -88.875, -88.625, -88.375, -88.125,\n       -87.875, -87.625,\n       ...\n        87.625,  87.875,  88.125,  88.375,  88.625,  88.875,  89.125,  89.375,\n        89.625,  89.875],\n      dtype='float32', name='lat', length=720))lonPandasIndexPandasIndex(Index([  0.125,   0.375,   0.625,   0.875,   1.125,   1.375,   1.625,   1.875,\n         2.125,   2.375,\n       ...\n       357.625, 357.875, 358.125, 358.375, 358.625, 358.875, 359.125, 359.375,\n       359.625, 359.875],\n      dtype='float32', name='lon', length=1440))timePandasIndexPandasIndex(DatetimeIndex(['1981-09-01 12:00:00', '1981-09-02 12:00:00',\n               '1981-09-03 12:00:00', '1981-09-04 12:00:00',\n               '1981-09-05 12:00:00', '1981-09-06 12:00:00',\n               '1981-09-07 12:00:00', '1981-09-08 12:00:00',\n               '1981-09-09 12:00:00', '1981-09-10 12:00:00',\n               ...\n               '2022-10-30 12:00:00', '2022-10-31 12:00:00',\n               '2022-11-01 12:00:00', '2022-11-02 12:00:00',\n               '2022-11-03 12:00:00', '2022-11-04 12:00:00',\n               '2022-11-05 12:00:00', '2022-11-06 12:00:00',\n               '2022-11-07 12:00:00', '2022-11-08 12:00:00'],\n              dtype='datetime64[ns]', name='time', length=15044, freq=None))zlevPandasIndexPandasIndex(Index([0.0], dtype='float32', name='zlev'))Attributes: (37)Conventions :CF-1.6, ACDD-1.3cdm_data_type :Gridcomment :Data was converted from NetCDF-3 to NetCDF-4 format with metadata updates in November 2017.creator_email :oisst-help@noaa.govcreator_url :https://www.ncei.noaa.gov/date_created :2020-05-08T19:05:13Zdate_modified :2020-05-08T19:05:13Zgeospatial_lat_max :90.0geospatial_lat_min :-90.0geospatial_lat_resolution :0.25geospatial_lat_units :degrees_northgeospatial_lon_max :360.0geospatial_lon_min :0.0geospatial_lon_resolution :0.25geospatial_lon_units :degrees_easthistory :Final file created using preliminary as first guess, and 3 days of AVHRR data. Preliminary uses only 1 day of AVHRR data.id :oisst-avhrr-v02r01.19810901.ncinstitution :NOAA/National Centers for Environmental Informationinstrument :Earth Remote Sensing Instruments &gt; Passive Remote Sensing &gt; Spectrometers/Radiometers &gt; Imaging Spectrometers/Radiometers &gt; AVHRR &gt; Advanced Very High Resolution Radiometerinstrument_vocabulary :Global Change Master Directory (GCMD) Instrument Keywordskeywords :Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperaturekeywords_vocabulary :Global Change Master Directory (GCMD) Earth Science Keywordsmetadata_link :https://doi.org/10.25921/RE9P-PT57naming_authority :gov.noaa.nceincei_template_version :NCEI_NetCDF_Grid_Template_v2.0platform :Ships, buoys, Argo floats, MetOp-A, MetOp-Bplatform_vocabulary :Global Change Master Directory (GCMD) Platform Keywordsprocessing_level :NOAA Level 4product_version :Version v02r01references :Reynolds, et al.(2007) Daily High-Resolution-Blended Analyses for Sea Surface Temperature (available at https://doi.org/10.1175/2007JCLI1824.1). Banzon, et al.(2016) A long-term record of blended satellite and in situ sea-surface temperature for climate monitoring, modeling and environmental studies (available at https://doi.org/10.5194/essd-8-165-2016). Huang et al. (2020) Improvements of the Daily Optimum Interpolation Sea Surface Temperature (DOISST) Version v02r01, submitted.Climatology is based on 1971-2000 OI.v2 SST. Satellite data: Pathfinder AVHRR SST and Navy AVHRR SST. Ice data: NCEP Ice and GSFC Ice.sensor :Thermometer, AVHRRsource :ICOADS, NCEP_GTS, GSFC_ICE, NCEP_ICE, Pathfinder_AVHRR, Navy_AVHRRstandard_name_vocabulary :CF Standard Name Table (v40, 25 January 2017)summary :NOAAs 1/4-degree Daily Optimum Interpolation Sea Surface Temperature (OISST) (sometimes referred to as Reynolds SST, which however also refers to earlier products at different resolution), currently available as version v02r01, is created by interpolating and extrapolating SST observations from different sources, resulting in a smoothed complete field. The sources of data are satellite (AVHRR) and in situ platforms (i.e., ships and buoys), and the specific datasets employed may change over time. At the marginal ice zone, sea ice concentrations are used to generate proxy SSTs.  A preliminary version of this file is produced in near-real time (1-day latency), and then replaced with a final version after 2 weeks. Note that this is the AVHRR-ONLY DOISST, available from Oct 1981, but there is a companion DOISST product that includes microwave satellite data, available from June 2002time_coverage_end :1981-09-01T23:59:59Ztime_coverage_start :1981-09-01T00:00:00Ztitle :NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2.1 - Final"
  },
  {
    "objectID": "kerchunk/kerchunk-in-practice.html#other-examples-of-existing-kerchunk-data",
    "href": "kerchunk/kerchunk-in-practice.html#other-examples-of-existing-kerchunk-data",
    "title": "Kerchunk in Practice",
    "section": "Other examples of existing kerchunk data",
    "text": "Other examples of existing kerchunk data\n\nCase Studies on kerchunk Docs page"
  },
  {
    "objectID": "kerchunk/intro.html",
    "href": "kerchunk/intro.html",
    "title": "Kerchunk",
    "section": "",
    "text": "Kerchunk is a python library for creating reference files (see next paragraph for an explanation) to support cloud-optimized access to traditional geospatial file formats, like NetCDF. Kerchunk negates the need to create and store copies of data for cloud-optimized access. Given the challenge of creating and maintaining copies of data, Kerchunk is a great tool.\nReference files can be used to instantiate an fsspec.FileSystemReference instance. Kerchunk reference files are json files with key value pairs for reading the underlying data as a Zarr data store. The keys are Zarr metadata paths or paths to zarr data chunks. The values for each key will either be raw data values or a list of the file URL, starting byte, and byte length where the data can be read.\nAs Kerchunk creates Zarr metadata for non-Zarr data, Kerchunk is compatible with Zarr tools that can use Zarr. Kerchunk enables a unified way to access chunked, compressed n-dimensionsional data across a variety of conventional data formats. The kerchunk library now supports NetCDF/HDF5, GRIB2, TIFF. Check the File format backends section of the kerchunk documentation for updates to supported formats.\n\n\n\n\n\n\nWarning\n\n\n\nA major limitation of kerchunk is the chunking of data will always be constrained to the chunk structure of the underlying data format. Read about zarr chunks on the Zarr page.\n\n\nLearn more about kerchunk at kerchunk.readthedocs.io."
  },
  {
    "objectID": "kerchunk/intro.html#what-is-kerchunk",
    "href": "kerchunk/intro.html#what-is-kerchunk",
    "title": "Kerchunk",
    "section": "",
    "text": "Kerchunk is a python library for creating reference files (see next paragraph for an explanation) to support cloud-optimized access to traditional geospatial file formats, like NetCDF. Kerchunk negates the need to create and store copies of data for cloud-optimized access. Given the challenge of creating and maintaining copies of data, Kerchunk is a great tool.\nReference files can be used to instantiate an fsspec.FileSystemReference instance. Kerchunk reference files are json files with key value pairs for reading the underlying data as a Zarr data store. The keys are Zarr metadata paths or paths to zarr data chunks. The values for each key will either be raw data values or a list of the file URL, starting byte, and byte length where the data can be read.\nAs Kerchunk creates Zarr metadata for non-Zarr data, Kerchunk is compatible with Zarr tools that can use Zarr. Kerchunk enables a unified way to access chunked, compressed n-dimensionsional data across a variety of conventional data formats. The kerchunk library now supports NetCDF/HDF5, GRIB2, TIFF. Check the File format backends section of the kerchunk documentation for updates to supported formats.\n\n\n\n\n\n\nWarning\n\n\n\nA major limitation of kerchunk is the chunking of data will always be constrained to the chunk structure of the underlying data format. Read about zarr chunks on the Zarr page.\n\n\nLearn more about kerchunk at kerchunk.readthedocs.io."
  },
  {
    "objectID": "kerchunk/intro.html#why-kerchunk",
    "href": "kerchunk/intro.html#why-kerchunk",
    "title": "Kerchunk",
    "section": "Why Kerchunk?",
    "text": "Why Kerchunk?\nIt is burdensome to create and maintain copies of data. The other pages in this guide introduce data formats which require processing and creating new data products. This process of creating and maintaining new data products, which are essentially copies of existing data, requires time and money. Kerchunk provides a method of providing cloud-optimized access to data that is more traditional archival formats."
  },
  {
    "objectID": "kerchunk/intro.html#how-to-kerchunk",
    "href": "kerchunk/intro.html#how-to-kerchunk",
    "title": "Kerchunk",
    "section": "How to kerchunk",
    "text": "How to kerchunk\nAs noted above, kerchunk is a python library you can use to create a reference file from any of the file formats it supports. The reference file is used by the fsspec.ReferenceFileSystem to read data from local or remote storage.\nHere’s an example:\nimport fsspec\nimport json\nfrom kerchunk.hdf import SingleHdf5ToZarr\n\nlocal_file = 'some_data.nc'\nout_file = 'some_references.json'\n\n# Instantiate the local file system with fsspec to save kerchunk's reference data as json.\nfs = fsspec.filesystem('')\nin_file = fs.open(local_file)\n\n# The inline threshold adjusts the size below which binary blocks are included directly in the output.\n# A higher inline threshold can result in a larger json file but faster loading time overally, since fewer requests are made.\nh5chunks = SingleHdf5ToZarr(in_file, local_file, inline_threshold=300)\nwith fs.open(out_file, 'wb') as f:\n    f.write(json.dumps(h5chunks.translate()).encode())\n\n\n\n\n\n\nNote\n\n\n\nThe powerful fsspec library provides a uniform file system interface to many different storage backends and protocols. In addition to abstracting existing protocols, its ReferenceFileSystem class lets you view byte ranges of some other file as a file system. Kerchunk generates these ReferenceFileSystem objects.\n\n\nKerchunk generates a “reference set” which is a set of references to data or URLs under a key value store that matches the Zarr spec. For example, a simple reference file for a NetCDF file might look like:\n{\n  \".zgroup\": \"{\\n    \\\"zarr_format\\\": 2\\n}\",\n  \".zattrs\": \"{\\n    \\\"Conventions\\\": \\\"UGRID-0.9.0\\n\\\"}\",\n  \"x/.zattrs\": \"{\\n    \\\"_ARRAY_DIMENSIONS\\\": [\\n        \\\"node\\\"\\n ...\",\n  \"x/.zarray\": \"{\\n    \\\"chunks\\\": [\\n        9228245\\n    ],\\n    \\\"compressor\\\": null,\\n    \\\"dtype\\\": \\\"&lt;f8\\\",\\n  ...\",\n  \"x/0\": [\"s3://bucket/path/file.nc\", 294094376, 73825960]\n}\nThe [\"s3://bucket/path/file.nc\", 294094376, 73825960] is the key part, which says that to load the first chunk in the x dimension, the Zarr reader needs to fetch a byte range starting at 294094376 with a length of 73825960 bytes. This allows for efficient cloud-native data access without using the standard NetCDF driver.\nLearn more about how to read and write kerchunk reference files in the Kerchunk in Practice notebook."
  },
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "Template",
    "section": "",
    "text": "Format Basics (or What is a XX?)\n\n\nExample of Creating this Format\n\n\nExample of Cloud-Optimized Access for this Format"
  },
  {
    "objectID": "zarr/intro.html",
    "href": "zarr/intro.html",
    "title": "Zarr",
    "section": "",
    "text": "Zarr, despite its name, is not a scary format. It’s designed for data that is too big for users’ machines, but Zarr makes data small and organizes it in a way where users can take just the bits they need or distribute the load of processing lots of those bits (stored as chunks) across many machines.\nThe Zarr data format is a community-maintained format for large-scale n-dimensional data. A Zarr store consists of compressed and chunked n-dimensional arrays. Zarr’s flexible indexing and compatibility with object storage lends itself to parallel processing.\nA Zarr chunk is Zarr’s unit of data storage. Each chunk of a Zarr array is an equally-sized block of the array within a larger Zarr store comprised of one or more arrays and array groups. These blocks or chunks of data are stored separately to make reading and updating small chunks more efficient.\nRead more in the official tutorial: Zarr Tutorial\n\n\n\n\n\n\n\n\nImportant\n\n\n\nZarr Version 3 is underway but not released yet, so all the examples in this guide are for Zarr Version 2 data. The concepts in this page are consistent across both Zarr Version 2 and Zarr Version 3, however some metadata field names and organization are changing from Version 2 to version 3.\n\n\nVersion 3 changes from Version 2:\n\ndtype has been renamed to data_type,\nchunks has been replaced with chunk_grid,\ndimension_separator has been replaced with chunk_key_encoding,\norder has been replaced by the transpose codec,\nthe separate filters and compressor fields been combined into the single codecs field.\n\nRead more:\n\nZarr specification version 2\nZarr specification version 3.0\n\n\n\n\n\n\nZarr arrays are similar to numpy arrays, but chunked and compressed. We will add details about chunking and compression to this guide soon.\n\n\n\nZarr supports hierarchical organization via groups. Each node in the Zarr hierarchy is either a group or an array.\n\n\n\nA Zarr array has zero or more dimensions. A Zarr array’s shape is the tuple of the length of the array in each respective dimension.\n\n\n\nZarr indexing supports array subsetting (both reading and writing) without loading the whole array into memory. Advanced indexing operations, such as block indexing, are detailed in the Zarr tutorial: Advanced indexing.\n\n\n\n\n\n\nNote\n\n\n\nThe Zarr format is language-agnostic, but this indexing reference is specific to Python.\n\n\nThe Xarray library provides a rich API for slicing and subselecting data. In addition to providing a positional index to subselect data, xarray supports label-based indexing. Labels, or coordinates, in the case of geospatial data, often include latitude and longitude (or y and x). These coordinates (also called names or labels) can be used to read and write data when the position is unknown.\n\n\n\nEvery Zarr array has its own metadata. When considering cloud storage options, where latency is high so total requests should be limited, it is important to consolidate metadata so all metadata can be read from one object.\nRead more on consolidating metadata.\n\n\n\n\n\n\nZarr can be stored in memory, on disk, in Zip files, and in object storage like S3.\n\n\n\n\n\n\nNote\n\n\n\nAny backend that implements MutableMapping interface from the Python collections module can be used to store Zarr. Learn more and see all the options on the Storage (zarr.storage) documentation page.\n\n\nAs of Zarr version 2.5, Zarr store URLs can be passed to fsspec and it will create a MutableMapping automatically.\n\n\n\nChunking is the process of dividing the data arrays into smaller pieces. This allows for parallel processing and efficient storage.\nOnce data is chunked, applications may read in 1 or many chunks. Because the data is compressed, within-chunk reads are not possible.\n\n\n\nZarr supports compression algorithms to support efficient storage and retrieval.\nTo explore these concepts in practice, see the Zarr in Practice notebook."
  },
  {
    "objectID": "zarr/intro.html#zarr-version-2-and-version-3",
    "href": "zarr/intro.html#zarr-version-2-and-version-3",
    "title": "Zarr",
    "section": "",
    "text": "Important\n\n\n\nZarr Version 3 is underway but not released yet, so all the examples in this guide are for Zarr Version 2 data. The concepts in this page are consistent across both Zarr Version 2 and Zarr Version 3, however some metadata field names and organization are changing from Version 2 to version 3.\n\n\nVersion 3 changes from Version 2:\n\ndtype has been renamed to data_type,\nchunks has been replaced with chunk_grid,\ndimension_separator has been replaced with chunk_key_encoding,\norder has been replaced by the transpose codec,\nthe separate filters and compressor fields been combined into the single codecs field.\n\nRead more:\n\nZarr specification version 2\nZarr specification version 3.0"
  },
  {
    "objectID": "zarr/intro.html#zarr-data-organization",
    "href": "zarr/intro.html#zarr-data-organization",
    "title": "Zarr",
    "section": "",
    "text": "Zarr arrays are similar to numpy arrays, but chunked and compressed. We will add details about chunking and compression to this guide soon.\n\n\n\nZarr supports hierarchical organization via groups. Each node in the Zarr hierarchy is either a group or an array.\n\n\n\nA Zarr array has zero or more dimensions. A Zarr array’s shape is the tuple of the length of the array in each respective dimension.\n\n\n\nZarr indexing supports array subsetting (both reading and writing) without loading the whole array into memory. Advanced indexing operations, such as block indexing, are detailed in the Zarr tutorial: Advanced indexing.\n\n\n\n\n\n\nNote\n\n\n\nThe Zarr format is language-agnostic, but this indexing reference is specific to Python.\n\n\nThe Xarray library provides a rich API for slicing and subselecting data. In addition to providing a positional index to subselect data, xarray supports label-based indexing. Labels, or coordinates, in the case of geospatial data, often include latitude and longitude (or y and x). These coordinates (also called names or labels) can be used to read and write data when the position is unknown.\n\n\n\nEvery Zarr array has its own metadata. When considering cloud storage options, where latency is high so total requests should be limited, it is important to consolidate metadata so all metadata can be read from one object.\nRead more on consolidating metadata."
  },
  {
    "objectID": "zarr/intro.html#zarr-data-storage",
    "href": "zarr/intro.html#zarr-data-storage",
    "title": "Zarr",
    "section": "",
    "text": "Zarr can be stored in memory, on disk, in Zip files, and in object storage like S3.\n\n\n\n\n\n\nNote\n\n\n\nAny backend that implements MutableMapping interface from the Python collections module can be used to store Zarr. Learn more and see all the options on the Storage (zarr.storage) documentation page.\n\n\nAs of Zarr version 2.5, Zarr store URLs can be passed to fsspec and it will create a MutableMapping automatically.\n\n\n\nChunking is the process of dividing the data arrays into smaller pieces. This allows for parallel processing and efficient storage.\nOnce data is chunked, applications may read in 1 or many chunks. Because the data is compressed, within-chunk reads are not possible.\n\n\n\nZarr supports compression algorithms to support efficient storage and retrieval.\nTo explore these concepts in practice, see the Zarr in Practice notebook."
  },
  {
    "objectID": "zarr/intro.html#what-zarr-is-not",
    "href": "zarr/intro.html#what-zarr-is-not",
    "title": "Zarr",
    "section": "What Zarr is not",
    "text": "What Zarr is not\nZarr is not designed for vector, point cloud or sparse data, although there is investigations into supporting a greater variety of data types."
  },
  {
    "objectID": "zarr/intro.html#zarr-is-in-development",
    "href": "zarr/intro.html#zarr-is-in-development",
    "title": "Zarr",
    "section": "Zarr is in Development",
    "text": "Zarr is in Development\nThere are some limitations of Zarr which is why there are Zarr Enhancement Proposals.\nZarr Version 3 was itself a ZEP, which has been accepted.\nDraft ZEPs are recommended reading for anyone considering creating a new Zarr store, since they address common challenges with Zarr data to date."
  },
  {
    "objectID": "transition-from-rmarkdown.html",
    "href": "transition-from-rmarkdown.html",
    "title": "Transition from RMarkdown",
    "section": "",
    "text": "You may already have workflows in RMarkdown and are interested in transitioning to Quarto. There’s no hurry to migrate to Quarto. Keep using Rmarkdown and when you’re ready the migration will be fine.\nHere are some notes as we migrate RMarkdown sites and books.\nTODO: translating R code chunks"
  },
  {
    "objectID": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "href": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Bookdown to Quarto",
    "text": "Bookdown to Quarto\nConverting a Bookdown book to Quarto is slightly more involved than converting a website. A book has chapters whose order must be defined, and likely has citations and cross-refs. Still, conversion is not that hard.\nWe got some practice converting from Bookdown to Quarto by helping Gavin Fay convert his lab’s fantastic onboarding documentation, the Faylab Lab Manual. Here’s the GitHub view before and after.\nOur best first reference material for this was Nick Tierney’s Notes on Changing from Rmarkdown/Bookdown to Quarto. Nick shares some scripts in that post to automate some changes. In our case, the book was small enough that we made all changes manually. Quarto documentation was indispensable.\n\nExperimenting in a low-risk environment\nWe forked a copy of the Faylab Lab manual to the Openscapes organization, and worked in a branch so we could make changes relatively risk-free. We could always fork a new copy of the original if we “broke” something. (Caution: the default when making a pull request from a fork is to push changes to the original upstream repo, not your fork and it does this without warning if you have write-access to that repo.) With local previews it’s easy to test / play with settings to see what they do. We tended to make a change, Preview, then compare the look and functionality of the book to the original. It was helpful to comment out some elements of the configuration file _output.yml after their counterparts had been added to the Quarto configuration file _quarto.yml, or to confirm they were no longer needed, before making the drastic move of deleting them.\n\n\nThe conversion\nHere are the main steps to convert the Faylab Lab manual from Bookdown to Quarto.\nCreate new empty file called _quarto.yml and add book metadata there. The screenshots below\nSet project type as book.\nMove metadata out of index.qmd and into _quarto.yml. Title, author, and publication date were in index.qmd with date set using date: \"Last updated:r Sys.Date()\". Now these are in _quarto.yml with date set using date: last-modified. Note that having R code would require you to adjust code chunk options in the Quarto style (#|). This tripped us up a bit; see GitHub Actions.\nMove chapters listing out of _bookdown.yml and into _quarto.yml.\nAdd page footer to _quarto.yml.\nHere’s what ours looked like when we finished the steps above (_quarto.yml).\n\n\n\n\n\n\n_quarto.yml contents\n\n\n\n\n\n\n\nFaylab Lab Manual\n\n\n\n\n\nChange insertion of images from html style to Quarto style. (Note Quarto calls them “figures”, not “images”.) The following snippet will insert the GitHub octocat logo in a page:\n![](https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png){fig-align=\"left\" width=\"35px\"}\nChange all filename extensions .Rmd -&gt; .qmd (you could Preview after this change and see that the book looks the same). Note that Quarto works with .Rmd files just as well as it does .qmd, so this change is not urgent. In fact, if you have a lot of R code in your .Rmds (unlike the Faylab Lab Manual), there will be additional tinkering needed to make the code chunks happy.\n\n\nCitations\nThe Faylab Lab Manual cited two papers, presenting us with an opportunity to see how easy it is to add references to a Quarto book. Briefly, in the Visual Editor, Insert &gt; Citation &gt; DOI. Pasting the DOI or its full URL, we can insert the citation. This automatically creates a references.bib file and adds the full citations at the bottom of the chapter page (watch demo). In July 2022, we had to manually add a ## References heading, but this may not be necessary in future Quarto updates.\n\n\n\n\n\n\nInsert citation via its DOI using RStudio Visual Editor\n\n\n\n\n\n\n\n\n\n\nPublishing notes\nIf the book’s output is strictly html, there’s no need to specify output-dir in _quarto.yml. The output directory default is _book/, which is what we’d like. If we wanted other types of output like like PDF or EPUB, etc. those single file outputs are also written to the output-dir (Quarto docs).\nIf you currently have a docs/ folder, delete it.\nUpdate .gitignore to ignore _book/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_book/\nOnce all is settled, delete _output.yml.\nOnce the Openscapes fork was fully reviewed, we made a pull request from that to the main branch of the book’s repo. Once that was merged, we set up GitHub Actions to render the book. (TODO: instructions for GitHub Actions)\n\n\nGitHub Actions\nThis book was mostly prose and screenshots without any R code. This made the conversion from RMarkdown to Quarto likely more straightforward than if you also needed to adjust code chunk options in the quarto style (#|). Our initial GitHub Action to render the converted Faylab Lab Manual failed because we had a piece of R code - even though the code was commented out! This was resolved when we deleted the line."
  },
  {
    "objectID": "transition-from-rmarkdown.html#distill-to-quarto",
    "href": "transition-from-rmarkdown.html#distill-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Distill to quarto",
    "text": "Distill to quarto\nWe transitioned our events site from distill to quarto in May 2022 (github view before and after). We followed excellent notes and examples from Nick Tierney and Danielle Navarro.\nAfter we had changed all the files, the Build tab in the RStudio IDE still showed “Build website” rather then “Render Website” and “Preview Website”, and would error when we pushed them (because that button was expecting a distill site, not a quarto site). To fix this, we updated the .Rproj file. Clicking on the .Rproj file in the RStudio IDE will open a dialog box where you can click things you want (you can also open these in a text editor or from the GitHub website to see the actual text). To fix this situation with the Build tab: Project Options &gt; Build Tools &gt; Project Build Tools &gt; None.\nLooking at files /posts/_metadata.yml and _quarto.yml helps see where things are defined. For example, to make event post citations appear, we added citation: true to /posts/_metadata.yml and in _quarto.yml under the website key we set site-url: https://openscapes.github.io/events. We deleted footer.html used with distill because footer is now defined in quarto.yml.\n\nPublishing notes\n\nBackground: Our distill site had been set up to output to a docs folder, and had GitHub Settings &gt; Pages set to look there rather gh-pages branch. (Julie note: this was a new-to-me capability when we set up the events distill site in Spring 2021 so I had forgotten that was an option). We’ve inititally kept this same set-up for now with our events page in _quarto.yml: output-dir: docs. However, this is sub-optimal; better to not have to commit and push these files but to instead have a GitHub Action generate them upon a commit. So the following is what we did -\n\nDon’t specify output-dir in _quarto.yml. The output directory default is _site/, which is what we’d like.\nIf you currently have a docs/ folder (like we did as we were experimenting), delete it.\nUpdate .gitignore to ignore _site/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_site/\nPush these changes, merge into main.\nOn GitHub.com, in your repo, set up GitHub publishing\nFollow instructions from the explore and setup chapter."
  },
  {
    "objectID": "transition-from-rmarkdown.html#troubleshooting",
    "href": "transition-from-rmarkdown.html#troubleshooting",
    "title": "Transition from RMarkdown",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nGitHub Action fails, says you need RMarkdown but you don’t have R code!\nAnd you changed all .Rmds to .qmds!\nYou likely have a few setup code chunks from RMarkdown, that look like this:\n{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nYou can find them by opening each of your files and having a look, or use GitHub’s search for the keyword knitr"
  },
  {
    "objectID": "flatgeobuf/hilbert-r-tree.html",
    "href": "flatgeobuf/hilbert-r-tree.html",
    "title": "FlatGeobuf Spatial Index",
    "section": "",
    "text": "FlatGeobuf optionally supports including a spatial index that enables random access for each geometry in the file."
  },
  {
    "objectID": "flatgeobuf/hilbert-r-tree.html#when-to-use",
    "href": "flatgeobuf/hilbert-r-tree.html#when-to-use",
    "title": "FlatGeobuf Spatial Index",
    "section": "When to use",
    "text": "When to use\nWhen writing a FlatGeobuf file, one must decide whether to include a spatial index. A spatial index cannot be added to a FlatGeobuf file after the file has been written.\nA spatial index can enable much more efficient reading from FlatGeobuf, by allowing the reader to skip over portions of the file that fall outside of a qiven spatial query region."
  },
  {
    "objectID": "flatgeobuf/hilbert-r-tree.html#technical-details",
    "href": "flatgeobuf/hilbert-r-tree.html#technical-details",
    "title": "FlatGeobuf Spatial Index",
    "section": "Technical details",
    "text": "Technical details\nIn this section we’ll get into some gory technical details of how FlatGeobuf’s spatial index works. Understanding the below isn’t necessary for using FlatGeobuf, but it may add context for understanding how to create and work with FlatGeobuf files, and why FlatGeobuf is performant.\nFlatGeobuf’s spatial index is a static packed Hilbert R-tree index. That’s a mouthful, so let’s break it down:\n\nR-tree index\nAn R-Tree is a hierarchical collection of bounding boxes. At the lowest level of the tree is a bounding box of every geometry. Then one level above the lowest level exists a collection of bounding boxes, each of which is formed as the union of all child boxes. This means that each box encompasses every child box. There are fewer boxes at this level, because each box contains many child boxes, each of which represents one original geometry. This process continues repeatedly until there’s only one bounding box that indirectly contains the entire dataset.\nThis index allows you to quickly search for features that intersect a given bounding box query. At the top level, compare the bounding box of each node to your query region. If those two don’t intersect, you can discard that node and all of its child nodes from the search, because you know that none of them could possibly fall within your search region.\nContinuing this process allows you to quickly find only the specific items that are candidates for your search query.\n\n\nR-Tree diagram from Wikipedia. From top to bottom, the three levels of this tree are the black, blue, and red boxes. The black boxes contain the most items and encompass the largest area, while the red boxes contain the fewest items and encompass a smaller area.\n\nThe Wikipedia article and this Mapbox blog post are great resources for better understanding how R-Trees work.\n\n\nHilbert\nThe elements of an R-Tree must be sorted before insertion to make the R-Tree useful. This is because the core benefit of an R-Tree is to exclude elements that aren’t within a spatial filter. If elements of each node are randomly drawn from different geographies, then each node’s bounding box will be so large that no nodes can be excluded.\nBut how do you sort geometries? They encompass two dimensions and a range of shapes. If you sort all geometries first on the x coordinate, then you may pair geometries that are far from each other on the y dimension. Instead, it’s ideal to use a space-filling curve. That’s math jargon, but essentially defines a way to sort elements in n dimensions using 1 dimensional numbers.\nA Hilbert R-Tree uses a Hilbert Curve, a special type of space-filling curve, to sort the centers of geometries. This ensures that geometries that are nearby on both the x and y dimensions are placed close to each other in the R-Tree. This ensures that the resulting bounding boxes of the R-Tree are as small as possible, which means that the maximum number of elements can be discarded for any given spatial query.\nThis Crunchy Data blog post has helpful examples for why sorting input is important.\n\n\nStatic\nFlatGeobuf files can’t be modified without rewriting the entire file, so this R-Tree is constructed in such a way that it can’t be modified, which allows for improved tree generation.\n\n\nPacked\nAn R-Tree has a series of nodes at each level, where each node can contain up to n children. If the R-Tree might be updated, not every node will have a total of n children, because some space needs to be reserved for future elements.\nBecause the index is static and immutable, we can construct a packed index, where every node is completely full. This achieves better space utilization, and is more efficient for queries because there are fewer nodes to traverse."
  },
  {
    "objectID": "flatgeobuf/flatgeobuf-in-js.html",
    "href": "flatgeobuf/flatgeobuf-in-js.html",
    "title": "FlatGeobuf in JavaScript",
    "section": "",
    "text": "FlatGeobuf is a cloud-native vector data format because it contains a built-in spatial index that allows reading a specific spatial region from within the file without downloading the entire file’s content.\nThis is very useful for browser-based applications, because it allows them to make use of large files hosted on commodity cloud object storage without maintaining a server.\nThis notebook provides an example of using FlatGeobuf with spatial filtering from JavaScript."
  },
  {
    "objectID": "flatgeobuf/flatgeobuf-in-js.html#downloading-vs-streaming-vs-range-reads",
    "href": "flatgeobuf/flatgeobuf-in-js.html#downloading-vs-streaming-vs-range-reads",
    "title": "FlatGeobuf in JavaScript",
    "section": "Downloading vs Streaming vs Range reads",
    "text": "Downloading vs Streaming vs Range reads\nFlatGeobuf supports a few different ways of loading data into the browser.\nDownloading refers to fetching the entire FlatGeobuf file and parsing it after the full file has finished downloading. This has the downside that the user must wait for the entire download to finish before they see any interaction on the web page. This may lead to a user wondering if the web page is broken if it takes a while to download their data.\nStreaming refers to making use of a file’s contents incrementally as it downloads. This approach still downloads the entire file from beginning to end, but enables e.g. rendering part of the data on a map quickly, before waiting for the full file to finish downloading. This has the benefit of increased responsiveness, but the downside that a large file will be loaded in full. FlatGeobuf supports streaming because the file’s metadata is located at the beginning. A good example of this in action is “Streaming FlatGeobuf” by Björn Harrtell.\nRange reads refers to fetching only specific parts of the file that are required by the user. In the context of FlatGeobuf, this usually means a spatial query. FlatGeobuf enables this through its spatial index at the beginning of the file. Web clients can read the header, and then make requests only for data in a specific location. This has the benefit that very large files can be used in situations where downloading them in full would be impractical. A downside is that it takes more individual HTTP requests to understand which byte range in the file contains the desired data, leading to a longer latency before data starts to display."
  },
  {
    "objectID": "flatgeobuf/flatgeobuf-in-js.html#example",
    "href": "flatgeobuf/flatgeobuf-in-js.html#example",
    "title": "FlatGeobuf in JavaScript",
    "section": "Example",
    "text": "Example\nThis example uses slightly-modified JavaScript syntax used in Observable notebooks.\nLoad the FlatGeobuf JavaScript library:\n\nflatgeobuf = require(\"flatgeobuf@3.26.2/dist/flatgeobuf-geojson.min.js\")\n\n\n\n\n\n\nThis library has two functions: deserialize to fetch a remote file and parse it to GeoJSON, and serialize, which converts GeoJSON to FlatGeobuf.\n\nflatgeobuf\n\n\n\n\n\n\nFor this demo, we’ll use the same data source as in the FlatGeobuf leaflet example. This data file represents every census block in the USA.\n\nurl = 'https://flatgeobuf.septima.dk/population_areas.fgb'\n\n\n\n\n\n\nThe above is a really big file at almost 12GB total size, so we don’t want to fetch the entire file. In this demo, we’ll choose a small bounding box representing an area over Manhattan in New York City.\nBeware: if you make this bounding box too big, FlatGeobuf will try to download a large amount of data into your browser and maybe crash the tab!\n\nbbox = {\n    return {\n        minX: -74.003802,\n        minY: 40.725756,\n        maxX: -73.981481,\n        maxY: 40.744008,\n    }\n}\n\n\n\n\n\n\nThe above bbox object represents a bounding box in the format required by the FlatGeobuf API, but Leaflet’s API requires an array-formatted bounding box, so we’ll define a function to convert between the two:\n\n// leaflet uses lat-lon ordering\nbboxObjectToArray = (obj) =&gt; [\n  [obj.minY, obj.minX],\n  [obj.maxY, obj.maxX],\n];\n\n\n\n\n\n\nNext we’ll fetch all the data from the FlatGeobuf file within this bounding box. Notice how we pass the bbox argument into deserialize.\n\nfeatures = {\n  const iter = flatgeobuf.deserialize(url, bbox);\n  const features = [];\n  for await (const feature of iter) {\n    features.push(feature);\n  }\n  return features;\n}\n\n\n\n\n\n\nThere are 354 individual features that match this query:\n\nfeatures\n\n\n\n\n\n\nAs in the FlatGeobuf example, we’ll define a color scale based on how many people live in the census block.\n\ncolorScale = (d) =&gt; {\n  return d &gt; 750\n    ? \"#800026\"\n    : d &gt; 500\n    ? \"#BD0026\"\n    : d &gt; 250\n    ? \"#E31A1C\"\n    : d &gt; 100\n    ? \"#FC4E2A\"\n    : d &gt; 50\n    ? \"#FD8D3C\"\n    : d &gt; 25\n    ? \"#FEB24C\"\n    : d &gt; 10\n    ? \"#FED976\"\n    : \"#FFEDA0\";\n};\n\n\n\n\n\n\nNext we load the Leaflet JavaScript library and fetch its CSS styling defintions if needed.\n\nL = {\n  const L = await require(\"leaflet@1/dist/leaflet.js\");\n  if (!L._style) {\n    const href = await require.resolve(\"leaflet@1/dist/leaflet.css\");\n    document.head.appendChild(L._style = html`&lt;link href=${href} rel=stylesheet&gt;`);\n  }\n  return L;\n}\n\n\n\n\n\n\nNext we instantiate the Leaflet map and include multiple layers:\n\nAn L.tileLayer to show basemap tiles on the map for context.\nAn L.rectangle to show the bounding box of our FlatGeobuf query.\nAn L.layerGroup to group all the FlatGeobuf features into a single layer.\nAn L.geoJSON item for each feature in the FlatGeobuf response.\n\n\nmap = {\n  const container = html`&lt;div style=\"height:600px;\"&gt;&lt;/div&gt;`;\n  yield container;\n  const map = L.map(container).setView([40.7299, -73.9923], 13);\n  L.tileLayer(\"https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\", {\n    attribution:\n      \"&copy; &lt;a href=https://www.openstreetmap.org/copyright&gt;OpenStreetMap&lt;/a&gt; contributors\",\n  }).addTo(map);\n\n  // Render the bounding box rectangle\n  L.rectangle(bboxObjectToArray(bbox), {\n    interactive: false,\n    color: \"blue\",\n    fillOpacity: 0.0,\n    opacity: 1.0,\n  }).addTo(map);\n\n  const results = L.layerGroup().addTo(map);\n  for (const feature of features) {\n    // Leaflet styling\n    const defaultStyle = {\n      color: colorScale(feature.properties[\"population\"]),\n      weight: 1,\n      fillOpacity: 0.4,\n    };\n    L.geoJSON(feature, {\n      style: defaultStyle,\n    })\n      .on({\n        mouseover: function (e) {\n          const layer = e.target;\n          layer.setStyle({\n            weight: 4,\n            fillOpacity: 0.8,\n          });\n        },\n        mouseout: function (e) {\n          const layer = e.target;\n          layer.setStyle(defaultStyle);\n        },\n      })\n      .bindPopup(\n        `${feature.properties[\"population\"]} people live in this census block.&lt;/h1&gt;`\n      )\n      .addTo(results);\n  }\n}\n\n\n\n\n\n\nVoilà! We just fetched data directly from a massive FlatGeobuf file, directly from the client, without a server in between.\n\nReferences\nThis notebook was created with help from several resources\n\nFlatGeobuf Leaflet example (and its source code)\n@bjornharrtell/streaming-flatgeobuf is a useful related resource for an example of a streaming load of FlatGeobuf.\n@observablehq/hello-leaflet for an example of loading and rendering a Leaflet map using Observable."
  },
  {
    "objectID": "geoparquet/index.html",
    "href": "geoparquet/index.html",
    "title": "GeoParquet",
    "section": "",
    "text": "GeoParquet is an encoding for how to store geospatial vector data (point, lines, polygons) in Apache Parquet, a popular columnar storage format for tabular data.\nParquet has a wide ecosystem of tools and support; GeoParquet builds on this success by defining how to store geometries in the Parquet format. Because GeoParquet is not a separate format, any program that can read Parquet is able to load GeoParquet as well, even if it can’t make sense of the geometry information. This is very similar to how GeoTIFF layers geospatial information on top of the existing TIFF image standard.\nThe two main things that GeoParquet defines on top of Parquet are how to encode geometries in the geometry column and how to include metadata like the geometries’ Coordinate Reference System (CRS).\nGeoParquet is a relatively young format, and the specification has not yet reached a 1.0 release (as of August 2023, it’s at 1.0.0-rc.1). However, reading and writing GeoParquet has been supported in GDAL since version 3.5, and thus can be used in programs like GeoPandas and QGIS.\n\n\n\n\n\n\nWarning\n\n\n\nIn GeoPandas use read_parquet and to_parquet to read and write GeoParquet, not read_file and to_file as one would use with most other formats. 1\n\n\nBecause GeoParquet stores geometries in standard Well-Known Binary (WKB), it supports any vector geometry type defined in the OGC Simple Features specification. This includes the standard building blocks of Point, LineString, Polygon, MultiPoint, MultiLineString, MultiPolygon, and GeometryCollection. A best practice is to store only geometries with the same type, as that allows readers to know which geometry type is stored without scanning the entire file.\nSome of the sections below will discuss strengths of Parquet in general. Keep in mind that because GeoParquet is built on top of Parquet, GeoParquet inherits all of these strengths.\n\n\nParquet files are laid out differently than other tabular formats like CSV or FlatGeobuf, so it’s helpful to see a diagram:\n\n\n\nSchematic of Parquet file layout\n\n\nA Parquet file consists of a sequence of chunks called row groups. These are logical groups of columns with the same number of rows. A row group consists of multiple columns, each of which is called a column chunk. These are sequences of raw column values that are guaranteed to be contiguous in the file. All row groups in the file must have the same schema, meaning that the data type of each column must be the same for every row group.\nA Parquet file includes metadata describing the internal chunking. This metadata includes the byte range of every column chunk in the dataset. This allows a Parquet reader to fetch any given column chunk once they have the file metadata.\nThe Parquet metadata also includes column statistics (the minimum and maximum value) for each column chunk. This means that if a user is interested in data where column “A” has values greater than 100, the Parquet reader can skip loading and parsing any column chunks where the maximum is known to be less than 100.\nIn Parquet, the metadata is located at the end of the file rather than at the beginning. This makes it much easier to write, as you don’t need to know how many total rows you have at the beginning, but makes it slightly harder to read. In practice, this is not too much more difficult to read: a Parquet reader first reads the end of the file, then makes reads for select columns.\n\n\nThe bytes of each column are contiguous, instead of each row. This means that it’s easy to filter on columns — fetching all rows of a single column — but not possible to filter on individual rows.\n\n\n\nBecause Parquet is column-oriented, a Parquet reader can fetch only specific columns that the user is interested in.\n\n\n\nBecause Parquet is internally chunked, Parquet can fetch only specific row groups that meet a specific filtering condition.\nNote that row group filtering on a specific column tends to only work well if the Parquet file was sorted on that column when saved. Non-sorted columns tend to have random values, and so the column statistics won’t tend to filter out many row groups.\n\n\n\n\n\n\nNote\n\n\n\nIn general it’s only possible to optimize filtering row groups by one column. This is the biggest difference between file formats and databases. Databases can have multiple indexes on whatever columns you want, and then when you run a query, and it will use all of the indexes. But that’s why it’s hard to make databases work as cloud-native files, because if you have high latency, you don’t want to make lots of tiny fetches.\n\n\n\n\n\nParquet is internally compressed by default and Parquet compression is more efficient compared to other formats.\nCompression algorithms are more effective when nearby bytes are more similar to each other. Data within a column tends to be much more similar than data across a row. Since Parquet is column-oriented, compression algorithms work better and result in smaller file sizes than a comparable row-based format.\nIt’s possible to have random access to one of the internal chunks inside the file at large, even though that chunk is compressed. Note that it isn’t possible to fetch partial data inside one chunk without loading and decompressing the entire chunk.\n\n\n\nFor maximum compatibility with existing systems, geometries are stored as ISO-standard WKB. Most geospatial programs are able to read and write WKB.\n\n\n\nGeoParquet is a young specification, and spatial indices are not yet part of the standard. Future revisions of GeoParquet are expected to add support for spatial indexes.\nOne way around this is to store multiple GeoParquet files according to some region identifier, cataloging each file with the SpatioTemporal Asset Catalog (STAC) specification.\n\n\n\nIn a streaming download, you read bytes starting at the beginning of the file, progressing towards the end. In Parquet, this is not helpful because the metadata is in the footer of the file instead of the header.\nInstead, we can replicate something similar to streaming by first fetching only the metadata region at the end of the file, and then making multiple requests for each internal chunk.\n\n\n\nOnce written, a Parquet file is immutable. No modification or appending can happen to that Parquet file. Instead, create a new Parquet file.\n\n\n\nWhile at medium data sizes GeoParquet is most easily distributed as a single file, at large data sizes a single dataset is often split into multiple files. Sometimes multiple files can be easier to write, such as if the data is output from a distributed system.\nA best practice when writing multiple files is to store a top-level metadata file, often named _metadata, with the metadata of all Parquet files in the directory. Without a top-level metadata file, a reader must read the Parquet footer of every individual file in the directory before reading any data. With a metadata file, a Parquet reader can read just that one metadata file, and then read the relevant chunks in the directory. For more information on this, read the “Partitioned Datasets” and “Writing _metadata and _common_metadata files” of the pyarrow documentation. As of August 2023, GeoPandas has no way to write multiple GeoParquet files out of the box, though you may be able to pass a * glob with multiple paths into geopandas.read_parquet.\nStoring Parquet data in multiple files makes it possible to in effect append to the dataset by adding a new file to the directory, but you must be careful to ensure that the new file has the exact same data schema as the existing files, and if a top-level metadata file exists, it must be rewritten to reflect the new file.\nSome elements of how to store GeoParquet-specific metadata in a multi-file layout have not yet been standardized.\n\n\n\nParquet supports a very extensive type system, including nested types such as lists and maps (i.e. like a Python dict). This means that you can store a key-value mapping or a multi-dimensional array within an attribute column of a GeoParquet dataset.\n\n\n\n\n\nDemystifying the Parquet File Format"
  },
  {
    "objectID": "geoparquet/index.html#file-layout",
    "href": "geoparquet/index.html#file-layout",
    "title": "GeoParquet",
    "section": "",
    "text": "Parquet files are laid out differently than other tabular formats like CSV or FlatGeobuf, so it’s helpful to see a diagram:\n\n\n\nSchematic of Parquet file layout\n\n\nA Parquet file consists of a sequence of chunks called row groups. These are logical groups of columns with the same number of rows. A row group consists of multiple columns, each of which is called a column chunk. These are sequences of raw column values that are guaranteed to be contiguous in the file. All row groups in the file must have the same schema, meaning that the data type of each column must be the same for every row group.\nA Parquet file includes metadata describing the internal chunking. This metadata includes the byte range of every column chunk in the dataset. This allows a Parquet reader to fetch any given column chunk once they have the file metadata.\nThe Parquet metadata also includes column statistics (the minimum and maximum value) for each column chunk. This means that if a user is interested in data where column “A” has values greater than 100, the Parquet reader can skip loading and parsing any column chunks where the maximum is known to be less than 100.\nIn Parquet, the metadata is located at the end of the file rather than at the beginning. This makes it much easier to write, as you don’t need to know how many total rows you have at the beginning, but makes it slightly harder to read. In practice, this is not too much more difficult to read: a Parquet reader first reads the end of the file, then makes reads for select columns.\n\n\nThe bytes of each column are contiguous, instead of each row. This means that it’s easy to filter on columns — fetching all rows of a single column — but not possible to filter on individual rows.\n\n\n\nBecause Parquet is column-oriented, a Parquet reader can fetch only specific columns that the user is interested in.\n\n\n\nBecause Parquet is internally chunked, Parquet can fetch only specific row groups that meet a specific filtering condition.\nNote that row group filtering on a specific column tends to only work well if the Parquet file was sorted on that column when saved. Non-sorted columns tend to have random values, and so the column statistics won’t tend to filter out many row groups.\n\n\n\n\n\n\nNote\n\n\n\nIn general it’s only possible to optimize filtering row groups by one column. This is the biggest difference between file formats and databases. Databases can have multiple indexes on whatever columns you want, and then when you run a query, and it will use all of the indexes. But that’s why it’s hard to make databases work as cloud-native files, because if you have high latency, you don’t want to make lots of tiny fetches.\n\n\n\n\n\nParquet is internally compressed by default and Parquet compression is more efficient compared to other formats.\nCompression algorithms are more effective when nearby bytes are more similar to each other. Data within a column tends to be much more similar than data across a row. Since Parquet is column-oriented, compression algorithms work better and result in smaller file sizes than a comparable row-based format.\nIt’s possible to have random access to one of the internal chunks inside the file at large, even though that chunk is compressed. Note that it isn’t possible to fetch partial data inside one chunk without loading and decompressing the entire chunk.\n\n\n\nFor maximum compatibility with existing systems, geometries are stored as ISO-standard WKB. Most geospatial programs are able to read and write WKB.\n\n\n\nGeoParquet is a young specification, and spatial indices are not yet part of the standard. Future revisions of GeoParquet are expected to add support for spatial indexes.\nOne way around this is to store multiple GeoParquet files according to some region identifier, cataloging each file with the SpatioTemporal Asset Catalog (STAC) specification.\n\n\n\nIn a streaming download, you read bytes starting at the beginning of the file, progressing towards the end. In Parquet, this is not helpful because the metadata is in the footer of the file instead of the header.\nInstead, we can replicate something similar to streaming by first fetching only the metadata region at the end of the file, and then making multiple requests for each internal chunk.\n\n\n\nOnce written, a Parquet file is immutable. No modification or appending can happen to that Parquet file. Instead, create a new Parquet file.\n\n\n\nWhile at medium data sizes GeoParquet is most easily distributed as a single file, at large data sizes a single dataset is often split into multiple files. Sometimes multiple files can be easier to write, such as if the data is output from a distributed system.\nA best practice when writing multiple files is to store a top-level metadata file, often named _metadata, with the metadata of all Parquet files in the directory. Without a top-level metadata file, a reader must read the Parquet footer of every individual file in the directory before reading any data. With a metadata file, a Parquet reader can read just that one metadata file, and then read the relevant chunks in the directory. For more information on this, read the “Partitioned Datasets” and “Writing _metadata and _common_metadata files” of the pyarrow documentation. As of August 2023, GeoPandas has no way to write multiple GeoParquet files out of the box, though you may be able to pass a * glob with multiple paths into geopandas.read_parquet.\nStoring Parquet data in multiple files makes it possible to in effect append to the dataset by adding a new file to the directory, but you must be careful to ensure that the new file has the exact same data schema as the existing files, and if a top-level metadata file exists, it must be rewritten to reflect the new file.\nSome elements of how to store GeoParquet-specific metadata in a multi-file layout have not yet been standardized.\n\n\n\nParquet supports a very extensive type system, including nested types such as lists and maps (i.e. like a Python dict). This means that you can store a key-value mapping or a multi-dimensional array within an attribute column of a GeoParquet dataset."
  },
  {
    "objectID": "geoparquet/index.html#references",
    "href": "geoparquet/index.html#references",
    "title": "GeoParquet",
    "section": "",
    "text": "Demystifying the Parquet File Format"
  },
  {
    "objectID": "geoparquet/index.html#footnotes",
    "href": "geoparquet/index.html#footnotes",
    "title": "GeoParquet",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAs pointed out by GDAL developer Even Rouault, reading GeoParquet through GDAL is just as fast as reading through the geopandas.read_parquet function if you’re using GDAL’s Arrow API. As of September 2023, this is not the default, so you need to opt into the pyogrio engine and opt into the Arrow API:\nimport geopandas as gpd\ngpd.read_file(\"file.parquet\", engine=\"pyogrio\", use_arrow=True)\nIt’s also necessary to note that the Python wheels distributed by pyogrio do not include the Arrow and Parquet drivers by default. In order to use the pyogrio driver for a GeoParquet file, you need to compile from source when installing. You’ll need to have a GDAL installation version 3.6 or later (and built with Arrow and Parquet support, as seen by ogrinfo --formats) on your computer already, and then you can build pyogrio from source with:\npip install pyogrio --no-binary pyogrio\n↩︎"
  },
  {
    "objectID": "cloud-optimized-geotiffs/intro.html",
    "href": "cloud-optimized-geotiffs/intro.html",
    "title": "Cloud-Optimized GeoTIFFs",
    "section": "",
    "text": "Cloud-Optimized GeoTIFF (COG), a raster format, is a variant of the TIFF image format that specifies a particular layout of internal data in the GeoTIFF specification to allow for optimized (subsetted or aggregated) access over a network for display or data reading. All COG files are valid GeoTIFF files, but not all GeoTIFF files are valid COG files. The key components that differ between GeoTIFF and COG are overviews and internal tiling.\nFor more details see https://www.cogeo.org/\n\n\n\nDimensions are the number of bands, rows and columns stored in a GeoTIFF. There is a tradeoff between storing lots of data in one GeoTIFF and storing less data in many GeoTIFFs. The larger a single file, the larger the GeoTIFF header and the multiple requests may be required just to read the spatial index before data retrieval. The opposite problem occurs if you make too many small files, then it takes many reads to retrieve data, and when rendering a combined visualization can greatly impact load time.\nIf you plan to pan and zoom a large amount of data through a tiling service in a web browser, there is a tradeoff between 1 large file, or many smaller files. The current recommendation is to meet somewhere in the middle, a moderate amount of medium files.\n\n\n\n\nThis attribute is also sometimes called chunks or internal tiles.\n\nInternal blocks are required if the dimensions of data are over 512x512. However you can control the size of the internal blocks. 256x256 or 512x512 are recommended. When displaying data at full resolution, or doing partial reading of data this size will impact the number of reads required. A size of 256 will take less time to read, and read less data outside the desired bounding box, however for reading large parts of a file, it may take more total read requests. Some clients will aggregate neighboring block reads to reduce the total number of requests.\n\n\n\nOverviews are downsampled (aggregated) data intended for visualization. The best resampling algorithm depends on the range, type, and distribution of the data.\nThe smallest size overview should match the tiling components’ fetch size, typically 256x256. Due to aspect ratio variation just aim to have at least one dimension at or slightly less than 256. The COG driver in GDAL, or rio cogeo tools should do this.\nThere are many resampling algorithms for generating overviews. When creating overviews several options should be compared before deciding which resampling method to apply.\n\n\n\n\nAdditional COG details that can be helpful.\nMaking and using COG examples."
  },
  {
    "objectID": "cloud-optimized-geotiffs/intro.html#dimensions",
    "href": "cloud-optimized-geotiffs/intro.html#dimensions",
    "title": "Cloud-Optimized GeoTIFFs",
    "section": "",
    "text": "Dimensions are the number of bands, rows and columns stored in a GeoTIFF. There is a tradeoff between storing lots of data in one GeoTIFF and storing less data in many GeoTIFFs. The larger a single file, the larger the GeoTIFF header and the multiple requests may be required just to read the spatial index before data retrieval. The opposite problem occurs if you make too many small files, then it takes many reads to retrieve data, and when rendering a combined visualization can greatly impact load time.\nIf you plan to pan and zoom a large amount of data through a tiling service in a web browser, there is a tradeoff between 1 large file, or many smaller files. The current recommendation is to meet somewhere in the middle, a moderate amount of medium files."
  },
  {
    "objectID": "cloud-optimized-geotiffs/intro.html#internal-blocks",
    "href": "cloud-optimized-geotiffs/intro.html#internal-blocks",
    "title": "Cloud-Optimized GeoTIFFs",
    "section": "",
    "text": "This attribute is also sometimes called chunks or internal tiles.\n\nInternal blocks are required if the dimensions of data are over 512x512. However you can control the size of the internal blocks. 256x256 or 512x512 are recommended. When displaying data at full resolution, or doing partial reading of data this size will impact the number of reads required. A size of 256 will take less time to read, and read less data outside the desired bounding box, however for reading large parts of a file, it may take more total read requests. Some clients will aggregate neighboring block reads to reduce the total number of requests."
  },
  {
    "objectID": "cloud-optimized-geotiffs/intro.html#overviews",
    "href": "cloud-optimized-geotiffs/intro.html#overviews",
    "title": "Cloud-Optimized GeoTIFFs",
    "section": "",
    "text": "Overviews are downsampled (aggregated) data intended for visualization. The best resampling algorithm depends on the range, type, and distribution of the data.\nThe smallest size overview should match the tiling components’ fetch size, typically 256x256. Due to aspect ratio variation just aim to have at least one dimension at or slightly less than 256. The COG driver in GDAL, or rio cogeo tools should do this.\nThere are many resampling algorithms for generating overviews. When creating overviews several options should be compared before deciding which resampling method to apply."
  },
  {
    "objectID": "cloud-optimized-geotiffs/intro.html#see-more",
    "href": "cloud-optimized-geotiffs/intro.html#see-more",
    "title": "Cloud-Optimized GeoTIFFs",
    "section": "",
    "text": "Additional COG details that can be helpful.\nMaking and using COG examples."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-details.html",
    "href": "cloud-optimized-geotiffs/cogs-details.html",
    "title": "Advanced COG/GeoTIFF Details",
    "section": "",
    "text": "The COG Intro page describes what makes a Cloud-Optimized GeoTIFF different from a plain, non-optimized GeoTIFF. The rest of this page details additional useful information (applicable to both COGs and plain GeoTIFF files) that can be relevant for making your files as useful and efficient as possible. Any reference to “GeoTIFF” below applies both to plain GeoTIFF files and to COG files.\n\n\nRecommendation The smallest possible data type that still represents the data appropriately should be used. It is not generally recommended to shift or quantize data from float to integer by multiplying, a space saving technique, as end users then need to undo this step to use the data. Data compression is preferred, see also Compression.\nThe GeoTIFF format supports many data types. The key is that all bands must be of the same data type. Unlike some other formats, you cannot mix and match integer (whole number) and float (decimal number) data types in the same file. If you have this use case consider splitting files by data type and using a catalog like STAC to keep track of them, or look at other formats like Zarr.\nScenario: If the COG is intended only for visualization, conversion to 3 band byte will improve performance.\n\nGDAL supported Data Types list\n\n\n\n\nThe compression used in a GeoTIFF is the greatest determinator of the file’s size. If storing a large amount of data, the right compression choice can lead to much smaller file sizes on disk, leading to lower costs.\n\n\nThere are a variety of compression codecs supported by GeoTIFF. Compression codecs tend to be split into two camps: lossy compression where the exact original values cannot be recovered or lossless compression which does not lose any information through the compression and decompression process. For most cases, a lossless compression is recommended, but in some cases a lossy compression can be useful and lead to smaller file sizes, such as if the COG is intended to be used only for visualization.\nDeflate or LZW are both lossless compression codecs and are the recommended algorithms for general use.\nJPEG is a lossy compression codec useful for true-color GeoTIFFs intended to be used only for visualization. Because it’s lossy, it tends to produce smaller file sizes than deflate or LZW. JPEG should only be used with RGB Byte data.\nLERC (Limited Error Raster Compression) is a lossy but very efficient compression algorithm for floating point data. This compression rounds values to a precision provided by the user and tends to be useful e.g. for elevation data where the source data is known to not have precision beyond a known value. But note, this compression is not lossless. Additionally, LERC is a relatively new algorithm and may not be supported everywhere. GDAL needs to be compiled with the LERC driver in order to load a GeoTIFF with LERC compression.\nSome other compression algorithms may be preferred depending on the data type and distribution, and if the goal is maximum compression or not. Codecs that produce the smallest file sizes tend to take longer to read into memory. If the network bandwidth to load the file is slow, then a very efficient compression algorithm may be most efficient, even if it takes longer to decompress when loaded. Alternatively, if the network speed is very fast, or if reading from a local disk, a slightly less efficient compression codec that decompresses faster may be preferred.\nThere are many posts on the internet exploring GeoTIFF compression and performance:\n\nGuide to GeoTIFF compression and optimization with GDAL\nGeoTiff Compression for Dummies\nGeoTiff compression comparison\n\n\n\n\nGeoTIFFs have compression internal to the file, meaning that the internal blocks in a GeoTIFF are already compressed. This internal compression is especially useful for COGs, compared to external compression (such as saving a COG inside a ZIP file), since a COG reader can decompress only the specific portion of the file requested, instead of needing to decompress the entire file.\nThe internal compression of a GeoTIFF also means that it does not need additional compression, and indeed that additional compression will decrease performance. Gzip or ZIP compression applied to a GeoTIFF with internal compression will not make the file smaller.\nIt is possible but not recommended to create GeoTIFFs with no internal compression.\n\n\n\n\nSetting a no data value makes it clear to users and visualization tools what pixels are not actually data. For visualization this allows these pixels to be easily hidden (transparent). Historically many values have been used, 0, -9999, etc… The key is to make sure the GDAL flag for no data is set. It is also suggested that the smallest negative value be used instead of a random value. For byte and unsigned integers data types this will be 0. For float data, setting NaN as the no data value is suggested. Make sure to use a no data value that does not have meaning in your data; otherwise use a different value (like the max possible value). Having the right nodata flag set is important for overview generation.\n\n\n\nRead performance can be greatly impacted by the choice of projection and the particular applications used for dynamic tile serving. Using a known CRS defined in the PROJ database (typically EPSG code) is preferred over custom projections. Load times can be 5-20 times greater when using a custom projection. Whenever applying projections make sure to use WKT2 representation. If using a database of known projections, i.e. EPSG codes, this should be fine, there are known issues around manually setting proj-strings.\n\n\n\n\nThe optimum size of data at which splitting across files improves performance as a multi-file dataset instead of a single file.\nWhen to recommend particular internal tile sizes\nCompression impacts on http transfer rates.\nSupport for COG creation in all common geospatial tools varies.\n\n\n\n\n\nAn Introduction to Cloud Optimized GeoTIFFS (COGs) Part 1: Overview\nDo you really want people using your data?"
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-details.html#data-type",
    "href": "cloud-optimized-geotiffs/cogs-details.html#data-type",
    "title": "Advanced COG/GeoTIFF Details",
    "section": "",
    "text": "Recommendation The smallest possible data type that still represents the data appropriately should be used. It is not generally recommended to shift or quantize data from float to integer by multiplying, a space saving technique, as end users then need to undo this step to use the data. Data compression is preferred, see also Compression.\nThe GeoTIFF format supports many data types. The key is that all bands must be of the same data type. Unlike some other formats, you cannot mix and match integer (whole number) and float (decimal number) data types in the same file. If you have this use case consider splitting files by data type and using a catalog like STAC to keep track of them, or look at other formats like Zarr.\nScenario: If the COG is intended only for visualization, conversion to 3 band byte will improve performance.\n\nGDAL supported Data Types list"
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-details.html#compression",
    "href": "cloud-optimized-geotiffs/cogs-details.html#compression",
    "title": "Advanced COG/GeoTIFF Details",
    "section": "",
    "text": "The compression used in a GeoTIFF is the greatest determinator of the file’s size. If storing a large amount of data, the right compression choice can lead to much smaller file sizes on disk, leading to lower costs.\n\n\nThere are a variety of compression codecs supported by GeoTIFF. Compression codecs tend to be split into two camps: lossy compression where the exact original values cannot be recovered or lossless compression which does not lose any information through the compression and decompression process. For most cases, a lossless compression is recommended, but in some cases a lossy compression can be useful and lead to smaller file sizes, such as if the COG is intended to be used only for visualization.\nDeflate or LZW are both lossless compression codecs and are the recommended algorithms for general use.\nJPEG is a lossy compression codec useful for true-color GeoTIFFs intended to be used only for visualization. Because it’s lossy, it tends to produce smaller file sizes than deflate or LZW. JPEG should only be used with RGB Byte data.\nLERC (Limited Error Raster Compression) is a lossy but very efficient compression algorithm for floating point data. This compression rounds values to a precision provided by the user and tends to be useful e.g. for elevation data where the source data is known to not have precision beyond a known value. But note, this compression is not lossless. Additionally, LERC is a relatively new algorithm and may not be supported everywhere. GDAL needs to be compiled with the LERC driver in order to load a GeoTIFF with LERC compression.\nSome other compression algorithms may be preferred depending on the data type and distribution, and if the goal is maximum compression or not. Codecs that produce the smallest file sizes tend to take longer to read into memory. If the network bandwidth to load the file is slow, then a very efficient compression algorithm may be most efficient, even if it takes longer to decompress when loaded. Alternatively, if the network speed is very fast, or if reading from a local disk, a slightly less efficient compression codec that decompresses faster may be preferred.\nThere are many posts on the internet exploring GeoTIFF compression and performance:\n\nGuide to GeoTIFF compression and optimization with GDAL\nGeoTiff Compression for Dummies\nGeoTiff compression comparison\n\n\n\n\nGeoTIFFs have compression internal to the file, meaning that the internal blocks in a GeoTIFF are already compressed. This internal compression is especially useful for COGs, compared to external compression (such as saving a COG inside a ZIP file), since a COG reader can decompress only the specific portion of the file requested, instead of needing to decompress the entire file.\nThe internal compression of a GeoTIFF also means that it does not need additional compression, and indeed that additional compression will decrease performance. Gzip or ZIP compression applied to a GeoTIFF with internal compression will not make the file smaller.\nIt is possible but not recommended to create GeoTIFFs with no internal compression."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-details.html#no-data",
    "href": "cloud-optimized-geotiffs/cogs-details.html#no-data",
    "title": "Advanced COG/GeoTIFF Details",
    "section": "",
    "text": "Setting a no data value makes it clear to users and visualization tools what pixels are not actually data. For visualization this allows these pixels to be easily hidden (transparent). Historically many values have been used, 0, -9999, etc… The key is to make sure the GDAL flag for no data is set. It is also suggested that the smallest negative value be used instead of a random value. For byte and unsigned integers data types this will be 0. For float data, setting NaN as the no data value is suggested. Make sure to use a no data value that does not have meaning in your data; otherwise use a different value (like the max possible value). Having the right nodata flag set is important for overview generation."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-details.html#projection",
    "href": "cloud-optimized-geotiffs/cogs-details.html#projection",
    "title": "Advanced COG/GeoTIFF Details",
    "section": "",
    "text": "Read performance can be greatly impacted by the choice of projection and the particular applications used for dynamic tile serving. Using a known CRS defined in the PROJ database (typically EPSG code) is preferred over custom projections. Load times can be 5-20 times greater when using a custom projection. Whenever applying projections make sure to use WKT2 representation. If using a database of known projections, i.e. EPSG codes, this should be fine, there are known issues around manually setting proj-strings."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-details.html#what-we-dont-know-areas-of-research",
    "href": "cloud-optimized-geotiffs/cogs-details.html#what-we-dont-know-areas-of-research",
    "title": "Advanced COG/GeoTIFF Details",
    "section": "",
    "text": "The optimum size of data at which splitting across files improves performance as a multi-file dataset instead of a single file.\nWhen to recommend particular internal tile sizes\nCompression impacts on http transfer rates.\nSupport for COG creation in all common geospatial tools varies."
  },
  {
    "objectID": "cloud-optimized-geotiffs/cogs-details.html#additional-resources",
    "href": "cloud-optimized-geotiffs/cogs-details.html#additional-resources",
    "title": "Advanced COG/GeoTIFF Details",
    "section": "",
    "text": "An Introduction to Cloud Optimized GeoTIFFS (COGs) Part 1: Overview\nDo you really want people using your data?"
  },
  {
    "objectID": "copc/index.html",
    "href": "copc/index.html",
    "title": "Cloud-Optimized Point Clouds (COPC)",
    "section": "",
    "text": "The LASER (LAS) file format is designed to store 3-dimensional (x,y,z) point cloud data typically collected from LiDAR. An LAZ file is a compressed LAS file and a Cloud-Optimized Point Cloud (COPC) file is a valid LAZ file.\nCOPC files are similar to COGs for GeoTIFFs: Both are valid versions of the original file format but with additional requirements to support cloud-optimized data access. In the case of COGs, there are additional requirements for tiling and overviews. For COPC, data must be organized into a clustered octree with a variable-length record (VLR) describing the octree structure.\nRead more at https://copc.io/.\nStay tuned for more information on COPC in future releases of this guide."
  },
  {
    "objectID": "pmtiles/intro.html",
    "href": "pmtiles/intro.html",
    "title": "PMTiles",
    "section": "",
    "text": "PMTiles is a single-file archive format for tiled data, usually used for visualization.\nAs an “archive format”, PMTiles is similar to a ZIP file: it contains the contents of many individual files inside of one PMTiles file. A single file is often much easier to use and keep track of than many very small files.\nPMTiles is designed for tiled data. That is, data where one inner file represents a small square somewhere on a map, usually representing the Web Mercator grid. PMTiles can be used for any format of tiled data. PMTiles is used most often with vector data, where each tile data contained within the archive is encoded as a Mapbox Vector Tile (MVT), but can also be used with e.g. raster data or terrain mesh data.\n\n\nTo understand PMTiles, it’s important to understand the difference between “analytical” data and “tiled” data. Analytical data refers to data in its original form, without any modifications to geometry. Tiled data formats apply a variety of modifications to geometries, including clipping and simplification, to save space and make it faster to visualize.\n\nConsider the above diagram. In an analytical format, every coordinate of the complex polygon would be included in one single file. In a tiled format, there are predefined tile sets (or grids) and the geometry would be split into one or more files, where each file represents one cell of the grid.\nThe analytical format is more useful for operations like a spatial join, because the entire geometry is available. It’s harder to perform such analyses on tiled data because given any one tile, it’s impossible to know whether the data contained in that tile represents the full geometry or not.\n\nKnow which other tiles contain part of this polygon (This is hard! It requires some other pre-generated attribute other than the geometry itself.)\nFetch each of those neighboring tiles\nAssemble the dissected geometries back into a single geometry\nApply the desired operation\n\nThe tiled format is more useful for visualization because a user who wants to visualize a small area only needs to download a few tiles. Additionally loading the data is faster because of simplification. It’s slower to visualize analytical data because the entire shape with all coordinates must be loaded, even if visualizing only a small area.\nThus analytical and visualization formats strive for different goals.\n\n\n\nPMTiles is designed to be a cloud-native file format: used directly from a client over a network via HTTP range requests, without having a server in the middle.\n\n\n\nPMTiles has a file header, one or more metadata regions, and a region of tile data.\nThe header is fixed length, located at the beginning of the file, and includes necessary information to decode the rest of the file accurately.\nPMTiles includes directories, or regions of bytes with metadata about tiles. It’s important for each directory to remain small, so while there will always be at least one directory, larger PMTiles archives with many tiles may include more than one directory.\nAt the end of the file is the tile data. This includes all data for all the tiles in the archive.\nThe full specification is defined here.\n\n\nInterally, tiles are oriented along a Hilbert Curve. This means that tiles that are spatially near each other are also located near each other in the file structure.\nThis is especially appropriate for PMTiles because visualization purposes most often request data within a specific geographic area. Because spatially-nearby tiles are likely to be nearby in the file as well, this allows the PMTiles client to merge multiple requests for tiles into one larger request, rather than needing to fetch a different area of the file for each tile.\n\n\n\n\nPMTiles archives support storing a full XYZ pyramid of tile data. This means that you can store multiple zoom levels of data inside a single file.\n\n\n\nPMTiles allows tiles to be stored in the file with compression.\n\n\n\n\n\nThe easiest way to generate PMTiles for vector data is through the tippecanoe tool. This will generate vector tiles that are ideal for visualization, removing small features at low zoom levels to keep tiles a manageable size.\n\n\n\nPMTiles has a command-line program for creating PMTiles if you already have an MBTiles file or a directory of tiles.\n\n\n\n\n\n\nIf you have an existing PMTiles archive, either as a local file or hosted on cloud storage, you can use the PMTiles Viewer to inspect the tiles hosted within the file.\n\n\n\nPMTiles doesn’t have a standalone JavaScript library, but rather is designed to be used in conjunction with a JavaScript map rendering library.\nSee the docs on viewing PMTiles in Leaflet, MapLibre GL JS and OpenLayers.\n\n\n\nPMTiles has a Python package, which allows reading and writing PMTiles archives from Python.\n\n\n\n\n\n\nThe most common alternative for PMTiles is MBTiles, which was in many ways the precursor to PMTiles. MBTiles stores the included vector tiles in a table in a SQLite database. MBTiles has the benefit of being much easier to use than manually managing millions of tiny, individual files, but MBTiles is not serverless. In general, it’s impossible to read from a SQLite database without fetching the entire file’s content. This means that frontend clients like a web browser couldn’t fetch tiles directly using range requests, but rather a server has to be running to fetch tiles from the MBTiles file.\n\n\n\nIt’s also possible to upload the bare tiled data directly to cloud storage as individual files.\nThis has significant downsides of needing to manage many millions of tiny individual files. Uploading millions of files to a cloud storage provider such as S3 takes time and money. For example, AWS charges $5 per million files added to an S3 bucket. So a 10 million PMTiles archive would cost $50, compared to 5-millionths of a cent to upload the PMTiles file."
  },
  {
    "objectID": "pmtiles/intro.html#analytical-vs-tiled-data-formats",
    "href": "pmtiles/intro.html#analytical-vs-tiled-data-formats",
    "title": "PMTiles",
    "section": "",
    "text": "To understand PMTiles, it’s important to understand the difference between “analytical” data and “tiled” data. Analytical data refers to data in its original form, without any modifications to geometry. Tiled data formats apply a variety of modifications to geometries, including clipping and simplification, to save space and make it faster to visualize.\n\nConsider the above diagram. In an analytical format, every coordinate of the complex polygon would be included in one single file. In a tiled format, there are predefined tile sets (or grids) and the geometry would be split into one or more files, where each file represents one cell of the grid.\nThe analytical format is more useful for operations like a spatial join, because the entire geometry is available. It’s harder to perform such analyses on tiled data because given any one tile, it’s impossible to know whether the data contained in that tile represents the full geometry or not.\n\nKnow which other tiles contain part of this polygon (This is hard! It requires some other pre-generated attribute other than the geometry itself.)\nFetch each of those neighboring tiles\nAssemble the dissected geometries back into a single geometry\nApply the desired operation\n\nThe tiled format is more useful for visualization because a user who wants to visualize a small area only needs to download a few tiles. Additionally loading the data is faster because of simplification. It’s slower to visualize analytical data because the entire shape with all coordinates must be loaded, even if visualizing only a small area.\nThus analytical and visualization formats strive for different goals."
  },
  {
    "objectID": "pmtiles/intro.html#cloud-native",
    "href": "pmtiles/intro.html#cloud-native",
    "title": "PMTiles",
    "section": "",
    "text": "PMTiles is designed to be a cloud-native file format: used directly from a client over a network via HTTP range requests, without having a server in the middle."
  },
  {
    "objectID": "pmtiles/intro.html#internal-format",
    "href": "pmtiles/intro.html#internal-format",
    "title": "PMTiles",
    "section": "",
    "text": "PMTiles has a file header, one or more metadata regions, and a region of tile data.\nThe header is fixed length, located at the beginning of the file, and includes necessary information to decode the rest of the file accurately.\nPMTiles includes directories, or regions of bytes with metadata about tiles. It’s important for each directory to remain small, so while there will always be at least one directory, larger PMTiles archives with many tiles may include more than one directory.\nAt the end of the file is the tile data. This includes all data for all the tiles in the archive.\nThe full specification is defined here.\n\n\nInterally, tiles are oriented along a Hilbert Curve. This means that tiles that are spatially near each other are also located near each other in the file structure.\nThis is especially appropriate for PMTiles because visualization purposes most often request data within a specific geographic area. Because spatially-nearby tiles are likely to be nearby in the file as well, this allows the PMTiles client to merge multiple requests for tiles into one larger request, rather than needing to fetch a different area of the file for each tile."
  },
  {
    "objectID": "pmtiles/intro.html#multiple-resolution",
    "href": "pmtiles/intro.html#multiple-resolution",
    "title": "PMTiles",
    "section": "",
    "text": "PMTiles archives support storing a full XYZ pyramid of tile data. This means that you can store multiple zoom levels of data inside a single file."
  },
  {
    "objectID": "pmtiles/intro.html#internal-compression",
    "href": "pmtiles/intro.html#internal-compression",
    "title": "PMTiles",
    "section": "",
    "text": "PMTiles allows tiles to be stored in the file with compression."
  },
  {
    "objectID": "pmtiles/intro.html#generating-pmtiles",
    "href": "pmtiles/intro.html#generating-pmtiles",
    "title": "PMTiles",
    "section": "",
    "text": "The easiest way to generate PMTiles for vector data is through the tippecanoe tool. This will generate vector tiles that are ideal for visualization, removing small features at low zoom levels to keep tiles a manageable size.\n\n\n\nPMTiles has a command-line program for creating PMTiles if you already have an MBTiles file or a directory of tiles."
  },
  {
    "objectID": "pmtiles/intro.html#using-pmtiles",
    "href": "pmtiles/intro.html#using-pmtiles",
    "title": "PMTiles",
    "section": "",
    "text": "If you have an existing PMTiles archive, either as a local file or hosted on cloud storage, you can use the PMTiles Viewer to inspect the tiles hosted within the file.\n\n\n\nPMTiles doesn’t have a standalone JavaScript library, but rather is designed to be used in conjunction with a JavaScript map rendering library.\nSee the docs on viewing PMTiles in Leaflet, MapLibre GL JS and OpenLayers.\n\n\n\nPMTiles has a Python package, which allows reading and writing PMTiles archives from Python."
  },
  {
    "objectID": "pmtiles/intro.html#alternatives",
    "href": "pmtiles/intro.html#alternatives",
    "title": "PMTiles",
    "section": "",
    "text": "The most common alternative for PMTiles is MBTiles, which was in many ways the precursor to PMTiles. MBTiles stores the included vector tiles in a table in a SQLite database. MBTiles has the benefit of being much easier to use than manually managing millions of tiny, individual files, but MBTiles is not serverless. In general, it’s impossible to read from a SQLite database without fetching the entire file’s content. This means that frontend clients like a web browser couldn’t fetch tiles directly using range requests, but rather a server has to be running to fetch tiles from the MBTiles file.\n\n\n\nIt’s also possible to upload the bare tiled data directly to cloud storage as individual files.\nThis has significant downsides of needing to manage many millions of tiny individual files. Uploading millions of files to a cloud storage provider such as S3 takes time and money. For example, AWS charges $5 per million files added to an S3 bucket. So a 10 million PMTiles archive would cost $50, compared to 5-millionths of a cent to upload the PMTiles file."
  }
]